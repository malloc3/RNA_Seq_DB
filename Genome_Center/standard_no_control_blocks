-- MySQL dump 10.13  Distrib 5.7.27, for Linux (x86_64)
--
-- Host: localhost    Database: production
-- ------------------------------------------------------
-- Server version	5.7.27

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `account_logs`
--

DROP TABLE IF EXISTS `account_logs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `account_logs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `row1` int(11) DEFAULT NULL,
  `row2` int(11) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `note` text COLLATE utf8_unicode_ci,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_account_log_associations_on_user_id` (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `account_logs`
--

LOCK TABLES `account_logs` WRITE;
/*!40000 ALTER TABLE `account_logs` DISABLE KEYS */;
/*!40000 ALTER TABLE `account_logs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `accounts`
--

DROP TABLE IF EXISTS `accounts`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `accounts` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `transaction_type` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `amount` float DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `category` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `job_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` text COLLATE utf8_unicode_ci,
  `labor_rate` float DEFAULT NULL,
  `markup_rate` float DEFAULT NULL,
  `operation_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_accounts_on_budget_id` (`budget_id`),
  KEY `index_accounts_on_job_id` (`job_id`),
  KEY `index_accounts_on_user_id` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=51 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `accounts`
--

LOCK TABLES `accounts` WRITE;
/*!40000 ALTER TABLE `accounts` DISABLE KEYS */;
INSERT INTO `accounts` VALUES (7,'debit',0,1,1,'materials',4,'2020-03-19 20:33:36','2020-03-19 20:33:36','Materials',0,0,5),(8,'debit',0,1,1,'labor',4,'2020-03-19 20:33:36','2020-03-19 20:33:36','Labor: 0 minutes @ $0.0/min',0,0,5),(13,'debit',0,1,1,'materials',41,'2020-03-23 20:11:36','2020-03-23 20:11:36','Materials',0,0,9),(14,'debit',0,1,1,'labor',41,'2020-03-23 20:11:36','2020-03-23 20:11:36','Labor: 0 minutes @ $0.0/min',0,0,9),(19,'debit',0,1,1,'materials',69,'2020-03-23 23:26:24','2020-03-23 23:26:24','Materials',0,0,6),(20,'debit',0,1,1,'labor',69,'2020-03-23 23:26:24','2020-03-23 23:26:24','Labor: 0 minutes @ $0.0/min',0,0,6),(21,'debit',0,1,1,'materials',70,'2020-03-23 23:32:29','2020-03-23 23:32:29','Materials',0,0,6),(22,'debit',0,1,1,'labor',70,'2020-03-23 23:32:29','2020-03-23 23:32:29','Labor: 0 minutes @ $0.0/min',0,0,6),(23,'debit',0,1,1,'materials',76,'2020-03-23 23:54:07','2020-03-23 23:54:07','Materials',0,0,6),(24,'debit',0,1,1,'labor',76,'2020-03-23 23:54:07','2020-03-23 23:54:07','Labor: 0 minutes @ $0.0/min',0,0,6),(25,'debit',0,1,1,'materials',85,'2020-03-24 00:33:31','2020-03-24 00:33:31','Materials',0,0,6),(26,'debit',0,1,1,'labor',85,'2020-03-24 00:33:31','2020-03-24 00:33:31','Labor: 0 minutes @ $0.0/min',0,0,6),(27,'debit',0,1,1,'materials',86,'2020-03-24 15:22:26','2020-03-24 15:22:26','Materials',0,0,6),(28,'debit',0,1,1,'labor',86,'2020-03-24 15:22:26','2020-03-24 15:22:26','Labor: 0 minutes @ $0.0/min',0,0,6),(29,'debit',0,1,1,'materials',87,'2020-03-24 15:24:11','2020-03-24 15:24:11','Materials',0,0,42),(30,'debit',0,1,1,'labor',87,'2020-03-24 15:24:11','2020-03-24 15:24:11','Labor: 0 minutes @ $0.0/min',0,0,42),(31,'debit',0,1,1,'materials',88,'2020-03-24 16:06:52','2020-03-24 16:06:52','Materials',0,0,39),(32,'debit',0,1,1,'labor',88,'2020-03-24 16:06:52','2020-03-24 16:06:52','Labor: 0 minutes @ $0.0/min',0,0,39),(33,'debit',0,1,1,'materials',91,'2020-03-24 16:17:17','2020-03-24 16:17:17','Materials',0,0,85),(34,'debit',0,1,1,'labor',91,'2020-03-24 16:17:17','2020-03-24 16:17:17','Labor: 0 minutes @ $0.0/min',0,0,85),(35,'debit',0,1,1,'materials',92,'2020-03-24 16:17:59','2020-03-24 16:17:59','Materials',0,0,82),(36,'debit',0,1,1,'labor',92,'2020-03-24 16:17:59','2020-03-24 16:17:59','Labor: 0 minutes @ $0.0/min',0,0,82),(37,'debit',0,1,1,'materials',94,'2020-03-24 17:57:20','2020-03-24 17:57:20','Materials',0,0,83),(38,'debit',0,1,1,'labor',94,'2020-03-24 17:57:20','2020-03-24 17:57:20','Labor: 0 minutes @ $0.0/min',0,0,83),(39,'debit',0,1,1,'materials',95,'2020-03-24 17:58:19','2020-03-24 17:58:19','Materials',0,0,84),(40,'debit',0,1,1,'labor',95,'2020-03-24 17:58:19','2020-03-24 17:58:19','Labor: 0 minutes @ $0.0/min',0,0,84),(41,'debit',0,1,1,'materials',96,'2020-03-24 18:21:33','2020-03-24 18:21:33','Materials',0,0,84),(42,'debit',0,1,1,'labor',96,'2020-03-24 18:21:33','2020-03-24 18:21:33','Labor: 0 minutes @ $0.0/min',0,0,84),(43,'debit',0,1,1,'materials',97,'2020-03-24 19:07:43','2020-03-24 19:07:43','Materials',0,0,103),(44,'debit',0,1,1,'labor',97,'2020-03-24 19:07:43','2020-03-24 19:07:43','Labor: 0 minutes @ $0.0/min',0,0,103),(45,'debit',0,1,1,'materials',98,'2020-03-24 19:16:05','2020-03-24 19:16:05','Materials',0,0,109),(46,'debit',0,1,1,'labor',98,'2020-03-24 19:16:05','2020-03-24 19:16:05','Labor: 0 minutes @ $0.0/min',0,0,109),(47,'debit',0,1,1,'materials',99,'2020-03-24 19:59:28','2020-03-24 19:59:28','Materials',0,0,115),(48,'debit',0,1,1,'labor',99,'2020-03-24 19:59:28','2020-03-24 19:59:28','Labor: 0 minutes @ $0.0/min',0,0,115),(49,'debit',0,1,1,'materials',100,'2020-03-24 20:03:15','2020-03-24 20:03:15','Materials',0,0,121),(50,'debit',0,1,1,'labor',100,'2020-03-24 20:03:15','2020-03-24 20:03:15','Labor: 0 minutes @ $0.0/min',0,0,121);
/*!40000 ALTER TABLE `accounts` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `allowable_field_types`
--

DROP TABLE IF EXISTS `allowable_field_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `allowable_field_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `field_type_id` int(11) DEFAULT NULL,
  `sample_type_id` int(11) DEFAULT NULL,
  `object_type_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_allowable_field_types_on_field_type_id` (`field_type_id`),
  KEY `index_allowable_field_types_on_object_type_id` (`object_type_id`),
  KEY `index_allowable_field_types_on_sample_type_id` (`sample_type_id`)
) ENGINE=InnoDB AUTO_INCREMENT=479 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `allowable_field_types`
--

LOCK TABLES `allowable_field_types` WRITE;
/*!40000 ALTER TABLE `allowable_field_types` DISABLE KEYS */;
INSERT INTO `allowable_field_types` VALUES (1,10,1,3,'2020-03-19 17:30:41','2020-03-19 17:30:41'),(2,11,1,3,'2020-03-19 17:30:41','2020-03-19 17:30:41'),(3,12,1,3,'2020-03-19 17:30:41','2020-03-19 17:30:41'),(4,13,1,4,'2020-03-19 17:30:41','2020-03-19 17:30:41'),(5,14,1,3,'2020-03-19 17:30:41','2020-03-19 17:30:41'),(6,15,1,4,'2020-03-19 17:30:41','2020-03-19 17:30:41'),(9,21,NULL,5,'2020-03-19 20:09:26','2020-03-19 20:09:26'),(10,24,4,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(11,24,6,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(12,24,3,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(13,24,7,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(14,24,8,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(15,25,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(16,25,3,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(17,26,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(18,26,3,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(19,29,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(20,29,3,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(21,33,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(22,35,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(23,36,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(24,37,5,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(25,40,6,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(26,44,6,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(27,45,7,NULL,'2020-03-24 15:41:53','2020-03-24 15:41:53'),(28,46,4,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(29,46,3,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(30,47,4,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(31,51,5,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(32,52,5,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(33,57,7,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(34,58,9,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(35,61,5,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(36,62,5,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(37,63,5,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(38,64,5,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(39,71,3,6,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(40,71,3,7,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(41,71,4,8,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(42,71,4,9,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(43,71,4,10,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(44,71,4,11,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(45,71,4,12,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(46,71,4,13,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(47,71,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(48,71,4,15,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(49,71,5,16,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(50,71,5,17,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(51,71,7,18,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(52,71,7,19,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(53,71,7,20,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(54,72,3,6,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(55,72,3,7,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(56,72,4,8,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(57,72,4,9,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(58,72,4,10,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(59,72,4,12,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(60,72,4,13,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(61,72,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(62,72,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(63,72,4,15,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(64,72,5,16,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(65,72,5,17,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(66,72,7,18,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(67,72,7,19,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(68,72,7,20,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(69,73,NULL,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(70,74,NULL,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(71,75,3,6,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(72,75,3,7,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(73,75,4,8,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(74,75,4,9,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(75,75,4,10,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(76,75,4,11,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(77,75,4,12,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(78,75,4,13,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(79,75,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(80,75,4,15,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(81,75,5,16,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(82,75,5,17,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(83,75,7,18,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(84,75,7,19,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(85,75,7,20,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(86,76,3,6,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(87,76,3,7,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(88,76,4,8,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(89,76,4,9,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(90,76,4,10,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(91,76,4,12,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(92,76,4,13,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(93,76,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(94,76,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(95,76,4,15,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(96,76,5,16,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(97,76,5,17,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(98,76,7,18,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(99,76,7,19,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(100,76,7,20,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(101,77,3,6,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(102,77,3,7,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(103,77,4,8,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(104,77,4,9,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(105,77,4,10,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(106,77,4,11,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(107,77,4,12,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(108,77,4,13,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(109,77,4,14,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(110,77,4,15,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(111,77,5,16,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(112,77,5,17,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(113,77,7,18,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(114,77,7,19,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(115,77,7,20,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(116,78,3,6,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(117,78,3,7,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(118,78,4,8,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(119,78,4,9,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(120,78,4,10,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(121,78,4,11,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(122,78,4,12,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(123,78,4,13,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(124,78,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(125,78,4,15,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(126,78,5,16,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(127,78,5,17,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(128,78,7,18,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(129,78,7,19,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(130,78,7,20,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(131,79,3,6,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(132,79,3,7,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(133,79,4,8,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(134,79,4,9,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(135,79,4,10,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(136,79,4,12,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(137,79,4,13,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(138,79,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(139,79,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(140,79,4,15,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(141,79,5,16,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(142,79,5,17,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(143,79,7,18,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(144,79,7,19,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(145,79,7,20,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(146,80,3,6,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(147,80,3,7,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(148,80,4,8,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(149,80,4,9,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(150,80,4,10,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(151,80,4,11,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(152,80,4,12,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(153,80,4,13,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(154,80,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(155,80,4,15,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(156,80,5,16,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(157,80,5,17,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(158,80,7,18,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(159,80,7,19,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(160,80,7,20,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(161,81,3,6,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(162,81,3,7,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(163,81,4,8,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(164,81,4,9,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(165,81,4,10,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(166,81,4,12,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(167,81,4,13,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(168,81,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(169,81,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(170,81,4,15,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(171,81,5,16,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(172,81,5,17,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(173,81,7,18,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(174,81,7,19,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(175,81,7,20,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(176,82,3,6,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(177,82,3,7,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(178,82,4,8,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(179,82,4,9,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(180,82,4,10,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(181,82,4,12,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(182,82,4,13,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(183,82,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(184,82,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(185,82,4,15,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(186,82,5,16,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(187,82,5,17,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(188,82,7,18,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(189,82,7,19,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(190,82,7,20,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(191,83,NULL,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(192,84,NULL,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(193,85,3,6,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(194,85,3,7,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(195,85,4,8,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(196,85,4,9,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(197,85,4,10,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(198,85,4,11,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(199,85,4,12,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(200,85,4,13,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(201,85,4,14,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(202,85,4,15,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(203,85,5,16,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(204,85,5,17,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(205,85,7,18,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(206,85,7,19,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(207,85,7,20,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(208,86,NULL,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(209,87,NULL,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(210,88,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(211,88,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(212,88,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(213,88,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(214,88,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(215,88,4,11,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(216,88,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(217,88,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(218,88,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(219,88,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(220,88,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(221,88,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(222,88,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(223,88,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(224,88,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(225,89,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(226,89,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(227,89,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(228,89,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(229,89,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(230,89,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(231,89,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(232,89,4,11,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(233,89,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(234,89,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(235,89,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(236,89,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(237,89,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(238,89,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(239,89,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(240,90,NULL,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(241,91,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(242,91,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(243,91,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(244,91,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(245,91,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(246,91,4,11,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(247,91,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(248,91,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(249,91,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(250,91,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(251,91,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(252,91,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(253,91,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(254,91,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(255,91,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(256,92,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(257,92,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(258,92,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(259,92,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(260,92,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(261,92,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(262,92,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(263,92,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(264,92,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(265,92,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(266,92,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(267,92,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(268,92,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(269,92,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(270,93,NULL,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(271,94,NULL,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(272,95,NULL,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(273,96,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(274,96,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(275,96,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(276,96,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(277,96,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(278,96,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(279,96,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(280,96,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(281,96,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(282,96,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(283,96,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(284,96,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(285,96,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(286,97,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(287,97,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(288,97,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(289,97,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(290,97,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(291,97,4,11,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(292,97,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(293,97,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(294,97,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(295,97,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(296,97,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(297,97,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(298,97,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(299,97,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(300,97,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(301,98,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(302,98,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(303,98,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(304,98,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(305,98,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(306,98,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(307,98,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(308,98,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(309,98,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(310,98,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(311,98,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(312,98,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(313,98,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(314,98,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(315,98,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(316,99,NULL,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(317,100,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(318,100,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(319,100,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(320,100,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(321,100,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(322,100,4,11,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(323,100,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(324,100,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(325,100,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(326,100,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(327,100,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(328,100,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(329,100,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(330,100,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(331,100,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(332,101,3,6,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(333,101,3,7,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(334,101,4,8,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(335,101,4,9,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(336,101,4,10,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(337,101,4,12,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(338,101,4,13,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(339,101,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(340,101,4,14,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(341,101,4,15,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(342,101,5,16,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(343,101,5,17,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(344,101,7,18,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(345,101,7,19,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(346,101,7,20,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(347,102,NULL,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(348,103,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(349,103,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(350,103,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(351,103,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(352,103,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(353,103,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(354,103,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(355,103,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(356,103,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(357,103,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(358,103,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(359,103,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(360,103,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(361,103,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(362,103,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(363,104,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(364,105,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(365,106,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(366,106,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(367,106,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(368,106,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(369,106,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(370,106,4,11,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(371,106,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(372,106,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(373,106,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(374,106,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(375,106,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(376,106,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(377,106,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(378,106,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(379,106,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(380,107,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(381,107,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(382,107,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(383,107,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(384,107,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(385,107,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(386,107,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(387,107,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(388,107,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(389,107,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(390,107,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(391,107,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(392,107,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(393,107,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(394,108,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(395,109,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(396,110,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(397,111,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(398,111,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(399,111,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(400,111,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(401,111,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(402,111,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(403,111,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(404,111,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(405,111,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(406,111,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(407,111,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(408,111,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(409,111,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(410,112,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(411,112,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(412,112,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(413,112,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(414,112,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(415,112,4,11,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(416,112,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(417,112,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(418,112,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(419,112,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(420,112,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(421,112,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(422,112,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(423,112,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(424,112,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(425,113,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(426,113,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(427,113,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(428,113,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(429,113,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(430,113,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(431,113,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(432,113,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(433,113,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(434,113,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(435,113,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(436,113,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(437,113,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(438,113,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(439,113,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(440,114,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(441,115,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(442,116,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(443,117,NULL,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(444,118,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(445,118,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(446,118,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(447,118,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(448,118,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(449,118,4,11,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(450,118,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(451,118,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(452,118,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(453,118,4,15,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(454,118,5,16,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(455,118,5,17,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(456,118,7,18,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(457,118,7,19,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(458,118,7,20,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(459,119,3,6,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(460,119,3,7,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(461,119,4,8,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(462,119,4,9,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(463,119,4,10,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(464,119,4,12,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(465,119,4,13,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(466,119,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(467,119,4,14,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(468,119,4,15,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(469,119,5,16,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(470,119,5,17,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(471,119,7,18,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(472,119,7,19,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(473,119,7,20,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(474,120,NULL,NULL,'2020-03-24 15:41:58','2020-03-24 15:41:58'),(475,123,4,6,'2020-03-24 15:51:41','2020-03-24 15:51:41'),(476,124,4,6,'2020-03-24 16:01:17','2020-03-24 16:01:17'),(477,128,4,6,'2020-03-24 18:29:56','2020-03-24 18:29:56'),(478,129,4,6,'2020-03-24 18:30:30','2020-03-24 18:30:30');
/*!40000 ALTER TABLE `allowable_field_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `announcements`
--

DROP TABLE IF EXISTS `announcements`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `announcements` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `message` text COLLATE utf8_unicode_ci,
  `active` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `announcements`
--

LOCK TABLES `announcements` WRITE;
/*!40000 ALTER TABLE `announcements` DISABLE KEYS */;
INSERT INTO `announcements` VALUES (1,'Welcome to Aquarium','If you are just starting Aquarium for the first time, you may need to add some content. Go to http://www.aquarium.bio/ and click on COMMUNITY and then Workflows to find protocols and workflows you can add to this instance of Aquarium. Enjoy!',1,'2018-12-21 17:58:04','2018-12-21 17:58:27');
/*!40000 ALTER TABLE `announcements` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `budgets`
--

DROP TABLE IF EXISTS `budgets`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `budgets` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `overhead` float DEFAULT NULL,
  `contact` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` text COLLATE utf8_unicode_ci,
  `email` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `phone` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `budgets`
--

LOCK TABLES `budgets` WRITE;
/*!40000 ALTER TABLE `budgets` DISABLE KEYS */;
INSERT INTO `budgets` VALUES (1,'My First Budget',NULL,'Joe','2018-07-17 22:10:05','2018-07-17 22:10:05','An example budget','joe@nasa.org','8675309');
/*!40000 ALTER TABLE `budgets` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `codes`
--

DROP TABLE IF EXISTS `codes`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `codes` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `content` text COLLATE utf8_unicode_ci,
  `parent_id` int(11) DEFAULT NULL,
  `parent_class` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `user_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=610 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `codes`
--

LOCK TABLES `codes` WRITE;
/*!40000 ALTER TABLE `codes` DISABLE KEYS */;
INSERT INTO `codes` VALUES (1,'protocol','# Title: Inventory Purchase Protocol\n# Author: Eric Klavins\n# Date: May 31, 2016 \n\nneeds \"Standard Libs/Debug\"\n\nclass Protocol\n\n  include Debug\n\n  def labor_rate\n    Parameter.get_float(\'labor rate\')\n  end\n  \n  def main\n    if !operations.one?\n      show do\n        title \"Too many batched!\"\n        \n        note \"Right now, this protocol only supports one Direct Purchase at a time. Please re-batch in jobs of one.\"\n      end\n      \n      return {}\n    end\n    \n    \n    @object_types = ObjectType.all\n    @user = operations.first.user\n    user = @user # Can\'t put @user in show, because it would refer to the wrong object\n\n    result = show do\n      title \"Choose a budget\"\n      note \"User: #{user.name} (#{user.login})\"\n      select user.budget_info.collect { |bi| bi[:budget].name }, var: \"choice\", label: \"Choose a budget\", default: 0\n    end\n    \n    @budget = Budget.find_by_name(result[:choice])\n    @overhead = Parameter.get_float(\"markup rate\")\n    @transactions = []\n    \n    operations.first.plan.budget_id = @budget.id\n    operations.first.plan.save \n    \n    again = true\n    \n    while again \n    \n      result = show do\n        title \"Select Category\"\n        note \"Basics: tubes, tip boxes, ...\"\n        note \"Samples: media, ...\"\n        note \"Batched: Gibson Aliquots, plates, ...\"\n        select [ \"Basics\", \"Samples\", \"Batched\" ], var: \"choice\", label: \"Choose something\", default: 1\n      end\n      \n      case result[:choice]\n        when \"Basics\"then basic_chooser\n        when \"Samples\" then sample_chooser \n        when \"Batched\" then batched_chooser\n      end\n      \n      tab = [ [ \"Description\", \"Amount\" ] ]\n      tab += @transactions.collect do |t| \n        [\n          t[:description],\n          currency((1 + @overhead) * t[:amount])\n        ]\n      end\n      \n      result = show do\n        title  \"Summary\"\n        table tab if tab.length > 1 \n        note \"No purchases made\" unless tab.length > 1\n        select [ \"No\", \"Yes\" ], var: \"again\", label: \"Would you like to make another purchase?\", default: 0\n      end\n    \n      again = ( result[:again] == \"Yes\" )\n      \n    end\n    \n    operations.first.associate :transactions, @transactions\n    \n    return {}\n   end\n\n  def choose_object_from objects, number=false\n    result = show do\n      title \"Choose Object\"\n      select objects.collect { |ot| ot.name }, var: \"choice\", label: \"Choose object:\", default: 0\n      get \"number\", var: \"n\", label: \"How many?\", default: 5 if number\n    end\n\n    return objects.find { |b| b.name == result[:choice] } unless number\n    return [ objects.find { |b| b.name == result[:choice] }, result[:n] ] if number\n  end\n  \n  ###############################################################################################################\n  def basic_chooser \n    \n    basics = @object_types.select { |ot| basic? ot }      \n    ot = choose_object_from basics\n\n    error \"There seems to be a problem with the object you\'ve chosen.\" if ot.nil?\n\n    vol = {}\n  \n    m = ot.data_object[:materials]\n    l = ot.data_object[:labor]\n    u = ot.data_object[:unit] \n    vol[:n] = 1\n \n    vol = show do\n      title \"Choose Amount\"\n      get \"number\", var: \"n\", label: \"How many #{u.pluralize} of #{ot.name}?\", default: 5\n    end\n\n    message = \"Purchase #{vol[:n]} #{ot.name.pluralize}\"\n    if confirm message, currency((1+@overhead) * ((m* vol[:n])+(l * labor_rate* vol[:n])) ) \n      transaction = make_purchase message, m*vol[:n], l*vol[:n]\n    end        \n    \n  end\n\n  ###############################################################################################################\n  def sample_chooser \n   \n    samples = @object_types.select { |ot| sample? ot }   \n    ot = choose_object_from samples\n\n    error \"There seems to be a problem with the object you\'ve chosen.\" if ot.nil?\n\n    result = show do\n      title \"Choose Sample\"\n      select ot.data_object[:samples].collect { |s| s[:name] }, var: \"choice\", label: \"Choose sample\", default: 2\n    end\n    \n    descriptor = ot.data_object[:samples].find { |d| d[:name] == result[:choice] }\n    m = descriptor[:materials]\n    l = descriptor[:labor] \n    u = descriptor[:unit]\n    s = descriptor[:name] \n    vol = {}\n\n    items = Sample.find_by_name(s).items.reject { |i| i.deleted? }.reject {|i| i.object_type.name != ot.name }\n    \n    if items.length > 0\n      item = choose_item items, \"Choose #{ot.name} of #{s}\"\n\n      if ot.name.include?(\"Agar\")\n        vol[:n] = descriptor[:total_volume]\n      else\n        vol = show do\n          title \"Choose Volume\"\n          get \"number\", var: \"n\", label: \"How many #{u.pluralize} of #{s}?\", default: 5 \n          select [\"No\", \"Yes\"], var: \"delete\", label: \"Are you purchasing the whole container or is the container now empty?\", default: 0\n        end\n      end\n\n\n      cost = currency((1+@overhead)*((m* vol[:n])+(l * labor_rate* vol[:n]))) \n      message = \"Purchase #{ot.name} of #{s}, item #{item.id}\"\n      if confirm message, cost\n        take [item]\n        transaction = make_purchase message, m*vol[:n], l*vol[:n]\n        release [item]\n        if (descriptor[:delete] || vol[:delete] == \"Yes\")\n          item.mark_as_deleted\n        end\n      end\n    else\n      error \"There are no items of #{ot.name}/#{s} in stock\"\n    end \n  end    \n  ###############################################################################################################\n  def batched_chooser \n\n    collections = @object_types.select { |ot| batched? ot }\n    ot = choose_object_from collections\n\n    error \"There seems to be a problem with the object you\'ve chosen.\" if ot.nil?\n  \n    result = show do\n      title \"Choose sample type\" \n      select ot.data_object[:samples].collect { |s| s[:name] }, var: \"choice\", label: \"Choose sample\", default: 0\n    end\n  \n    descriptor = ot.data_object[:samples].find { |d| d[:name] == result[:choice] }\n    m = descriptor[:materials]\n    l = descriptor[:labor] \n    cost = currency((1+@overhead)*(m+(l*labor_rate)))\n  \n    s = Sample.find_by_name(descriptor[:name])\n    collections = ot.items.reject { |i| i.deleted? }.collect { |i| collection_from i }\n    # filter out collections based on user\'s sample input\n    collections.reject! { |c| c.matrix[0][0] != s.id }\n    cids = collections.collect { |c| c.id.to_s }\n  \n    if cids.length > 0\n  \n      result = show do \n        title \"Choose #{ot.name} and number of #{s.name.pluralize} (#{cost} each)\"\n        table [ [ \"id\", \"Location\", \"Number of Samples\" ] ] + (collections.collect { |i| [ \"#{i}\", i.location, i.num_samples ] } )\n        select cids, var: \"id\", label: \"Choose collection\", default: 0\n        get \"number\", var: \"n\", label: \"How many #{s.name.pluralize}?\", default: 2\n      end\n      \n      collection = collections.find { |c| c.id == result[:id].to_i }\n      \n      n = [ collection.num_samples, [ 1, result[:n]].max ].min\n      total_cost = currency((1+@overhead)*(n*m+(n*l* labor_rate)))\n      message = \"Purchase #{n} #{s.name.pluralize} from #{ot.name} #{collection.id}\"\n      \n      if confirm message, total_cost \n        take_samples collection, n\n        transaction = make_purchase message, n*m, n*l\n        release [collection]\n        if collection.num_samples == 0\n          collection.mark_as_deleted\n        end\n      end    \n    else\n      error \"There are no #{ot.name} in stock\"\n    end\n  end\n\n  def take_samples collection, n\n   \n    m = collection.matrix\n    x = 0\n  \n    (0..m.length-1).reverse_each do |i|\n      (0..m[i].length-1).reverse_each do |j|\n        if m[i][j] != -1 && x < n\n          m[i][j] = -1\n          x += 1\n        end\n      end\n    end\n  \n    collection.matrix = m\n    collection.save\n    take [collection]\n    \n  end\n\n  def error msg, details=nil\n    show do \n      title msg\n      note details if details\n      note \"Please report this problem to a BIOFAB lab manager.\"\n    end      \n  end\n\n  def confirm message, cost\n    result = show do \n      title message\n      note \"Cost: #{cost}\"\n      select [ \"Ok\", \"Cancel\" ], var: \"choice\", label: \"Ok to purchase?\", default: 0\n    end\n    return (result[:choice] == \"Ok\")\n  end\n\n  def choose_item items, message\n    options = (items.collect { |i| i.id.to_s })\n    result = show do \n      title message\n      note \"Please choose which item you would like to use: \"\n      select options, var: \"choice\", label: \"Choose item\", default: 0\n    end\n    Item.find(result[:choice])          \n  end\n\n\n  def make_purchase description, mat, lab\n    transaction = {\n      description: description,\n      amount: mat + lab * labor_rate,\n    }\n    \n    @transactions << transaction\n    \n    transaction\n  end\n\n  def valid_sample_descriptor s\n    val = s[:name]      && s[:name].class == String &&\n          s[:materials] && ( s[:materials].class == Float || s[:materials].class == Fixnum ) &&\n          s[:labor]     && ( s[:labor].class == Float     || s[:labor].class == Fixnum ) && \n          s[:unit]      && s[:unit].class == String &&\n          s[:total_volume] && (s[:total_volume].is_a?(Integer))\n    #error(\"Bad descriptor\", s.to_s) unless val #comment this out so user doesn\'t see it\n    val\n  end\n\n  def basic? ot\n    ot.handler != \"sample_container\" && ot.handler != \"collection\"  &&\n    ot.data_object[:materials] && ot.data_object[:labor] && ot.data_object[:unit]     \n  end\n\n  def sample? ot\n    ot.handler == \"sample_container\" && ot.data_object[:samples] && \n    ot.data_object[:samples].each { |s| return nil unless valid_sample_descriptor s }\n  end\n\n  def batched? ot\n    ot.handler == \"collection\" && ot.data_object[:samples] && \n    ot.data_object[:samples].each { |s| return nil unless (s[:materials] && s[:labor] && s[:unit]) }\n  end\n\n  def currency num\n    ActionController::Base.helpers.number_to_currency num\n  end  \n\nend\n',1,'OperationType','2020-01-24 16:50:00','2020-01-24 16:50:00',1),(2,'precondition','def precondition(op)\n  true\nend',1,'OperationType','2020-01-24 16:50:00','2020-01-24 16:50:00',1),(3,'cost_model','def cost(op)\n  trans = op.get(:transactions) || [{ amount: 0.1 }]\n  total_cost = trans.map { |t| t[:amount] }.sum\n  \n  { labor: 0, materials: total_cost }\nend',1,'OperationType','2020-01-24 16:50:00','2020-01-24 16:50:00',1),(4,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',1,'OperationType','2020-01-24 16:50:00','2020-01-24 16:50:00',1),(5,'test','',1,'OperationType','2020-01-24 16:50:00','2020-01-24 16:50:00',1),(6,'source','module Debug\n  def print_object obj\n    if [Numeric, String].any? { |c| obj.is_a? c }\n      obj\n    elsif [Array].any? { |c| obj.is_a? c }\n      obj.map { |item| print_object item }\n    elsif [Hash].any? { |c| obj.is_a? c }\n      Hash[obj.map { |k, v| [k, print_object(v)] }]\n    else\n      s = obj ? obj.id.to_s : \"\"\n      s += \" #{obj.name}\" if obj.class.method_defined? :name\n      s\n    end\n  end\n\n  def log_info *args\n    if debug\n      show do\n        title \"Debug slide (#{args.length} #{\"arg\".pluralize args.length})\"\n\n        args.each do |arg|\n          note \"#{arg.class}: #{print_object arg}\"\n        end\n      end\n    end\n  end\n\n    def inspect(object, ident=nil)\n        show do\n            title \"<span style=\\\"background-color:yellow\\\">INSPECTING #{ident} (#{object.class})</span>\"\n            if object.kind_of?(Array)\n              table object\n            else\n              note object.to_json\n            end\n        end\n    end\nend\n',1,'Library','2020-01-24 16:50:00','2020-01-24 16:50:00',1),(7,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n    \n    \nend',2,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(8,'source','#Justin Vrana\n#\n#modified by:\n#Cannon Mallory\n#malloc3@uw.edu\n#\n#Modifications include:\n# Documentation (yet to happen)\n#\n# This module is for displaying information about collections in effecient easy to use ways\n#\n# TODO Make the collection displays so that they wont always be checkable cause that gets annoying\nmodule CollectionDisplay\n  def create_collection_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    slots.each_slice(collection.object_type.columns).map do |row|\n      row.map do |col|\n        {content: col, class: \'td-empty-slot\'}\n      end\n    end\n  end\n\n  def highlight tbl, row, col, id\n    tbl[row][col] = {content: id, class: \'td-filled-slot\', check: true}\n  end\n\n  # [r,c,x] list\n  def highlight_rcx(collection, rcx_list)\n    tbl = create_collection_table collection\n    rcx_list.each do |r, c, x|\n      highlight tbl, r, c, x\n    end\n    tbl\n  end\n\n  def highlight_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_rcx collection, rcx_list\n  end\n\n  def highlight_non_empty(collection, &rc_block)\n    highlight_rc collection, collection.get_non_empty, &rc_block\n  end\n\n  def highlight_collection ops, id_block=nil, &fv_block\n    g = ops.group_by { |op| fv_block.call(op).collection }\n    tables = g.map do |collection, grouped_ops|\n      rcx_list = grouped_ops.map do |op|\n        fv = fv_block.call(op)\n        id = id_block.call(op) if id_block\n        id ||= fv.sample.id\n        [fv.row, fv.column, id]\n      end\n      tbl = highlight_rcx collection, rcx_list\n      [collection, tbl]\n    end\n    tables\n  end\n\n  def r_c_to_slot collection, r, c\n    rows, cols = collection.dimensions = collection.object_type.rows\n    r*cols + c+1\n  end\n  \n  \n  \n  \n  def create_alpha_numeric_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    alpha_r = (\'A\'..\'H\').to_a\n    slots.each_slice(collection.object_type.columns).each_with_index.map do |row, r_idx|\n      row.each_with_index.map do |col, c_idx|\n        {content: \"#{alpha_r[r_idx]}#{c_idx + 1}\", class: \'td-empty-slot\'}\n      end\n    end\n  end\n  \n  def highlight_alpha_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_alpha_rcx(collection, rcx_list)\n  end\n  \n  def highlight_alpha_rcx(collection, rcx_list)\n     tbl = create_alpha_numeric_table(collection)\n     rcx_list.each do |r, c, x|\n         highlight tbl, r, c, x\n     end\n     return tbl\n  end\n\n  def highlight_alpha_non_empty collection, &rc_block\n    highlight_alpha_rc collection, collection.get_non_empty, &rc_block\n  end\n      \nend',3,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(9,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} ul from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #Instructions on getting and labeling new plate\n  #\n  #@plate Collection plate to be gotten and labeled\n  def get_new_plate(plate)\n    show do\n      title \"Get and Label Working Plate\"\n      note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(10,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    alpha26 = (\"A\"...\"Z\").to_a\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + alpha26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\nend',5,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(11,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    working_plate = Collection.new_collection(C_TYPE)\n\n    get_new_plate(working_plate)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(12,'precondition','def precondition(_op)\n  true\nend',2,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(13,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',2,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(14,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',2,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(15,'test','',2,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(16,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    working_plate = Collection.new_collection(C_TYPE)\n\n    multi_plate = true #multi_input_plates?(operations)\n\n    get_new_plate(working_plate) if multi_plate\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(17,'precondition','def precondition(_op)\n  true\nend',3,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(18,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',3,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(19,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',3,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(20,'test','',3,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(21,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = Collection.new_collection(C_TYPE)\n    show do\n      title \"Get and Label Working Plate\"\n      note \"Get a <b>#{C_TYPE}</b> and lable ID: <b>#{working_plate.id}</b>\"\n    end\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(22,'precondition','def precondition(_op)\n  true\nend',4,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(23,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',4,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(24,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',4,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(25,'test','',4,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(26,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    working_plate = Collection.new_collection(C_TYPE)\n    show do\n      title \"Get and Lable Working Plate\"\n      note \"Get a <b>#{C_TYPE}</b> and lable ID: <b>#{working_plate.id}</b>\"\n    end\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(27,'precondition','def precondition(_op)\n  true\nend',5,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(28,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',5,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(29,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',5,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(30,'test','',5,'OperationType','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(31,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\nend',6,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(32,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This includes all moduels that validate workflow parameters at run time\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"RNA_Seq/KeywordLib\"\n\nmodule WorkflowValidation\n  include CommonInputOutputNames, KeywordLib\n\n  \n  \n  #Validates that total inputs (from all operations)\n  #Ensures that all inputs doesnt exeed max inputs\n  #\n  # @operations OperationList list of all operations in the job\n  # @inputs_match_outputs Boolean if the number of inputs should match the number of outputs set as true\n  def validate_inputs(operations, inputs_match_outputs = false)\n    total_inputs = []\n    total_outputs = []\n    operations.each do |op|\n      total_inputs = total_inputs + op.input_array(INPUT_ARRAY).map!{|fv| fv.sample}\n      total_outputs = total_outputs + op.output_array(OUTPUT_ARRAY).map!{|fv| fv.sample}\n    end\n\n    a = total_inputs.detect{ |sample| total_inputs.count(sample) > 1}\n    raise \"Sample #{a.id} has been included multiple times in this job\" if a != nil\n    raise \"The number of Input Samples and Output \n            Samples do not match\" if total_inputs.length != total_outputs.length && inputs_match_outputs\n    raise \"Too many samples for this job. Please re-lauch job with fewer samples\" if total_inputs.length > MAX_INPUTS\n    raise \"There are no samples for this job.\"  if total_inputs.length <= 0\n  end\n\n\n  def validate_concentrations(operations, range)\n    operations.each do |op|\n      op.input_array(INPUT_ARRAY).each do |fv|\n        conc = fv.item.get(CON_KEY)\n        raise \"Sample #{fv.sample.id} doesn\'t have a valid concentration for this operation\"if !range.cover? conc\n      end\n    end\n  end\n\n  def validate_cdna_qc(operations)\n    operations.each do |op|\n      op.input_array(INPUT_ARRAY).each do |fv|\n        qc = fv.item.get(QC2_KEY)\n        raise \"Item #{fv.item.id} doesn\'t have a valid C-DNA QC\" if qc != \"Pass\"\n      end\n    end\n  end\n  \n  \nend',7,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(33,'source','# frozen_string_literal: true\n\n# Module with methods and classes that seek to help with associating data\n# to, and retrieving data from, items, operations, plans, collections, and parts.\n#\nmodule AssociationManagement\n  require \'matrix\'\n\n  # Associates a key and value to the associations hash of the given object.\n  # Replaces an existing association for the given key.\n  #\n  # A part may be represented as a part item, or a collection and coordinate.\n  #\n  # @param object [DataAssociator]  the object to associate data\n  # @param key [String]  the key for the association\n  # @param data [serializable object]  the data for the association\n  # @param opts [Hash]  additional method options\n  # @option coord [Array]  row, column pair if the object is a collection\n  # @option data_matrix [String]  optional data matrix for a collection\n  def associate_data(object, key, data, opts = {})\n    AssociationMap.associate_data(object, key, data, opts)\n  end\n\n  # Returns the associated value from the associations hash of a given object.\n  # If an association doesn\'t exist for the key, returns nil.\n  #\n  # @param object [DataAssociator]  the object to associated data\n  # @param key [String]  the key for the association\n  # @param opts [Hash]  additional method options\n  # @option coord [tuple Array]  row, column of part if object is a collection.\n  # @option data_matrix [String]  optional data matrix\n  # @return [serializable object]  the value associated with the given key\n  def get_associated_data(object, key, opts = {})\n    AssociationMap.get_associated_data(object, key, opts)\n  end\n\n  # Defines a map to manage the associations for an {Item}, {Operation}, or\n  # {Plan} object, which are Aquarium classes that extend {DataAssociator}.\n  #\n  # Note: if `map` contains associations, it is necessary to call `map.save` for\n  #       the associations to be saved to Aquarium.\n  #\n  class AssociationMap\n    DATAMATRIX_KEY = \'part_data\'\n\n    # Initializes an {AssociationMap} for the given item, operation, or plan.\n    #\n    # @param object [DataAssociator]  the object to which to associated data\n    def initialize(object)\n      @object = object\n      @map = {}\n\n      @object.associations.each do |datum|\n        @map[datum[0]] =\n          if @object.upload(datum[0]).nil?\n            datum[1]\n          else\n            UploadAssoc.new(datum[1], @object.upload(datum[0]))\n          end\n      end\n\n      if object.is_a? Collection\n        initialize_part_data\n        data_matrix_all(@object, @map[DATAMATRIX_KEY])\n      end\n    end\n\n    # Retrieves part_data from the data associations of constituent parts.\n    # achieves forward compatibility with AQ Part update\n    def data_matrix_all(coll, data_matrix)\n      pas = coll.part_associations\n      part_ids = pas.collect(&:part_id)\n      das = DataAssociation.where(parent_class: \'Item\', parent_id: part_ids)\n      pas.each do |pa|\n        data_matrix[pa.row][pa.column] = {}\n        das.select { |da| da.parent_id == pa.part_id }.each do |da|\n          data_matrix[pa.row][pa.column][da.key] = da.value\n        end\n      end\n      data_matrix\n    end\n\n    # All in one static method which associates a key and value\n    # to the associations hash of a given object. If an association already\n    # exists at the given key, it will be replaced. Can associate to parts of collection either\n    # using a part field value, or an optional coordinate specification with a collection\n    #\n    # @param object [DataAssociator]  the object to which data is to be associated. Can be an io field value\n    # @param key [String]  the key for the association\n    # @param data [serializable object]  the data for the association\n    # @param opts [Hash]  additional method options\n    # @option coord [tuple Array]  specify r, c index of the data matrix of the object to upload to,\n    #                   rather than directly to the object. Requires that object is a collection.\n    # @option data_matrix [String]  optionally, when associating to a part of a collection, use a\n    #                         data matrix besides the default one\n    def self.associate_data(object, key, data, opts = {})\n      defaults = { data_matrix: DATAMATRIX_KEY }\n      opts.merge defaults\n      raise \'Bad Arguments: cannot associate to a part and specify coords at the same time\' if object.is_a?(FieldValue) && opts[:coord]\n      if object.is_a?(FieldValue)\n        assoc_map = AssociationMap.new(object.collection)\n        assoc_map.putrc(object.row, object.column, key, data)\n      elsif opts[:coord]\n        assoc_map = AssociationMap.new(object)\n        assoc_map.putrc(opts[:coord][0], opts[:coord][1], key, data)\n      else # Normal case that deals directly with object\n        assoc_map = AssociationMap.new(object)\n        assoc_map.put(key, data)\n      end\n      assoc_map.save\n    end\n\n    # All in one static method which gets an associated value\n    # from the associations hash of a given object. If an association doesn\'t\n    # exist at the given key, returns nil. Can get associations from parts of collection either\n    # using a part field value, or an optional coordinate specification with a collection\n    #\n    # @param object [DataAssociator]  the object to which data is to be associated, can be an io field value\n    # @param key [String]  the key for the association\n    # @param opts [Hash]  additional method options\n    # @option coord [tuple Array]  specify r, c index of the data matrix of the object to upload to,\n    #                   rather than directly to the object. Requires that object is a collection.\n    # @option data_matrix [String]  optionally, when retrieving association from a part of a collection,\n    #                         use a matrix besides the default one\n    # @return [serializable object]  the data stored in the associations of the given object at the given key\n    def self.get_associated_data(object, key, opts = {})\n      defaults = { data_matrix: DATAMATRIX_KEY }\n      opts.merge defaults\n      raise \'Bad Arguments: cannot get data from a part and specify coords at the same time\' if object.is_a?(FieldValue) && opts[:coord]\n      if object.is_a?(FieldValue)\n        assoc_map = AssociationMap.new(object.collection)\n        return assoc_map.getrc(object.row, object.column, key)\n      elsif opts[:coord]\n        assoc_map = AssociationMap.new(object)\n        return assoc_map.getrc(opts[:coord][0], opts[:coord][1], key)\n      else # Normal case that deals directly with object\n        assoc_map = AssociationMap.new(object)\n        return assoc_map.get(key)\n      end\n    end\n\n    # Adds an association for the data with the key.\n    # The data must be serializable.\n    #\n    # @param key [String]  the key for the association\n    # @param data [serializable object]  the data for the association\n    # @param opts [Hash]  Additional Options\n    # @option tag  [String]  If putting an Upload, optionally specify an extra label\n    def put(key, data, opts = { tag: {} })\n      @map[key] = if data.is_a?(Upload)\n                    UploadAssoc.new(opts[:tag], data)\n                  else\n                    data\n                  end\n    end\n\n    # Adds an association for the data with the key, for\n    # a specific row, column coordinate within a collection\n    # If the data_matrix for the collection has not been created yet, it is initialized\n    #\n    # @requires  current object is a Collection, and r,c corresponds to a valid location in the object\n    # @param r [Integer]  the row of the part within the collection to associate to\n    # @param c [Integer]  the column of the part within the collection to associate to\n    # @param key [String]  the key for the association\n    # @param data [serializable object]  the data for the association\n    # @param data_matrix [String/Symbol]  optionally specify a data matrix to access besides the default one,\n    #                         for example, you might have the default part data, alongside a routing matrix\n    def putrc(row, column, key, data, data_matrix = DATAMATRIX_KEY)\n      # if the data_matrix for this collection does not exist yet, initialize it.\n      initialize_part_data(data_matrix)\n      @map[data_matrix][row][column][key] = data\n    end\n\n    # To be called when the object of association is a collection,\n    # establishes a matrix parallel to the sample matrix which can\n    # be used to store additional information about individual parts\n    # Each slot in the matrix will be a new empty hash.\n    #\n    # @param coll [Collection]  the object for which part-data matrix will be initialized\n    # @param data_matrix [String/Symbol]  optionally specify a data matrix to access besides the default one,\n    #                         for example, you might have the default part data, alongside a routing matrix\n    def initialize_part_data(data_matrix = DATAMATRIX_KEY)\n      raise \"Invalid Method Call: cannot associate part data to an object that isn\'t a collection\" unless @object.is_a?(Collection)\n      # TODO: fix the following so that can use the Base method\n      # coll = collection_from(@object.id)\n      coll = Collection.find(@object.id)\n      @map[data_matrix] = Array.new(coll.dimensions[0]) { Array.new(coll.dimensions[1]) { {} } } if @map[data_matrix].nil?\n    end\n\n    # Returns the associated data for the key, if any.\n    #\n    # @param key [String]  the key for the association\n    # @returns the data object for the key, `nil` otherwise\n    def get(key)\n      data = @map[key]\n      if data.is_a?(UploadAssoc)\n        data.upload\n      else\n        data\n      end\n    end\n\n    # Gets an association for the data with the key, for\n    # a specific row, column coordinate within a collection\n    # Returns the associated data for the key, if any.\n    #\n    # @requires  current object is a Collection, and r,c corresponds to a valid location in the object\n    # @param r [Integer]  the row of the part within the collection to associate to\n    # @param c [Integer]  the column of the part within the collection to associate to\n    # @param key [String]  the key for the association\n    # @param data_matrix [String/Symbol]  optionally specify a data matrix to access besides the default one,\n    #                         for example, you might have the default part data, alongside a routing matrix\n    # @returns the data object for the key, `nil` otherwise\n    def getrc(row, column, key, data_matrix = DATAMATRIX_KEY)\n      @map[data_matrix][row][column][key] unless @map[data_matrix].nil?\n    end\n\n    # Retrieve the associations for all parts of the collection\n    # as a matrix.\n    # @requires  current object is a collection\n    # @param data_matrix [String/Symbol]  optionally specify a data matrix to access besides the default one,\n    #                         for example, you might have the default part data, alongside a routing matrix\n    # @returns  the data matrix, if one exists\n    def get_data_matrix(data_matrix = DATAMATRIX_KEY)\n      Matrix.rows(@map[data_matrix])\n    end\n\n    # Replace or initialize the data matrix for this object\n    # with a custom one.\n    # @requires  the current object is a collection\n    # `matrix` have the same row column dimensions as the collection\n    #\n    # @param new_matrix [Matrix]  the new data matrix\n    # @param data_matrix [String/Symbol]  optionally specify a data matrix (by key) to access besides the default one,\n    #                         for example, you might have the default part data, alongside a routing matrix\n\n    def set_data_matrix(matrix, data_matrix = DATAMATRIX_KEY)\n      @map[data_matrix] = matrix.to_a\n    end\n\n    # Saves the associations in this map to Aquarium.\n    def save\n      das = []\n      @map.each_key do |key|\n        if key == DATAMATRIX_KEY\n          das.concat save_data_matrix_alt(@object, @map[key])\n        elsif @map[key].is_a? UploadAssoc\n          # TODO: update this to lazy associate once aq is updated to hav lazy upload assoc (on master, just not on server yet)\n          @object.associate(key, @map[key].tag, @map[key].upload)\n        else\n          das << @object.lazy_associate(key, @map[key])\n        end\n      end\n      DataAssociation.import(das, on_duplicate_key_update: [:object]) unless das.empty?\n      @object.save\n      nil\n    end\n\n    # saves part_data to the data associations of constituent parts.\n    # achieves forward compatibility with AQ Part update\n    # built off of set_data_matrix from collection.rb\n    def save_data_matrix_alt(coll, matrix, offset: [0, 0])\n      pm = coll.part_matrix\n      das = []\n\n      uniq_keys = matrix.flatten.map(&:keys).flatten.uniq\n      dms_by_key = {}\n      uniq_keys.each do |key|\n        dms_by_key[key] = coll.data_matrix(key)\n      end\n\n      coll.each_row_col(matrix, offset: offset) do |x, y, ox, oy|\n        next unless !matrix[x][y].nil? && pm[ox][oy] # this part has das\n        matrix[x][y].each do |k, v|\n          if pm[ox][oy]\n            if dms_by_key[k][ox][oy]\n              da = dms_by_key[k][ox][oy]\n              da.object = { k => v }.to_json\n              das << da\n            else\n              das << pm[ox][oy].lazy_associate(k, v)\n            end\n          end\n        end\n      end\n\n      das\n    end\n\n    # Returns an array of all the keys in this map\n    def keys\n      @map.keys\n    end\n\n    # Returns the string representation of the map\n    def to_string\n      @map.to_s\n    end\n\n    alias to_s to_string\n  end\n\n  # private class that is used to deal with associating upload objects alongside their tag\n  class UploadAssoc\n    def initialize(tag, upload)\n      @upload = upload\n      @tag = tag || {}\n    end\n\n    def change_tag(new_tag)\n      @tag = new_tag\n    end\n\n    attr_reader :upload\n\n    attr_reader :tag\n  end\n\n  # Utilizes the part-data matrix of collections to store information about the history of\n  # parts of a collection. PartProvenance initializes and relies on two fields of every part-data\n  # slot: `source` and `destination`.\n  # `source` will store a list of item ids (with rc index if applicable),\n  # of all the ingredients used to make this part, and destination will use the same data format\n  # to record all of the places this part was used in.\n  # Item-Item provenance can technically be recorded as well with this library, but it will not\n  # be necessary.\n  #\n  module PartProvenance\n    SOURCE = \'source\'\n    DESTINATION = \'destination\'\n\n    # Record an entry to the provenance data between two parts, or a part and an item.\n    # This will populate the destination field of `from`, and the source field\n    # of the `to` in their respective associations. If from_coord or to_coord is specified, then\n    # the associations of the part of the from/to collection at that coordinate will\n    # populated instead.\n    #\n    # @param opts [Hash]  Arguments specifying which objects to record relation for\n    # @option from [Item/Collection]  the item or collection where sample transfer originated\n    # @option to [Item/Collection]  the item or collection for destination of sample transfer\n    # @option from_coord [Tuple Array]  optionally, specify the coordinate selecting a part of the collection, if `to` was a collection\n    # @option to_coord [Tuple Array]  optionally, specify the coordinate selecting a part of the collection, if `from` was a collection\n    # @option additional_relation_data [Hash]  optionally, add additional key/value pairs to add to both object\'s routing data\n    #                         for this relation. For example, you might want to specify the volume of the transfer,\n    #                         or which colony was picked from a plate\n    # @option from_map [AssociationMap]  existing AssociationMap for the given from-object, required to successfully associate provenance to\n    #                           the `from` item\n    # @option to_map [AssociationMap]  existing AssociationMap for the given to-object, required to successfully associate provenance to\n    #                           the `to` item\n    def add_provenance(opts = {})\n      if opts[:from] == opts[:to] # special case: provenance between two parts on the same collection\n        opts[:from_map] = opts[:to_map] # ensure from map and to map are the same object for this case\n      end\n\n      # creating information hashes to represent `from` and `to` relationship data\n      from_info = serialize_as_simple_tag(opts[:from], opts[:from_coord], opts[:additional_relation_data])\n      to_info = serialize_as_simple_tag(opts[:to], opts[:to_coord], opts[:additional_relation_data])\n\n      # in destination field of `from`, add information tag representing `to`\n      append_to_association(opts[:from_map], DESTINATION, to_info, coord: opts[:from_coord]) if opts[:from_map]\n\n      # in source field of `to`, add information tag representing `from`\n      append_to_association(opts[:to_map], SOURCE, from_info, coord: opts[:to_coord]) if opts[:to_map]\n    end\n\n    # Retrieves a list of sources that were used to construct the given part\n    # of a Collection\n    #\n    # @param object [FieldValue/Collection]  the part of interest, or the collection which\n    #                 contains the part of interest. For the second case, coord must also be specified\n    # @param coord [Tuple Array]  the r,c index of the target part\n    def sources(object, coord = nil)\n      if coord\n        AssociationMap.get_associated_data(object, SOURCE, coord: coord)\n      else\n        AssociationMap.get_associated_data(object, SOURCE)\n      end\n    end\n\n    # Retrieves a list of destinations that were made using the given part\n    # of a Collection\n    #\n    # @param object [FieldValue/Collection]  the part of interest, or the collection which\n    #                 contains the part of interest. For the second case, coord must also be specified\n    # @param coord [Tuple Array]  the r,c index of the target part\n    def destinations(object, coord = nil)\n      if coord\n        AssociationMap.get_associated_data(object, DESTINATION, coord: opts[:coord])\n      else\n        AssociationMap.get_associated_data(object, DESTINATION)\n      end\n    end\n\n    # For the given associatable target object, appends or concatenates the given datum_to_append to the association\n    # at `key` for that object\n    #\n    # @param association_map [AssocioationMap]  an AssociationMap that will have its associations appended to.\n    # @param key [String/Symbol]  The association key which maps to an appendable object\n    # @param datum_to_append [Serializable Object]  the element to append to the list at the value for the given key\n    # @param opts [Hash]  additional options\n    # @option coord [Tuple array]  coordinate of target part, if association target is a collection\n    def append_to_association(association_map, key, datum_to_append, opts = {})\n      if opts[:coord] # we will be interacting with the associations of a part of a collection if coord is specified\n        association_map.putrc(opts[:coord][0], opts[:coord][1], key, []) if association_map.getrc(opts[:coord][0], opts[:coord][1], key).nil?\n        association_map.getrc(opts[:coord][0], opts[:coord][1], key) <<  datum_to_append\n      else\n        association_map.put(key, []) if association_map.get(key).nil?\n        association_map.get(key) << datum_to_append\n      end\n    end\n\n    # Given an item, or a part of a collection, serializes it into a simple tag which can be used to retrieve it.\n    #\n    # @param item [Item/FieldValue]  can be either an Item, or\n    #                         an i/o object corresponding to a part of a collection, which can be thought of\n    #                         as constituting a \'sub item\'\n    def serialize_as_simple_tag(item, coord, additional_info)\n      info = if item.collection? && coord\n               { id: item.id, row: coord[0], column: coord[1] }\n             elsif (item.is_a? Item) || (item.is_a? Collection)\n               { id: item.id }\n             else\n               raise \'Argument is neither a part nor an item\'\n             end\n      info.merge!(additional_info) unless additional_info.nil?\n      info\n    end\n  end\nend\n',8,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(34,'source','module CommonInputOutputNames\n\n    INPUT_YEAST = \'Yeast Culture\'\n    OUTPUT_YEAST = \'Yeast Culture\'\n    MEDIA = \'Media\'\n    DNA = \'DNA\'\n    \n    INPUT_SAMPLE = \'Input Sample\'\n    OUTPUT_SAMPLE = \'Output Sample\'\n\n    INPUT_ARRAY = \"Input Array\"\n    OUTPUT_ARRAY = \"Output Array\"\n\n    FORWARD_PRIMER = \'Forward Primer\'\n    REVERSE_PRIMER = \'Reverse Primer\'\n    TEMPLATE = \'Template\'\n    FRAGMENT = \'Fragment\'\n    PROGRAM = \'Program\'\n    PRIMER_PLATE = \'96-Well Primer Aliquot Plate\'\n\nend',9,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(35,'source','module Debug\n  def print_object obj\n    if [Numeric, String].any? { |c| obj.is_a? c }\n      obj\n    elsif [Array].any? { |c| obj.is_a? c }\n      obj.map { |item| print_object item }\n    elsif [Hash].any? { |c| obj.is_a? c }\n      Hash[obj.map { |k, v| [k, print_object(v)] }]\n    else\n      s = obj ? obj.id.to_s : \"\"\n      s += \" #{obj.name}\" if obj.class.method_defined? :name\n      s\n    end\n  end\n\n  def log_info *args\n    if debug\n      show do\n        title \"Debug slide (#{args.length} #{\"arg\".pluralize args.length})\"\n\n        args.each do |arg|\n          note \"#{arg.class}: #{print_object arg}\"\n        end\n      end\n    end\n  end\n\n    def inspect(object, ident=nil)\n        show do\n            title \"<span style=\\\"background-color:yellow\\\">INSPECTING #{ident} (#{object.class})</span>\"\n            if object.kind_of?(Array)\n              table object\n            else\n              note object.to_json\n            end\n        end\n    end\nend\n',NULL,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(36,'source','module PlanParams\n\n  # Gets :options from the plan associations and uses it to override default_plan_params\n  #\n  # @return [Hash] plan_params\n  def update_plan_params(plan_params:, opts:)\n    if opts.present?\n      opts = JSON.parse(opts, { symbolize_names: true })\n      plan_params.update(opts)\n    end\n    plan_params\n  end\n\n  #gets the options on the first operaton of a plan\n  def get_opts(operations)\n    operations.first.plan.associations[:options]\n  end\n\n  #gets the options on a specific operation\n  def get_op_opts(op)\n    op.plan.associations[:options]\n  end\n\n  #sets plan params as a temporary association to the operation under the :plan_params key\n  def set_temporary_op_params(op, default_plan_parameters)\n      opts = get_op_opts(op)\n      op.temporary[:plan_params] = update_plan_params(plan_params: default_plan_params, opts: opts)\n  end\n \nend',10,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(37,'source','module Units\n    \n    EMPTY = -1\n    \n    # Volume\n    MICROLITERS = \'ul\'\n    MILLILITERS = \'ml\'\n    \n    # Weight\n    NANOGRAMS = \'ng\'\n    MICROGRAMS = \'g\'\n    \n    # Concentration\n    PICOMOLAR = \'pM\'\n    NANOMOLAR = \'nM\'\n    MICROMOLAR = \'M\'\n    MILLIMOLAR = \'mM\'\n    MOLAR = \'M\'\n    \n    # Temperature\n    DEGREES_C = \'C\'\n    \n    # Time\n    MINUTES = \'min\'\n    SECONDS = \'sec\'\n    HOURS =\'hr\'\n    # Force\n    TIMES_G = \'x g\'\n    \n    # R/DNA Length\n    BASEPAIRS = \'bp\'\n    KILOBASEPAIRS = \'kbp\'\n    MEGABASEPAIRS = \'mbp\'\n    GIGABASEPAIRS = \'gbp\'\n    \n    # Voltage\n    VOLTS = \'V\'\n\n    def self.qty_display(qty)\n        \"#{qty[:qty]} #{qty[:units]}\"\n    end\n    \n    def qty_display(qty)\n        \"#{qty[:qty]} #{qty[:units]}\"\n    end\n    \n    def add_qty_display(options)\n        new_items = {}\n        \n        options.each do |key, value|\n            key =~ /^(.+_)+([a-z]+)$/\n            \n            case $2\n            when \'microliters\'\n                units = MICROLITERS\n            when \'milliliters\'\n                units = MILLILITERS\n            when \'minutes\'\n                units = MINUTES\n            else\n                next\n            end\n            \n            qty = value.to_f\n            \n            new_items[\"#{$1}qty\".to_sym] = { qty: qty, units: units }\n        end\n        \n        options.update(new_items)\n    end\n    \n    # Return the unit constant for the the unit name if there is one.\n    #\n    # @param unit_name [String] the name of the unit\n    # @returns the value of the constant with the given name\n    # @raises BadUnitNameError if the name is not the name of a defined unit\n    def self.get_unit(unit_name:)\n        self.const_get(unit_name.upcase)\n      rescue\n        raise BadUnitNameError.new(name: unit_name)\n    end\n    \n    # Exception class for bad unit name arguments to Units::get_unit.\n    #\n    # @attr_reader [String] name  the bad unit name\n    class BadUnitNameError < StandardError\n        attr_reader :name\n        \n        def initialize(msg: \"Unknown unit name\", name:)\n            @name = name\n            super(msg)\n        end\n    end\n    \n    # Return a key for the measure hash defined on the given object type.\n    #\n    # The measure hash must be defined in the data proerty of the object type as JSON.\n    # For instance\n    #\n    #   { \"measure\": { \"type\": \"concentration\", \"unit\": \"micromolar\" } }\n    #\n    # The key is constructed as the type name, an underscore, and the unit name.\n    #\n    # @param object_type [ObjectType] the object type\n    # @returns the key for the measure of the the object type if there is one\n    # @raises MissingObjectTypeMeasure if the object type has no measure data_object\n    def self.get_measure_key(object_type:)\n        data_object = object_type.data_object\n        raise MissingObjectTypeMeasureError.new(name: object_type.name) if !data_object.key?(:measure)\n        \n        measure = object_type.data_object[:measure]\n        type_name = measure[:type]\n        unit_name = measure[:unit]\n        \"#{type_name}_#{self.get_unit(unit_name: unit_name)}\"\n    end\n    \n    # Exception class for an object type with out a measure hash definition.\n    #\n    # @attr_reader [String] name  the name of the object type where measure has was expected\n    class MissingObjectTypeMeasureError < StandardError\n        attr_reader :name\n        \n        def initialize(msg: \"ObjectType has no measure in data object\", name:)\n            @name = name\n            super(msg)\n        end\n    end\n   \nend',11,'Library','2020-03-19 17:30:41','2020-03-19 17:30:41',1),(38,'protocol','# frozen_string_literal: true\n\n# This is a default, one-size-fits all protocol that shows how you can\n# access the inputs and outputs of the operations associated with a job.\n# Add specific instructions for this protocol!\n\nclass Protocol\n\n  def main\n\n    operations.retrieve.make\n\n    tin  = operations.io_table \'input\'\n    tout = operations.io_table \'output\'\n\n    show do\n      title \'Input Table\'\n      table tin.all.render\n    end\n\n    show do\n      title \'Output Table\'\n      table tout.all.render\n    end\n\n    operations.store\n\n    {}\n\n  end\n\nend\n',6,'OperationType','2020-03-19 19:32:57','2020-03-19 19:32:57',1),(39,'precondition','def precondition(_op)\n  true\nend',6,'OperationType','2020-03-19 19:32:57','2020-03-19 19:32:57',1),(40,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',6,'OperationType','2020-03-19 19:32:57','2020-03-19 19:32:57',1),(41,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',6,'OperationType','2020-03-19 19:32:57','2020-03-19 19:32:57',1),(42,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV = \"csv\"\n\nend',6,'Library','2020-03-19 19:53:50','2020-03-19 19:53:50',1),(43,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV = \"csv\"\n\nend',6,'Library','2020-03-19 19:53:50','2020-03-19 19:53:50',1),(44,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV = \"csv\"\n\nend',6,'Library','2020-03-19 19:53:50','2020-03-19 19:53:50',1),(45,'protocol','needs \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #transfer items properly to plate\n\n  end\n\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 19:53:53','2020-03-19 19:53:53',1),(46,'protocol','needs \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #transfer items properly to plate\n\n  end\n\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 19:53:53','2020-03-19 19:53:53',1),(47,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload if debug\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"#{op.get(CSV.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:01:14','2020-03-19 20:01:14',1),(48,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload if debug\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"#{op.get(CSV.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:01:14','2020-03-19 20:01:14',1),(49,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload if debug\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:01:28','2020-03-19 20:01:28',1),(50,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload if debug\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:01:29','2020-03-19 20:01:29',1),(51,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload if true\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:01:42','2020-03-19 20:01:42',1),(52,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload if true\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV.to_sym\n      end\n      op.associate(CSV.to_sym, up_csv.get_response(CSV.to_sym))\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:01:42','2020-03-19 20:01:42',1),(53,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        Title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:33:30','2020-03-19 20:33:30',1),(54,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        Title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:33:30','2020-03-19 20:33:30',1),(55,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\nend',6,'Library','2020-03-19 20:33:30','2020-03-19 20:33:30',1),(56,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\nend',6,'Library','2020-03-19 20:33:31','2020-03-19 20:33:31',1),(57,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  #include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        Title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:35:06','2020-03-19 20:35:06',1),(58,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  #include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        Title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:35:06','2020-03-19 20:35:06',1),(59,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  #include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:36:09','2020-03-19 20:36:09',1),(60,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  #include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:36:10','2020-03-19 20:36:10',1),(61,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib\n  #include CSV\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:36:10','2020-03-19 20:36:10',1),(62,'source','# Library code here',12,'Library','2020-03-19 20:47:48','2020-03-19 20:47:48',1),(63,'source','module CSV_DEBUG_LIB\n    CSV_DEBUG = \"Plate ID, Well Location\n    100, A1\n    100, B1\n    100, C1\n    100, D1\n    100, E1\n    100, F1\n    100, G1\n    100, A2\n    100, B2\n    100, C2\n    100, D2\n    100, E2\n    100, F2\n    100, G2\n    100, A3\n    100, B3\n    100, C3\n    100, D3\n    100, E3\n    100, F3\n    100, G3\"\n    \nend',12,'Library','2020-03-19 20:52:36','2020-03-19 20:52:36',1),(64,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID, Well Location\n    100, A1\n    100, B1\n    100, C1\n    100, D1\n    100, E1\n    100, F1\n    100, G1\n    100, A2\n    100, B2\n    100, C2\n    100, D2\n    100, E2\n    100, F2\n    100, G2\n    100, A3\n    100, B3\n    100, C3\n    100, D3\n    100, E3\n    100, F3\n    100, G3\"\nend',12,'Library','2020-03-19 20:53:32','2020-03-19 20:53:32',1),(65,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:53:50','2020-03-19 20:53:50',1),(66,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:53:50','2020-03-19 20:53:50',1),(67,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = op.get(CSV_KEY.to_sym)\n        csv.open\n        csv.read\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:53:50','2020-03-19 20:53:50',1),(68,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:55:56','2020-03-19 20:55:56',1),(69,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:55:56','2020-03-19 20:55:56',1),(70,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\nend',6,'Library','2020-03-19 20:55:58','2020-03-19 20:55:58',1),(71,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\nend',6,'Library','2020-03-19 20:55:58','2020-03-19 20:55:58',1),(72,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\n#needs \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:56:16','2020-03-19 20:56:16',1),(73,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\n#needs \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:56:16','2020-03-19 20:56:16',1),(74,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\n#needs \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\n#needs \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:56:26','2020-03-19 20:56:26',1),(75,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\n#needs \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\n#needs \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:56:27','2020-03-19 20:56:27',1),(76,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\n#needs \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\n#needs \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:56:54','2020-03-19 20:56:54',1),(77,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\n#needs \"Standard Libs/UploadHelper\"\nneeds \"Standard Libs/Debug\"\n#needs \"Standard Libs/MatrixTools\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CS_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:56:54','2020-03-19 20:56:54',1),(78,'source','module \n    CSV_DEBUG = \"Plate ID, Well Location\n    100, A1\n    100, B1\n    100, C1\n    100, D1\n    100, E1\n    100, F1\n    100, G1\n    100, A2\n    100, B2\n    100, C2\n    100, D2\n    100, E2\n    100, F2\n    100, G2\n    100, A3\n    100, B3\n    100, C3\n    100, D3\n    100, E3\n    100, F3\n    100, G3\"\nend',12,'Library','2020-03-19 20:57:33','2020-03-19 20:57:33',1),(79,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID, Well Location\n    100, A1\n    100, B1\n    100, C1\n    100, D1\n    100, E1\n    100, F1\n    100, G1\n    100, A2\n    100, B2\n    100, C2\n    100, D2\n    100, E2\n    100, F2\n    100, G2\n    100, A3\n    100, B3\n    100, C3\n    100, D3\n    100, E3\n    100, F3\n    100, G3\"\nend',12,'Library','2020-03-19 20:58:17','2020-03-19 20:58:17',1),(80,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:58:41','2020-03-19 20:58:41',1),(81,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, W)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:58:41','2020-03-19 20:58:41',1),(82,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:59:17','2020-03-19 20:59:17',1),(83,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-19 20:59:17','2020-03-19 20:59:17',1),(84,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:07:09','2020-03-20 03:07:09',1),(85,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:07:09','2020-03-20 03:07:09',1),(86,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:07:10','2020-03-20 03:07:10',1),(87,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:09:31','2020-03-20 03:09:31',1),(88,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:09:31','2020-03-20 03:09:31',1),(89,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:15:02','2020-03-20 03:15:02',1),(90,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:15:03','2020-03-20 03:15:03',1),(91,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n  require \'csv\'\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:17:17','2020-03-20 03:17:17',1),(92,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n  require \'csv\'\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:17:17','2020-03-20 03:17:17',1),(93,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib, CSV\n\n  require \'csv\'\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:17:17','2020-03-20 03:17:17',1),(94,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  require \'csv\'\n\n  def main\n\n    csv = CSV.new()\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:17:30','2020-03-20 03:17:30',1),(95,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  require \'csv\'\n\n  def main\n    \n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:17:45','2020-03-20 03:17:45',1),(96,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  require \'csv\'\n\n  def main\n    \n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:17:45','2020-03-20 03:17:45',1),(97,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n  def main\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:18:34','2020-03-20 03:18:34',1),(98,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n\n  def main\n\n    operations.make\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    test_upload #TODO for debug purposes only\n\n    parse_csv\n\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: Plate Collection ID\"\n        note \"Column 2: Well Location (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def parse_csv\n    operations.each do |op|\n      show do\n        title \"Here are the rows of the CSV\"\n        csv = CSV.parse(op.get(CSV_KEY.to_sym))\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n    end\n  end\n\n\n  #for Debug purposes only\n  #Test to ensure that upload to operation and CSV\n  #looks proper\n  def test_upload\n    show do\n      title \"For debug purposes only\"\n      operations.each do |op|\n        note \"uploaded file: #{op.get(CSV_KEY.to_sym)}\"\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:18:34','2020-03-20 03:18:34',1),(99,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n          collection = Item.find(row[0])\n          inspect collection.id\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:41:42','2020-03-20 03:41:42',1),(100,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n          collection = Item.find(row[0])\n          inspect collection.id\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:41:42','2020-03-20 03:41:42',1),(101,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID, Well Location\n    100, A1\n    100, B1\n    100, C1\n    100, D1\n    100, E1\n    100, F1\n    100, G1\n    100, A2\n    100, B2\n    100, C2\n    100, D2\n    100, E2\n    100, F2\n    100, G2\n    100, A3\n    100, B3\n    100, C3\n    100, D3\n    100, E3\n    100, F3\n    100, G3\"\nend',12,'Library','2020-03-20 03:42:56','2020-03-20 03:42:56',1),(102,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID, Well Location\n    100, A1\n    100, B1\n    100, C1\n    100, D1\n    100, E1\n    100, F1\n    100, G1\n    100, A2\n    100, B2\n    100, C2\n    100, D2\n    100, E2\n    100, F2\n    100, G2\n    100, A3\n    100, B3\n    100, C3\n    100, D3\n    100, E3\n    100, F3\n    100, G3\"\nend',12,'Library','2020-03-20 03:42:56','2020-03-20 03:42:56',1),(103,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        collection = Item.find(row[0])\n        inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:43:25','2020-03-20 03:43:25',1),(104,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        collection = Item.find(row[0])\n        inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:43:25','2020-03-20 03:43:25',1),(105,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        collection = Item.find(row[0])\n        inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:43:50','2020-03-20 03:43:50',1),(106,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        collection = Item.find(row[0])\n        inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:43:50','2020-03-20 03:43:50',1),(107,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          #raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        collection = Item.find(row[0])\n        inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:44:02','2020-03-20 03:44:02',1),(108,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          #raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        collection = Item.find(row[0])\n        inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:44:02','2020-03-20 03:44:02',1),(109,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          #raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        #collection = Item.find(row[0])\n        #inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:44:13','2020-03-20 03:44:13',1),(110,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          #raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        end\n        #collection = Item.find(row[0])\n        #inspect collection.id\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:44:14','2020-03-20 03:44:14',1),(111,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          #raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        inspect collection.id\n\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:44:30','2020-03-20 03:44:30',1),(112,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          inspect plate_id\n          inspect well_location\n          #raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        inspect collection.id\n\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:44:30','2020-03-20 03:44:30',1),(113,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID,Well Location\n    100,A1\n    100,B1\n    100,C1\n    100,D1\n    100,E1\n    100,F1\n    100,G1\n    100,A2\n    100,B2\n    100,C2\n    100,D2\n    100,E2\n    100,F2\n    100,G2\n    100,A3\n    100,B3\n    100,C3\n    100,D3\n    100,E3\n    100,F3\n    100,G3\"\nend',12,'Library','2020-03-20 03:45:17','2020-03-20 03:45:17',1),(114,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID,Well Location\n    100,A1\n    100,B1\n    100,C1\n    100,D1\n    100,E1\n    100,F1\n    100,G1\n    100,A2\n    100,B2\n    100,C2\n    100,D2\n    100,E2\n    100,F2\n    100,G2\n    100,A3\n    100,B3\n    100,C3\n    100,D3\n    100,E3\n    100,F3\n    100,G3\"\nend',12,'Library','2020-03-20 03:45:17','2020-03-20 03:45:17',1),(115,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        inspect collection.id\n\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:45:46','2020-03-20 03:45:46',1),(116,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        inspect collection.id\n\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 03:45:46','2020-03-20 03:45:46',1),(117,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        inspect collection.id\n\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:03:25','2020-03-20 04:03:25',1),(118,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        inspect collection.id\n\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:03:25','2020-03-20 04:03:25',1),(119,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        part_alpha_num\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:03:48','2020-03-20 04:03:48',1),(120,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        part_alpha_num\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:03:48','2020-03-20 04:03:48',1),(121,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        part_alpha_num\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:03:48','2020-03-20 04:03:48',1),(122,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        part_alpha_num\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:03:48','2020-03-20 04:03:48',1),(123,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        part_alpha_num(collection, row[1])\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:06:33','2020-03-20 04:06:33',1),(124,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Item.find(row[0])\n        part_alpha_num(collection, row[1])\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:06:33','2020-03-20 04:06:33',1),(125,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    raise \"Location String <b>#{loc}</b> not in valid format (e.g. A1, B1, D2)\"\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_int\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:06:39','2020-03-20 04:06:39',1),(126,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    raise \"Location String <b>#{loc}</b> not in valid format (e.g. A1, B1, D2)\"\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_int\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:06:39','2020-03-20 04:06:39',1),(127,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_int\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:07:20','2020-03-20 04:07:20',1),(128,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_int\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:07:20','2020-03-20 04:07:20',1),(129,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:07:30','2020-03-20 04:07:30',1),(130,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:07:30','2020-03-20 04:07:30',1),(131,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:07:30','2020-03-20 04:07:30',1),(132,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part_alpha_num(collection, row[1])\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:07:52','2020-03-20 04:07:52',1),(133,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part_alpha_num(collection, row[1])\n\n        end\n      end\n\n      \n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:07:52','2020-03-20 04:07:52',1),(134,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect dem\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:08:21','2020-03-20 04:08:21',1),(135,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect dem\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:08:21','2020-03-20 04:08:21',1),(136,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"#{dem}\"\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:08:41','2020-03-20 04:08:41',1),(137,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"#{dem}\"\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:08:41','2020-03-20 04:08:41',1),(138,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"#{dem}\"\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:08:41','2020-03-20 04:08:41',1),(139,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:07','2020-03-20 04:10:07',1),(140,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:07','2020-03-20 04:10:07',1),(141,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    #raise \"Location outside collection dimensions\" if row != dem[0] || col != dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:07','2020-03-20 04:10:07',1),(142,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:43','2020-03-20 04:10:43',1),(143,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:43','2020-03-20 04:10:43',1),(144,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:43','2020-03-20 04:10:43',1),(145,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:50','2020-03-20 04:10:50',1),(146,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:50','2020-03-20 04:10:50',1),(147,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:51','2020-03-20 04:10:51',1),(148,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    inspect \"dem: #{dem}  Loc: #{row},#{col}\"\n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:51','2020-03-20 04:10:51',1),(149,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:52','2020-03-20 04:10:52',1),(150,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:53','2020-03-20 04:10:53',1),(151,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:53','2020-03-20 04:10:53',1),(152,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n\n\n    #return part\n  end\n\nend',5,'Library','2020-03-20 04:10:53','2020-03-20 04:10:53',1),(153,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 04:11:46','2020-03-20 04:11:46',1),(154,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 04:11:46','2020-03-20 04:11:46',1),(155,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 04:11:46','2020-03-20 04:11:46',1),(156,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:12:49','2020-03-20 04:12:49',1),(157,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:12:50','2020-03-20 04:12:50',1),(158,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect parts\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:12:58','2020-03-20 04:12:58',1),(159,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect parts\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:12:58','2020-03-20 04:12:58',1),(160,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect \"#{parts}\"\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:13:13','2020-03-20 04:13:13',1),(161,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect \"#{parts}\"\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n  end\n\nend\n',6,'OperationType','2020-03-20 04:13:13','2020-03-20 04:13:13',1),(162,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect parts\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:32:15','2020-03-20 15:32:15',1),(163,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect \"#{parts.class}\"\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:33:51','2020-03-20 15:33:51',1),(164,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    inspect \"#{parts.class}\"\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:33:52','2020-03-20 15:33:52',1),(165,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:37:26','2020-03-20 15:37:26',1),(166,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:38:29','2020-03-20 15:38:29',1),(167,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:38:29','2020-03-20 15:38:29',1),(168,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:38:29','2020-03-20 15:38:29',1),(169,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 15:51:22','2020-03-20 15:51:22',1),(170,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 15:51:23','2020-03-20 15:51:23',1),(171,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:51:27','2020-03-20 15:51:27',1),(172,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-20 15:52:22','2020-03-20 15:52:22',1),(173,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-20 15:52:23','2020-03-20 15:52:23',1),(174,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-20 15:52:23','2020-03-20 15:52:23',1),(175,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 15:52:24','2020-03-20 15:52:24',1),(176,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 15:52:24','2020-03-20 15:52:24',1),(177,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 15:52:25','2020-03-20 15:52:25',1),(178,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 15:52:26','2020-03-20 15:52:26',1),(179,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 15:52:27','2020-03-20 15:52:27',1),(180,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 15:52:27','2020-03-20 15:52:27',1),(181,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:52:28','2020-03-20 15:52:28',1),(182,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 15:52:28','2020-03-20 15:52:28',1),(183,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    working_plate = Collection.new_collection(C_TYPE)\n    \n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:00:24','2020-03-20 16:00:24',1),(184,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    working_plate = Collection.new_collection(C_TYPE)\n    \n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:00:24','2020-03-20 16:00:24',1),(185,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    workingt_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 16:05:24','2020-03-20 16:05:24',1),(186,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 16:05:34','2020-03-20 16:05:34',1),(187,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 16:05:34','2020-03-20 16:05:34',1),(188,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    working_plate = make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 16:05:38','2020-03-20 16:05:38',1),(189,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 16:05:52','2020-03-20 16:05:52',1),(190,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 16:05:53','2020-03-20 16:05:53',1),(191,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-20 16:06:05','2020-03-20 16:06:05',1),(192,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-20 16:06:05','2020-03-20 16:06:05',1),(193,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:06:11','2020-03-20 16:06:11',1),(194,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #make custom output plate\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:06:11','2020-03-20 16:06:11',1),(195,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} ul from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:06:48','2020-03-20 16:06:48',1),(196,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} ul from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:06:48','2020-03-20 16:06:48',1),(197,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    working_plate = make_new_plate(C_TYPE)\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:16:34','2020-03-20 16:16:34',1),(198,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    parts = sample_from_csv\n\n    parts.each do |part|\n      inspect \"#{part.id}\"\n    end\n\n    working_plate = make_new_plate(C_TYPE)\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:16:34','2020-03-20 16:16:34',1),(199,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:19:31','2020-03-20 16:19:31',1),(200,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:19:31','2020-03-20 16:19:31',1),(201,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:19:31','2020-03-20 16:19:31',1),(202,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:19:54','2020-03-20 16:19:54',1),(203,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:19:54','2020-03-20 16:19:54',1),(204,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:19:55','2020-03-20 16:19:55',1),(205,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:20:12','2020-03-20 16:20:12',1),(206,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:20:13','2020-03-20 16:20:13',1),(207,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| item.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:20:13','2020-03-20 16:20:13',1),(208,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:20:34','2020-03-20 16:20:34',1),(209,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        titile \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:20:34','2020-03-20 16:20:34',1),(210,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Colelction.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:21:26','2020-03-20 16:21:26',1),(211,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Colelction.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:21:26','2020-03-20 16:21:26',1),(212,'source','#Justin Vrana\n#\n#modified by:\n#Cannon Mallory\n#malloc3@uw.edu\n#\n#Modifications include:\n# Documentation (yet to happen)\n#\n# This module is for displaying information about collections in effecient easy to use ways\n#\n# TODO Make the collection displays so that they wont always be checkable cause that gets annoying\nmodule CollectionDisplay\n  def create_collection_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    slots.each_slice(collection.object_type.columns).map do |row|\n      row.map do |col|\n        {content: col, class: \'td-empty-slot\'}\n      end\n    end\n  end\n\n  def highlight tbl, row, col, id\n    tbl[row][col] = {content: id, class: \'td-filled-slot\', check: true}\n  end\n\n  # [r,c,x] list\n  def highlight_rcx(collection, rcx_list)\n    tbl = create_collection_table collection\n    rcx_list.each do |r, c, x|\n      highlight tbl, r, c, x\n    end\n    tbl\n  end\n\n  def highlight_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_rcx collection, rcx_list\n  end\n\n  def highlight_non_empty(collection, &rc_block)\n    highlight_rc collection, collection.get_non_empty, &rc_block\n  end\n\n  def highlight_collection ops, id_block=nil, &fv_block\n    g = ops.group_by { |op| fv_block.call(op).collection }\n    tables = g.map do |collection, grouped_ops|\n      rcx_list = grouped_ops.map do |op|\n        fv = fv_block.call(op)\n        id = id_block.call(op) if id_block\n        id ||= fv.sample.id\n        [fv.row, fv.column, id]\n      end\n      tbl = highlight_rcx collection, rcx_list\n      [collection, tbl]\n    end\n    tables\n  end\n\n  def r_c_to_slot collection, r, c\n    rows, cols = collection.dimensions = collection.object_type.rows\n    r*cols + c+1\n  end\n  \n  \n  \n  \n  def create_alpha_numeric_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    alpha_r = (\'A\'..\'H\').to_a\n    slots.each_slice(collection.object_type.columns).each_with_index.map do |row, r_idx|\n      row.each_with_index.map do |col, c_idx|\n        {content: \"#{alpha_r[r_idx]}#{c_idx + 1}\", class: \'td-empty-slot\'}\n      end\n    end\n  end\n  \n  def highlight_alpha_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_alpha_rcx(collection, rcx_list)\n  end\n  \n  def highlight_alpha_rcx(collection, rcx_list)\n     tbl = create_alpha_numeric_table(collection)\n     rcx_list.each do |r, c, x|\n         highlight tbl, r, c, x\n     end\n     return tbl\n  end\n\n  def highlight_alpha_non_empty collection, &rc_block\n    highlight_alpha_rc collection, collection.get_non_empty, &rc_block\n  end\n      \nend',3,'Library','2020-03-20 16:21:27','2020-03-20 16:21:27',1),(213,'source','#Justin Vrana\n#\n#modified by:\n#Cannon Mallory\n#malloc3@uw.edu\n#\n#Modifications include:\n# Documentation (yet to happen)\n#\n# This module is for displaying information about collections in effecient easy to use ways\n#\n# TODO Make the collection displays so that they wont always be checkable cause that gets annoying\nmodule CollectionDisplay\n  def create_collection_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    slots.each_slice(collection.object_type.columns).map do |row|\n      row.map do |col|\n        {content: col, class: \'td-empty-slot\'}\n      end\n    end\n  end\n\n  def highlight tbl, row, col, id\n    tbl[row][col] = {content: id, class: \'td-filled-slot\', check: true}\n  end\n\n  # [r,c,x] list\n  def highlight_rcx(collection, rcx_list)\n    tbl = create_collection_table collection\n    rcx_list.each do |r, c, x|\n      highlight tbl, r, c, x\n    end\n    tbl\n  end\n\n  def highlight_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_rcx collection, rcx_list\n  end\n\n  def highlight_non_empty(collection, &rc_block)\n    highlight_rc collection, collection.get_non_empty, &rc_block\n  end\n\n  def highlight_collection ops, id_block=nil, &fv_block\n    g = ops.group_by { |op| fv_block.call(op).collection }\n    tables = g.map do |collection, grouped_ops|\n      rcx_list = grouped_ops.map do |op|\n        fv = fv_block.call(op)\n        id = id_block.call(op) if id_block\n        id ||= fv.sample.id\n        [fv.row, fv.column, id]\n      end\n      tbl = highlight_rcx collection, rcx_list\n      [collection, tbl]\n    end\n    tables\n  end\n\n  def r_c_to_slot collection, r, c\n    rows, cols = collection.dimensions = collection.object_type.rows\n    r*cols + c+1\n  end\n  \n  \n  \n  \n  def create_alpha_numeric_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    alpha_r = (\'A\'..\'H\').to_a\n    slots.each_slice(collection.object_type.columns).each_with_index.map do |row, r_idx|\n      row.each_with_index.map do |col, c_idx|\n        {content: \"#{alpha_r[r_idx]}#{c_idx + 1}\", class: \'td-empty-slot\'}\n      end\n    end\n  end\n  \n  def highlight_alpha_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_alpha_rcx(collection, rcx_list)\n  end\n  \n  def highlight_alpha_rcx(collection, rcx_list)\n     tbl = create_alpha_numeric_table(collection)\n     rcx_list.each do |r, c, x|\n         highlight tbl, r, c, x\n     end\n     return tbl\n  end\n\n  def highlight_alpha_non_empty collection, &rc_block\n    highlight_alpha_rc collection, collection.get_non_empty, &rc_block\n  end\n      \nend',3,'Library','2020-03-20 16:21:27','2020-03-20 16:21:27',1),(214,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} ul from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:21:28','2020-03-20 16:21:28',1),(215,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} ul from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:21:28','2020-03-20 16:21:28',1),(216,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:21:29','2020-03-20 16:21:29',1),(217,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = collection.find(sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:21:29','2020-03-20 16:21:29',1),(218,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:22:05','2020-03-20 16:22:05',1),(219,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:22:05','2020-03-20 16:22:05',1),(220,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:22:21','2020-03-20 16:22:21',1),(221,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:22:21','2020-03-20 16:22:21',1),(222,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:22:21','2020-03-20 16:22:21',1),(223,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:22:36','2020-03-20 16:22:36',1),(224,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:22:37','2020-03-20 16:22:37',1),(225,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:22:38','2020-03-20 16:22:38',1),(226,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:22:50','2020-03-20 16:22:50',1),(227,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:22:50','2020-03-20 16:22:50',1),(228,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    parts.group_by{|part| part.containing_collection}\n    return parts\n  end\n\nend\n',6,'OperationType','2020-03-20 16:22:50','2020-03-20 16:22:50',1),(229,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:23:23','2020-03-20 16:23:23',1),(230,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:23:23','2020-03-20 16:23:23',1),(231,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      show do\n        title \"Here are the rows of the CSV\"\n        csv.each do |row|\n          note \"#{row}\"\n        end\n      end\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:23:24','2020-03-20 16:23:24',1),(232,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:23:59','2020-03-20 16:23:59',1),(233,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:23:59','2020-03-20 16:23:59',1),(234,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    workingt_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 16:27:31','2020-03-20 16:27:31',1),(235,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    workingt_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 16:27:31','2020-03-20 16:27:31',1),(236,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:27:35','2020-03-20 16:27:35',1),(237,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:27:35','2020-03-20 16:27:35',1),(238,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n\n  needs Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:28:11','2020-03-20 16:28:11',1),(239,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n\n  needs Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:28:12','2020-03-20 16:28:12',1),(240,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:28:13','2020-03-20 16:28:13',1),(241,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:28:14','2020-03-20 16:28:14',1),(242,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Debug\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:28:14','2020-03-20 16:28:14',1),(243,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude Units\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:29:55','2020-03-20 16:29:55',1),(244,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude Units\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:29:56','2020-03-20 16:29:56',1),(245,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude StandardLibs/Units\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:30:10','2020-03-20 16:30:10',1),(246,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude \"StandardLibs/Units\"\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:30:20','2020-03-20 16:30:20',1),(247,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\ninclude \"StandardLibs/Units\"\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:30:20','2020-03-20 16:30:20',1),(248,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:31:52','2020-03-20 16:31:52',1),(249,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:31:53','2020-03-20 16:31:53',1),(250,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:31:58','2020-03-20 16:31:58',1),(251,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = input_collection.find(sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = working_collection.find(sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:31:58','2020-03-20 16:31:58',1),(252,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:32:36','2020-03-20 16:32:36',1),(253,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:32:36','2020-03-20 16:32:36',1),(254,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-20 16:33:29','2020-03-20 16:33:29',1),(255,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 16:33:40','2020-03-20 16:33:40',1),(256,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',4,'OperationType','2020-03-20 16:33:41','2020-03-20 16:33:41',1),(257,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    working_plate = make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 16:33:50','2020-03-20 16:33:50',1),(258,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    working_plate = make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-20 16:33:51','2020-03-20 16:33:51',1),(259,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    workingt_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 16:33:57','2020-03-20 16:33:57',1),(260,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    workingt_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-20 16:33:58','2020-03-20 16:33:58',1),(261,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:50:01','2020-03-20 16:50:01',1),(262,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:50:01','2020-03-20 16:50:01',1),(263,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:50:02','2020-03-20 16:50:02',1),(264,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:51:49','2020-03-20 16:51:49',1),(265,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:51:49','2020-03-20 16:51:49',1),(266,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collectuon, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_plate, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:51:55','2020-03-20 16:51:55',1),(267,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-20 16:52:17','2020-03-20 16:52:17',1),(268,'source','#Justin Vrana\n#\n#modified by:\n#Cannon Mallory\n#malloc3@uw.edu\n#\n#Modifications include:\n# Documentation (yet to happen)\n#\n# This module is for displaying information about collections in effecient easy to use ways\n#\n# TODO Make the collection displays so that they wont always be checkable cause that gets annoying\nmodule CollectionDisplay\n  def create_collection_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    slots.each_slice(collection.object_type.columns).map do |row|\n      row.map do |col|\n        {content: col, class: \'td-empty-slot\'}\n      end\n    end\n  end\n\n  def highlight tbl, row, col, id\n    tbl[row][col] = {content: id, class: \'td-filled-slot\', check: true}\n  end\n\n  # [r,c,x] list\n  def highlight_rcx(collection, rcx_list)\n    tbl = create_collection_table collection\n    rcx_list.each do |r, c, x|\n      highlight tbl, r, c, x\n    end\n    tbl\n  end\n\n  def highlight_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_rcx collection, rcx_list\n  end\n\n  def highlight_non_empty(collection, &rc_block)\n    highlight_rc collection, collection.get_non_empty, &rc_block\n  end\n\n  def highlight_collection ops, id_block=nil, &fv_block\n    g = ops.group_by { |op| fv_block.call(op).collection }\n    tables = g.map do |collection, grouped_ops|\n      rcx_list = grouped_ops.map do |op|\n        fv = fv_block.call(op)\n        id = id_block.call(op) if id_block\n        id ||= fv.sample.id\n        [fv.row, fv.column, id]\n      end\n      tbl = highlight_rcx collection, rcx_list\n      [collection, tbl]\n    end\n    tables\n  end\n\n  def r_c_to_slot collection, r, c\n    rows, cols = collection.dimensions = collection.object_type.rows\n    r*cols + c+1\n  end\n  \n  \n  \n  \n  def create_alpha_numeric_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    alpha_r = (\'A\'..\'H\').to_a\n    slots.each_slice(collection.object_type.columns).each_with_index.map do |row, r_idx|\n      row.each_with_index.map do |col, c_idx|\n        {content: \"#{alpha_r[r_idx]}#{c_idx + 1}\", class: \'td-empty-slot\'}\n      end\n    end\n  end\n  \n  def highlight_alpha_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_alpha_rcx(collection, rcx_list)\n  end\n  \n  def highlight_alpha_rcx(collection, rcx_list)\n     tbl = create_alpha_numeric_table(collection)\n     rcx_list.each do |r, c, x|\n         highlight tbl, r, c, x\n     end\n     return tbl\n  end\n\n  def highlight_alpha_non_empty collection, &rc_block\n    highlight_alpha_rc collection, collection.get_non_empty, &rc_block\n  end\n      \nend',3,'Library','2020-03-20 16:52:18','2020-03-20 16:52:18',1),(269,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collectuon, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_plate, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:52:18','2020-03-20 16:52:18',1),(270,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:52:19','2020-03-20 16:52:19',1),(271,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:52:23','2020-03-20 16:52:23',1),(272,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:52:23','2020-03-20 16:52:23',1),(273,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:52:51','2020-03-20 16:52:51',1),(274,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:52:51','2020-03-20 16:52:51',1),(275,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_plate, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:52:59','2020-03-20 16:52:59',1),(276,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_plate, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:53:00','2020-03-20 16:53:00',1),(277,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:53:36','2020-03-20 16:53:36',1),(278,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:53:36','2020-03-20 16:53:36',1),(279,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 16:53:37','2020-03-20 16:53:37',1),(280,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_plate, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:54:03','2020-03-20 16:54:03',1),(281,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_plate, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-20 16:54:03','2020-03-20 16:54:03',1),(282,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"#{part.class.to_s}\"\n      #raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:54:10','2020-03-20 16:54:10',1),(283,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n    else\n      raise \"#{part.class.to_s}\"\n      #raise \"Part is neither sample nor item\"\n    end\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:54:10','2020-03-20 16:54:10',1),(284,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n      raise \"#{loc}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:55:25','2020-03-20 16:55:25',1),(285,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = input_collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = part.location\n      location_array = [loc]\n      raise \"#{loc}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 16:55:25','2020-03-20 16:55:25',1),(286,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 21:09:43','2020-03-20 21:09:43',1),(287,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 21:09:43','2020-03-20 21:09:43',1),(288,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-20 21:09:43','2020-03-20 21:09:43',1),(289,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{loc}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:09:53','2020-03-20 21:09:53',1),(290,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{loc}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:09:53','2020-03-20 21:09:53',1),(291,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:10:38','2020-03-20 21:10:38',1),(292,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:10:39','2020-03-20 21:10:39',1),(293,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:10:50','2020-03-20 21:10:50',1),(294,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:10:51','2020-03-20 21:10:51',1),(295,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:10:51','2020-03-20 21:10:51',1),(296,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      #location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:11:02','2020-03-20 21:11:02',1),(297,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      #location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:11:02','2020-03-20 21:11:02',1),(298,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      #location_array = [loc]\n      raise \"#{part.class}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-20 21:11:03','2020-03-20 21:11:03',1),(299,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      #location_array = [loc]\n      raise \"#{Sample.find(part.id).id}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 16:56:17','2020-03-23 16:56:17',1),(300,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    if part.class.to_s == \"Sample\"\n      location_array = collection.find(part)\n    elsif part.class.to_s == \"Item\"\n      inspect \"#{part.id}\"\n      raise \"Item #{part.id} is not part of a collection\" unless part.is_part\n      #loc = collection.find(part)\n      #location_array = [loc]\n      raise \"#{Sample.find(part.id).id}\"\n    else\n      raise \"Part is neither sample nor item\"\n    end\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 16:56:17','2020-03-23 16:56:17',1),(301,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample if part.class.to_s == \"Item\"\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:05:38','2020-03-23 17:05:38',1),(302,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample if part.class.to_s == \"Item\"\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:05:38','2020-03-23 17:05:38',1),(303,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample if part.class.to_s == \"Item\"\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:05:38','2020-03-23 17:05:38',1),(304,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample if part.is_part\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:06:22','2020-03-23 17:06:22',1),(305,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample if part.is_part\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:06:22','2020-03-23 17:06:22',1),(306,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample if part.is_part\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:06:22','2020-03-23 17:06:22',1),(307,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample #if part.is_part\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:06:58','2020-03-23 17:06:58',1),(308,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample #if part.is_part\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:06:59','2020-03-23 17:06:59',1),(309,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample #if part.is_part\n    raise \"#{part.class}\"\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:07:28','2020-03-23 17:07:28',1),(310,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample #if part.is_part\n    raise \"#{part.class}\"\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:07:28','2020-03-23 17:07:28',1),(311,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    part = part.sample #if part.is_part\n    #raise \"#{part.class}\"\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:07:44','2020-03-23 17:07:44',1),(312,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    raise \"#{thing.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:09:00','2020-03-23 17:09:00',1),(313,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    raise \"#{thing.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:09:01','2020-03-23 17:09:01',1),(314,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:09:10','2020-03-23 17:09:10',1),(315,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:09:10','2020-03-23 17:09:10',1),(316,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    raise \"#{collection.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:09:31','2020-03-23 17:09:31',1),(317,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    raise \"#{collection.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:09:31','2020-03-23 17:09:31',1),(318,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    raise \"#{collection.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:11:49','2020-03-23 17:11:49',1),(319,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    raise \"#{collection.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:11:49','2020-03-23 17:11:49',1),(320,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    raise \"#{collection.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:11:58','2020-03-23 17:11:58',1),(321,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    #raise \"#{thing.class}\"\n    raise \"#{collection.class}\"\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 17:11:59','2020-03-23 17:11:59',1),(322,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:12:13','2020-03-23 17:12:13',1),(323,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:12:13','2020-03-23 17:12:13',1),(324,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:12:17','2020-03-23 17:12:17',1),(325,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:12:18','2020-03-23 17:12:18',1),(326,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:23:54','2020-03-23 17:23:54',1),(327,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:23:54','2020-03-23 17:23:54',1),(328,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        raise \"#{collection.class}\"\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:24:48','2020-03-23 17:24:48',1),(329,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.class}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:52:41','2020-03-23 17:52:41',1),(330,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.class}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:52:41','2020-03-23 17:52:41',1),(331,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.class}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 17:52:41','2020-03-23 17:52:41',1),(332,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.collection?}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:09:23','2020-03-23 18:09:23',1),(333,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.collection?}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:09:23','2020-03-23 18:09:23',1),(334,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.id}, part: #{part.id}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:10:51','2020-03-23 18:10:51',1),(335,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.id}, part: #{part.id}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:10:51','2020-03-23 18:10:51',1),(336,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.class}, part: #{part.id}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:11:10','2020-03-23 18:11:10',1),(337,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.class}, part: #{part.id}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:11:10','2020-03-23 18:11:10',1),(338,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.collection?}, part: #{part.id}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:13:52','2020-03-23 18:13:52',1),(339,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        raise \"#{part.containing_collection.collection?}, part: #{part.id}\"\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:13:52','2020-03-23 18:13:52',1),(340,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:16:34','2020-03-23 18:16:34',1),(341,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      #raise \"#{collection.class}\"\n      raise \"#{parts.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:16:34','2020-03-23 18:16:34',1),(342,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      raise \"#{collection.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:16:54','2020-03-23 18:16:54',1);
INSERT INTO `codes` VALUES (343,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      raise \"#{collection.class}\"\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:16:55','2020-03-23 18:16:55',1),(344,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:17:02','2020-03-23 18:17:02',1),(345,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:17:02','2020-03-23 18:17:02',1),(346,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      show do\n        title \"Collkectiuon and parts\"\n        note \"collection id: #{collection.id}\"\n        parts.each do |part|\n          note \"Part ID: #{part.id}\"\n        end\n      end\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:17:02','2020-03-23 18:17:02',1),(347,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:39','2020-03-23 18:17:39',1),(348,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:39','2020-03-23 18:17:39',1),(349,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    thing = part.sample #if part.is_part\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:40','2020-03-23 18:17:40',1),(350,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:47','2020-03-23 18:17:47',1),(351,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(thing)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:48','2020-03-23 18:17:48',1),(352,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:58','2020-03-23 18:17:58',1),(353,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:17:58','2020-03-23 18:17:58',1),(354,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:18:22','2020-03-23 18:18:22',1),(355,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:18:22','2020-03-23 18:18:22',1),(356,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 18:18:22','2020-03-23 18:18:22',1),(357,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:18:31','2020-03-23 18:18:31',1),(358,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\n\n\nmodule CollectionTransfer\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:18:32','2020-03-23 18:18:32',1),(359,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  require \"Units\"\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:19:58','2020-03-23 18:19:58',1),(360,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  require \"Units\"\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:19:58','2020-03-23 18:19:58',1),(361,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  require Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:20:24','2020-03-23 18:20:24',1),(362,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  require Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:20:25','2020-03-23 18:20:25',1),(363,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  require Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:20:25','2020-03-23 18:20:25',1),(364,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:22:31','2020-03-23 18:22:31',1),(365,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\nend',4,'Library','2020-03-23 18:22:32','2020-03-23 18:22:32',1),(366,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plates.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:24:54','2020-03-23 18:24:54',1),(367,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plates.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:24:54','2020-03-23 18:24:54',1),(368,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plates.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:24:55','2020-03-23 18:24:55',1),(369,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME POINT!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plates.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:26:23','2020-03-23 18:26:23',1),(370,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME POINT!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plates.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:26:23','2020-03-23 18:26:23',1),(371,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME POINT!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plates.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:26:23','2020-03-23 18:26:23',1),(372,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME POINT!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:26:43','2020-03-23 18:26:43',1),(373,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME POINT!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 18:26:43','2020-03-23 18:26:43',1),(374,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 19:26:21','2020-03-23 19:26:21',1),(375,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 19:26:21','2020-03-23 19:26:21',1),(376,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    total_parts = 0\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      total_parts = total_parts + csv.readlines.size\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 19:29:08','2020-03-23 19:29:08',1),(377,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    total_parts = 0\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      total_parts = total_parts + csv.readlines.size\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\nend\n',6,'OperationType','2020-03-23 19:29:08','2020-03-23 19:29:08',1),(378,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n\n    upload_and_associate_csv\n\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      operations.associate(CSV_KEY.to_sym, CSV_DEBUG)\n    else\n      operations.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\nend\n',4,'OperationType','2020-03-23 19:46:09','2020-03-23 19:46:09',1),(379,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n\n    upload_and_associate_csv\n\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      operations.associate(CSV_KEY.to_sym, CSV_DEBUG)\n    else\n      operations.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\nend\n',4,'OperationType','2020-03-23 19:46:10','2020-03-23 19:46:10',1),(380,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        operations.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        operations.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 19:46:27','2020-03-23 19:46:27',1),(381,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        operations.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        operations.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 19:46:27','2020-03-23 19:46:27',1),(382,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        operations.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        operations.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 19:46:27','2020-03-23 19:46:27',1),(383,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n\n    upload_and_associate_csv\n\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      operations.associate(CSV_KEY.to_sym, CSV_DEBUG)\n    else\n      operations.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n    end\n  end\nend\n',4,'OperationType','2020-03-23 19:50:02','2020-03-23 19:50:02',1),(384,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(CSV)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 19:59:38','2020-03-23 19:59:38',1),(385,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(CSV)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 19:59:38','2020-03-23 19:59:38',1),(386,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:10:50','2020-03-23 20:10:50',1),(387,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:10:50','2020-03-23 20:10:50',1),(388,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:12:37','2020-03-23 20:12:37',1),(389,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:12:37','2020-03-23 20:12:37',1),(390,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:07','2020-03-23 20:13:07',1),(391,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:08','2020-03-23 20:13:08',1),(392,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:08','2020-03-23 20:13:08',1),(393,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:37','2020-03-23 20:13:37',1),(394,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:38','2020-03-23 20:13:38',1),(395,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:38','2020-03-23 20:13:38',1),(396,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 20:13:38','2020-03-23 20:13:38',1),(397,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:13:41','2020-03-23 20:13:41',1),(398,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:13:42','2020-03-23 20:13:42',1),(399,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 20:16:35','2020-03-23 20:16:35',1),(400,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 20:16:35','2020-03-23 20:16:35',1),(401,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:16:58','2020-03-23 20:16:58',1),(402,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:16:58','2020-03-23 20:16:58',1),(403,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:16:58','2020-03-23 20:16:58',1),(404,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:16:59','2020-03-23 20:16:59',1),(405,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    csv = CSV.parse(op.get(CSV_KEY.to_sym))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:16:59','2020-03-23 20:16:59',1),(406,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:20:47','2020-03-23 20:20:47',1),(407,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:20:47','2020-03-23 20:20:47',1),(408,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:21:57','2020-03-23 20:21:57',1),(409,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:21:57','2020-03-23 20:21:57',1),(410,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:22:04','2020-03-23 20:22:04',1),(411,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 20:22:04','2020-03-23 20:22:04',1),(412,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inpsect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:19:19','2020-03-23 21:19:19',1),(413,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inpsect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:19:19','2020-03-23 21:19:19',1),(414,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:19:55','2020-03-23 21:19:55',1),(415,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:19:55','2020-03-23 21:19:55',1),(416,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{csv.class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:21:16','2020-03-23 21:21:16',1),(417,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n    raise \"yeet it worked\"\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{csv.class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:21:16','2020-03-23 21:21:16',1),(418,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{csv.class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:21:40','2020-03-23 21:21:40',1),(419,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{csv.class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:21:40','2020-03-23 21:21:40',1),(420,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{csv.class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:21:40','2020-03-23 21:21:40',1),(421,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{op.get(CSV_KEY.to_sym).class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:22:16','2020-03-23 21:22:16',1),(422,'protocol','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This protocol is goes through determining what oligo adapters to use.\n#This information is uploaded through a CSV and a plate design is created.\n#The plate is then created and components are transfered to an intermidiate plate to be used later\n\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include CommonInputOutputNames, KeywordLib, CsvDebugLib\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  TRANSFER_VOL = 20\n\n\n  def main\n\n    #get the what sample to use\n    upload_and_associate_csv\n\n    validate_inputs\n\n    #find all these parts\n    col_parts_hash = sample_from_csv\n\n    working_plate = make_new_plate(C_TYPE)\n\n    #TODO Validate INPUTS AT SOME point!!\n\n    col_parts_hash.each do |collection, parts|\n      collection = Collection.find(collection.id)\n      working_plate.add_samples(parts)\n      transfer_to_working_plate(collection, working_plate, arry_sample = parts, TRANSFER_VOL)\n    end\n\n\n    #Assign this plate to the outputs of each operation (they are the same plate)\n    # and should be associated with the output object\n    #\n    #This protocol makes the plate but they plate also has to coordinate with the proper jobs...\n    #This is where batching really happens....  Right?  Theotically that would go together pretty\n    #easily but must think on this a bit.  A good thing to talk with amy about.\n    #\n    #Maybe the solve is in the other plan if there is a mismatch in matrix demensions of the\n    #RNA plate and the ligase adapter plate we could either error or provide a warning.\n    #e.g. \"The Ligase adapter plate has more samples than the RNA Plate.  Do you want to continue?\"\n    # or \"The Ligase adapter plate does not have enough samples for the RNA plate.  This job is errored\"\n    #\n    #\n    #\n    #transfer items properly to plate\n\n  end\n\n\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  def upload_and_associate_csv\n    operations.each do |op|\n      up_csv = show do\n        title \"Upload CSV file of Adapters\"\n        note \"Please upload a <b>CSV</B> file of all required adapters\"\n        note \"Row 1 is Reserved for headers\"\n        note \"Column 1: \'#{PLATE_ID}\'\"\n        note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n        upload var: CSV_KEY.to_sym\n      end\n      if debug\n        op.associate(CSV_KEY.to_sym, CSV_DEBUG)\n      else\n        op.associate(CSV_KEY.to_sym, up_csv.get_response(CSV_KEY.to_sym))\n      end\n    end\n  end\n\n\n  #Parses CSV and returns an array of all the samples required\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv\n    parts = []\n    operations.each do |op|\n      csv = CSV.parse(op.get(CSV_KEY.to_sym))\n      inspect \"#{op.get(CSV_KEY.to_sym).class}\"\n\n      csv.each_with_index do |row, idx|\n        if idx == 0\n          plate_id = row[0]\n          well_location = row[1]\n          raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n        else\n        collection = Collection.find(row[0])\n        part = part_alpha_num(collection, row[1])\n        parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\n\n\n  #Validates all input parts.  Currently just checks that there are less than 96 parts in the total sample\n  def validate_inputs\n\n  end\n\nend\n',6,'OperationType','2020-03-23 21:22:16','2020-03-23 21:22:16',1),(423,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 21:22:45','2020-03-23 21:22:45',1),(424,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 21:22:45','2020-03-23 21:22:45',1),(425,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-23 21:22:45','2020-03-23 21:22:45',1),(426,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:23:51','2020-03-23 21:23:51',1),(427,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:23:52','2020-03-23 21:23:52',1),(428,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(raw_csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:23:52','2020-03-23 21:23:52',1),(429,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:24:28','2020-03-23 21:24:28',1),(430,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:24:28','2020-03-23 21:24:28',1),(431,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv.class}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:24:28','2020-03-23 21:24:28',1),(432,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:25:24','2020-03-23 21:25:24',1),(433,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:25:25','2020-03-23 21:25:25',1),(434,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym).file\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:27:36','2020-03-23 21:27:36',1),(435,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym).file\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:27:36','2020-03-23 21:27:36',1),(436,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym).file\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv)\n    parts = []\n    #csv = CSV.parse(raw_csv)\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 21:27:36','2020-03-23 21:27:36',1),(437,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 22:49:12','2020-03-23 22:49:12',1),(438,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Upload CSV file of Adapters\"\n      note \"Please upload a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 22:49:12','2020-03-23 22:49:12',1),(439,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload[0].url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 22:59:52','2020-03-23 22:59:52',1),(440,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload[0].url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 22:59:52','2020-03-23 22:59:52',1),(441,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:00:11','2020-03-23 23:00:11',1),(442,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:00:11','2020-03-23 23:00:11',1),(443,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:03:56','2020-03-23 23:03:56',1),(444,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        raise \"Headers incorrect\" if plate_id != PLATE_ID || well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:03:56','2020-03-23 23:03:56',1),(445,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        raise \"Headers incorrect\" if plate_id != PLATE_ID \n        raise \"well locatio nwrong\" if well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:05:01','2020-03-23 23:05:01',1),(446,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        raise \"Headers incorrect\" if plate_id != PLATE_ID \n        raise \"well locatio nwrong\" if well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:05:02','2020-03-23 23:05:02',1),(447,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        #raise \"Headers incorrect\" if plate_id != PLATE_ID \n        raise \"well locatio nwrong\" if well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:06:51','2020-03-23 23:06:51',1),(448,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        #raise \"Headers incorrect\" if plate_id != PLATE_ID \n        raise \"well locatio nwrong\" if well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:06:51','2020-03-23 23:06:51',1),(449,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_upload)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv = CSV.read(open(csv_upload.first.url))\n    csv.each_with_index do |row, idx|\n      if idx == 0\n        plate_id = row[0]\n        well_location = row[1]\n        inspect \"plate_id #{plate_id}, well_location #{well_location}\"\n        #raise \"Headers incorrect\" if plate_id != PLATE_ID \n        raise \"well locatio nwrong\" if well_location != WELL_LOCATION\n      else\n      collection = Collection.find(row[0])\n      part = part_alpha_num(collection, row[1])\n      parts.push(part)\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:06:52','2020-03-23 23:06:52',1),(450,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.eacy do |upload|\n      csv = CSV.read(open(upload.url))\n      inspect \"#{csv.class}\"\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:10:04','2020-03-23 23:10:04',1),(451,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.eacy do |upload|\n      csv = CSV.read(open(upload.url))\n      inspect \"#{csv.class}\"\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:10:05','2020-03-23 23:10:05',1),(452,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.eacy do |upload|\n      csv = CSV.read(open(upload.url))\n      inspect \"#{csv.class}\"\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:10:05','2020-03-23 23:10:05',1),(453,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      inspect \"#{csv.class}\"\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:10:35','2020-03-23 23:10:35',1),(454,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      inspect \"#{csv.class}\"\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:10:35','2020-03-23 23:10:35',1),(455,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          inspect \"#{row[1]}\"\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:14:38','2020-03-23 23:14:38',1),(456,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          inspect \"#{row[1]}\"\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:14:39','2020-03-23 23:14:39',1),(457,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:22:44','2020-03-23 23:22:44',1),(458,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:22:44','2020-03-23 23:22:44',1),(459,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    inspect \"#{up_csv}\"\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:22:45','2020-03-23 23:22:45',1),(460,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:23:27','2020-03-23 23:23:27',1),(461,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:23:27','2020-03-23 23:23:27',1),(462,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapter > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:23:27','2020-03-23 23:23:27',1),(463,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:24:06','2020-03-23 23:24:06',1),(464,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:24:06','2020-03-23 23:24:06',1),(465,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:29:42','2020-03-23 23:29:42',1),(466,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,1].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:29:43','2020-03-23 23:29:43',1),(467,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:34:21','2020-03-23 23:34:21',1),(468,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:34:21','2020-03-23 23:34:21',1),(469,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:34:21','2020-03-23 23:34:21',1),(470,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          inspect \"#{collection.find(part)}\"\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:45:17','2020-03-23 23:45:17',1),(471,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          inspect \"#{collection.find(part)}\"\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:45:17','2020-03-23 23:45:17',1),(472,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          inspect \"location: #{collection.find(part)}, row: #{row}\"\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:46:48','2020-03-23 23:46:48',1),(473,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          inspect \"location: #{collection.find(part)}, row: #{row}\"\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:46:48','2020-03-23 23:46:48',1),(474,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          inspect \"location: #{collection.find(part)}, row: #{row}\"\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:46:49','2020-03-23 23:46:49',1),(475,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,-1].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:48:52','2020-03-23 23:48:52',1),(476,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1,-1].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:48:52','2020-03-23 23:48:52',1),(477,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1...].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:53:09','2020-03-23 23:53:09',1),(478,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1...].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:53:10','2020-03-23 23:53:10',1),(479,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1...].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-23 23:53:10','2020-03-23 23:53:10',1),(480,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:54:22','2020-03-23 23:54:22',1),(481,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:54:22','2020-03-23 23:54:22',1),(482,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      inspect \"#{parts.length}\"\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-23 23:54:22','2020-03-23 23:54:22',1),(483,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-24 00:00:19','2020-03-24 00:00:19',1),(484,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-24 00:00:19','2020-03-24 00:00:19',1),(485,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This module is to contain commen actions done with collections\n#This includes moving them, finding locations, putting away individual collections.\n# or putting a whole collection on a machine etc\n#These actions should involve the WHOLE plate not individual wells.  The colleciton is doing the whole action\nmodule CollectionActions\n    \n    #stores all input collections from all operations\n    #\n    # @operations OperationsList the operation list that all input collections should be stored\n    # @location Optional String, the location that the items are to be moved to\n    def store_input_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           operations.each do |op|\n              array_of_input_fv = op.inputs.reject{|fv| fv.collection == nil}\n              table table_of_object_locations(array_of_input_fv, location)\n          end\n        end\n    end\n    \n    #stores all output collections from all operations\n    #\n    # @operations OperationsList the operation list that all output collections should be stored\n    def store_output_collections(operations, location = nil)\n        show do \n           title \"Put Away the Following Items\"\n           array_of_input_fv = []\n           operations.each do |op|\n            array_of_input_fv = array_of_input_fv + op.outputs.reject{|fv| fv.collection == nil}\n           end\n           table table_of_object_locations(array_of_input_fv, location)\n        end\n    end\n    \n    #Shows the locations of all the collections in the array of FV.\n    #Can move the location to optional \"location\"\n    #\n    # array_of_fv Array[FieldValues] an array of FieldValues\n    # @location string Optional moves all collections to that location\n    # Returns\n    # @Table    Table   Returns a Table\n    def table_of_object_locations(array_of_fv, location = nil)\n        obj_array = []\n        array_of_fv.each do |fv|\n            if fv.collection != nil\n                obj_array.push fv.collection\n            elsif fv.item != nil\n                obj_array.push fv.item\n            else\n                raise \"Invalid class.  Neither collection nor item.\"\n            end\n        end\n        obj_array = obj_array.uniq\n        set_locations(obj_array, location) if location != nil\n        return get_item_locations(obj_array)\n    end\n\n\n    #Sets the location of all objects in array to some given locations\n    #\n    # @obj_array  Array[Collection] or Array[Items] an array of any objects that extend class item\n    # @location     String the location to be moved to (just string or Wizard if Wizard Exist)\n    def set_locations(obj_array, location)\n        obj_array.each do |obj|\n            obj.move(location)\n        end\n    end\n    \n    #instructions to store a specific collection\n    #\n    # @collection Collection the collection that is to be put away\n    # Returns:\n    # @ Table of collections and their locations\n    def get_item_locations(obj_array)\n        tab = [[\'ID\', \'Collection Type\', \'Location\']]\n        obj_array.each do |obj|\n            tab.push([obj.id, obj.object_type.name, obj.location])\n        end\n        return tab\n    end\n    \n    #Instructions to store a specific item\n    #\n    # @obj_item Item/Object that extends class item or Array[Item/item that \n    #       extends class item]         all items that need to be stored\n    # @location Optional String Sets the location of the items if included\n    def store_items(obj_item, location = nil)\n        show do\n            title \"Put Away the Following Items\"\n            if obj_item.class != Array\n                set_locations([obj_item], location) if location != nil\n                table get_item_locations([obj_item])\n            else\n                set_locations(obj_item, location) if location != nil\n                table get_item_location(obj_item)\n            end\n        end\n    end\n\n    #Gives directions to throwaway an object (collection or item)\n    #\n    # @obj or array of Item or Object that extends class Item  eg collection\n    # @hazardous boolean if hazardous then true\n    def trash_object(obj_array, hazardous = true)\n        #toss QC plate\n        if obj_array.class != Array\n            obj_array = [obj_array]\n        end\n        \n        show do\n            title \"Trash the following items\"\n            tab = [[\'Item\', \'Waste Container\']]\n            obj_array.each do |obj|\n                obj.mark_as_deleted\n                if hazardous\n                    waste_container = \"Biohazard Waste\"\n                else\n                    waste_container = \"Trash Can\"\n                end\n                tab.push([obj.id, waste_container])\n            end\n            table tab\n        end\n    end\n\n    #makes a new plate and provides instructions to label said plate\n    #\n    # @ c_type string the collection type\n    # @ label_plate boolean weather to get and label plate or no default true\n    # Returns\n    # @collection collection the collection it makes\n    def make_new_plate(c_type, label_plate = true)\n        working_plate = Collection.new_collection(c_type)\n        get_and_label_new_plate(working_plate) if label_plate\n        return working_plate\n    end\n\n\n\n    #Instructions on getting and labeling new plate\n    #\n    #@plate Collection plate to be gotten and labeled\n    def get_and_label_new_plate(plate)\n        show do\n        title \"Get and Label Working Plate\"\n        note \"Get a <b>#{plate.object_type.name}</b> and lable ID: <b>#{plate.id}</b>\"\n        end\n    end\n    \n    \nend',2,'Library','2020-03-24 00:29:44','2020-03-24 00:29:44',1),(486,'source','#Justin Vrana\n#\n#modified by:\n#Cannon Mallory\n#malloc3@uw.edu\n#\n#Modifications include:\n# Documentation (yet to happen)\n#\n# This module is for displaying information about collections in effecient easy to use ways\n#\n# TODO Make the collection displays so that they wont always be checkable cause that gets annoying\nmodule CollectionDisplay\n  def create_collection_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    slots.each_slice(collection.object_type.columns).map do |row|\n      row.map do |col|\n        {content: col, class: \'td-empty-slot\'}\n      end\n    end\n  end\n\n  def highlight tbl, row, col, id\n    tbl[row][col] = {content: id, class: \'td-filled-slot\', check: true}\n  end\n\n  # [r,c,x] list\n  def highlight_rcx(collection, rcx_list)\n    tbl = create_collection_table collection\n    rcx_list.each do |r, c, x|\n      highlight tbl, r, c, x\n    end\n    tbl\n  end\n\n  def highlight_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_rcx collection, rcx_list\n  end\n\n  def highlight_non_empty(collection, &rc_block)\n    highlight_rc collection, collection.get_non_empty, &rc_block\n  end\n\n  def highlight_collection ops, id_block=nil, &fv_block\n    g = ops.group_by { |op| fv_block.call(op).collection }\n    tables = g.map do |collection, grouped_ops|\n      rcx_list = grouped_ops.map do |op|\n        fv = fv_block.call(op)\n        id = id_block.call(op) if id_block\n        id ||= fv.sample.id\n        [fv.row, fv.column, id]\n      end\n      tbl = highlight_rcx collection, rcx_list\n      [collection, tbl]\n    end\n    tables\n  end\n\n  def r_c_to_slot collection, r, c\n    rows, cols = collection.dimensions = collection.object_type.rows\n    r*cols + c+1\n  end\n  \n  \n  \n  \n  def create_alpha_numeric_table(collection)\n    size = collection.object_type.rows * collection.object_type.columns\n    slots = (1..size).to_a\n    alpha_r = (\'A\'..\'H\').to_a\n    slots.each_slice(collection.object_type.columns).each_with_index.map do |row, r_idx|\n      row.each_with_index.map do |col, c_idx|\n        {content: \"#{alpha_r[r_idx]}#{c_idx + 1}\", class: \'td-empty-slot\'}\n      end\n    end\n  end\n  \n  def highlight_alpha_rc collection, rc_list, &rc_block\n    rcx_list = rc_list.map { |r, c|\n      block_given? ? [r, c, yield(r, c)] : [r, c, \"\"]\n    }\n    highlight_alpha_rcx(collection, rcx_list)\n  end\n  \n  def highlight_alpha_rcx(collection, rcx_list)\n     tbl = create_alpha_numeric_table(collection)\n     rcx_list.each do |r, c, x|\n         highlight tbl, r, c, x\n     end\n     return tbl\n  end\n\n  def highlight_alpha_non_empty collection, &rc_block\n    highlight_alpha_rc collection, collection.get_non_empty, &rc_block\n  end\n      \nend',3,'Library','2020-03-24 00:29:45','2020-03-24 00:29:45',1),(487,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n\n    associate_plate_to_plate(working_collection, input_collection, INPUT_PLATE, INPUT_ITEM)\n\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\n\n\n  #associates all items in the added_plate to the items in the base plate\n  # Associates corrosponding well locations.  Assocaites plate to plate and well to well\n  # Only associates to wells that have a part in them\n  #\n  #@base_plate collcetion the plate that is getting the association\n  #@added_plate collection the plate that is transfering the association\n  def associate_plate_to_plate(base_plate, added_plate, plate_key, item_key)\n    base_plate.associate(plate_key, added_plate)\n    added_parts = added_plate.parts\n    base_parts = base_plate.parts\n    base_parts.each_with_index do |part, idx|\n      part.assocaite(item_key, added_parts[idx])\n    end\n  end\nend',4,'Library','2020-03-24 00:29:46','2020-03-24 00:29:46',1),(488,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is to facilitate sample management within collection\nmodule SampleManagement\n\n  ALPHA26 = (\"A\"...\"Z\").to_a\n\n  #Gets the location string of a sample in a collection \n  #Returns Alpha numerical string eg A1 or if the sample is\n  #in multiple locations will return A1, A2, A3\n  #\n  #@collection Collection the collection that the sample is in\n  #@sample Sample the Sample that you want the Alpha Numerical location for\n  def get_alpha_num_location(collection, sample)\n    loc_array = get_item_sample_location(collection, sample)\n    string = \"\"\n    loc_array.each_with_index do |loc, idx|\n      string = string + \", \" if idx > 0\n      loc.each_with_index do |rc, idx|\n        if idx.even?\n          string = string + ALPHA26[rc]\n        else\n          string = string + \"#{rc+1}\"\n        end\n      end\n    end\n    return string\n  end\n\n\n  #Finds the location of what ever is give either item or sample\n  #\n  # @collection collection the collection containing the thing\n  # @part item,part, or sample that is to be found\n  # returns\n  # @Array[array[r,c]] sometimes samples are in multiple places so array of array\n  def get_item_sample_location(collection, part)\n    location_array = collection.find(part)\n    return location_array\n  end\n\n\n  #Assigns samples to specific well locations\n  #\n  #input:  working_plate   Collection\n  def add_fv_array_samples_to_collection(input_array, working_plate)\n      sample_array = []\n      input_array = input_array.sort_by{|fv| [fv.collection.find(fv.sample).first[1],fv.collection.find(fv.sample).first[0]]}\n      input_array.each_with_index do |fv, idx|\n        sample = fv.sample\n        sample_array << sample\n      end\n      slots_left = working_plate.get_empty.length\n      raise \"There are too many samples in this batch.\" if sample_array.length > slots_left\n      working_plate.add_samples(sample_array) #TODO add error checking for if the working_plate is full\n  end\n\n\n  #This replaces the operations.make command.  It ensures that all items in output_fv_array\n  #Remain in the same collection (instead of being put into different collections)\n  #\n  # @output_fv_array array[fv] array of field values\n  # @working_plate collection the destination collection.\n  def make_output_plate(output_fv_array, working_plate)\n    output_fv_array.each do |fv|\n        r_c = working_plate.find(fv.sample).first\n        fv.set(collection: working_plate, row: r_c[0], column: r_c[1])\n      end\n  end\n\n  #This finds a sample from an alpha numberical string location(e.g. A1, B1)\n  #\n  # @collection collection a collection that the part is located in\n  # @loc string  the location in the collection for part (A1, B3, C7)\n  # Returns:\n  # @part item the item at that location\n  def part_alpha_num(collection, loc)\n    row = ALPHA26.find_index(loc[0,1])\n    col = loc[1...].to_i - 1\n\n    dem = collection.dimensions \n    raise \"Location outside collection dimensions\" if row > dem[0] || col > dem[1]\n    part = collection.part(row,col)\n    return part\n  end\n\nend',5,'Library','2020-03-24 00:29:46','2020-03-24 00:29:46',1),(489,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\n    ADAPTER_PLATE = \"Adapter Plate\"\n    ADAPTER = \"Adapter Item\"\n\n    INPUT_PLATE = \"Input Plate\"\n    INPUT_ITEM = \"Input Item\"\n\nend',6,'Library','2020-03-24 00:29:47','2020-03-24 00:29:47',1),(490,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This includes all moduels that validate workflow parameters at run time\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"RNA_Seq/KeywordLib\"\n\nmodule WorkflowValidation\n  include CommonInputOutputNames, KeywordLib\n\n  \n  \n  #Validates that total inputs (from all operations)\n  #Ensures that all inputs doesnt exeed max inputs\n  #\n  # @operations OperationList list of all operations in the job\n  # @inputs_match_outputs Boolean if the number of inputs should match the number of outputs set as true\n  def validate_inputs(operations, inputs_match_outputs = false)\n    total_inputs = []\n    total_outputs = []\n    operations.each do |op|\n      total_inputs = total_inputs + op.input_array(INPUT_ARRAY).map!{|fv| fv.sample}\n      total_outputs = total_outputs + op.output_array(OUTPUT_ARRAY).map!{|fv| fv.sample}\n    end\n\n    a = total_inputs.detect{ |sample| total_inputs.count(sample) > 1}\n    raise \"Sample #{a.id} has been included multiple times in this job\" if a != nil\n    raise \"The number of Input Samples and Output \n            Samples do not match\" if total_inputs.length != total_outputs.length && inputs_match_outputs\n    raise \"Too many samples for this job. Please re-lauch job with fewer samples\" if total_inputs.length > MAX_INPUTS\n    raise \"There are no samples for this job.\"  if total_inputs.length <= 0\n  end\n\n\n  def validate_concentrations(operations, range)\n    operations.each do |op|\n      op.input_array(INPUT_ARRAY).each do |fv|\n        conc = fv.item.get(CON_KEY)\n        raise \"Sample #{fv.sample.id} doesn\'t have a valid concentration for this operation\"if !range.cover? conc\n      end\n    end\n  end\n\n  def validate_cdna_qc(operations)\n    operations.each do |op|\n      op.input_array(INPUT_ARRAY).each do |fv|\n        qc = fv.item.get(QC2_KEY)\n        raise \"Item #{fv.item.id} doesn\'t have a valid C-DNA QC\" if qc != \"Pass\"\n      end\n    end\n  end\n  \n  \nend',7,'Library','2020-03-24 00:29:48','2020-03-24 00:29:48',1),(491,'source','module CsvDebugLib\n    CSV_DEBUG = \"Plate ID,Well Location\n    100,A1\n    100,B1\n    100,C1\n    100,D1\n    100,E1\n    100,F1\n    100,G1\n    100,A2\n    100,B2\n    100,C2\n    100,D2\n    100,E2\n    100,F2\n    100,G2\n    100,A3\n    100,B3\n    100,C3\n    100,D3\n    100,E3\n    100,F3\n    100,G3\"\nend',12,'Library','2020-03-24 00:29:49','2020-03-24 00:29:49',1),(492,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\nneeds \"RNA_Seq/CsvDebugLib\"\n\nrequire \'csv\'\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib, CsvDebugLib\n  C_TYPE = \"96 Well Sample Plate\"\n  CON_KEY = \"Stock Conc (ng/ul)\"\n\n  PLATE_ID = \"Plate ID\"\n  WELL_LOCATION = \"Well Location\"\n  ADAPTER_TRANSFER_VOL = 12 #volume of adapter to transfer\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n  CONC_RANGE = (50...100)\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_concentrations(operations, CONC_RANGE)\n\n    working_plate = make_new_plate(C_TYPE)\n\n    adapter_plate = make_adapter_plate\n\n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n\n    associate_plate_to_plate(working_plate, adapter_plate, ADAPTER_PLATE, ADAPTER)\n\n    store_input_collections(operations)\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title \"Run RNA-Prep\"\n      note \"Run typical RNA-Prep Protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\n\n\n  #Instructions for making an adapter plate\n  #\n  #returns:\n  # @adapter_plate collection the adapter plate\n  def make_adapter_plate\n    adapter_plate = make_new_plate(C_TYPE)\n    up_csv = upload_and_csv\n    col_parts_hash = sample_from_csv(up_csv)\n    validate_csv(col_parts_hash)\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n      adapter_plate.add_samples(parts)\n      transfer_to_working_plate(collection, adapter_plate, arry_sample = parts, ADAPTER_TRANSFER_VOL)\n    end\n    return adapter_plate\n  end\n\n  #Validates CSV information to make sure that it matches inputs\n  #\n  #@col_parts_hash  a hash of parts with the collection that they originate in as the key\n  def validate_csv(col_parts_hash)\n    total_samples = 0\n    total_adapters = 0\n\n    operations.each do |op|\n      total_samples = total_samples + op.input_array(INPUT_ARRAY).length\n    end\n\n    col_parts_hash.each do |col, parts|\n      total_adapters = total_adapters + parts.length\n    end\n\n    raise \"Not enough adapters for all samples in job\" if total_adapters < total_samples #TODO loop back to upload\n    if total_adapters > total_samples  #TODO could have it loop back to upload here too\n      show do \n        title \"More Adapters than needed\"\n        note \"The CSV uploaded adds more adapters than needed.\"\n        note \"Click OKAY to continue with this job or Cancel to Cancel\"\n      end\n    end\n  end\n\n  #Gets CSV upload and associates each CSV file with the operation in question\n  #\n  #returns\n  #@CSV CSV a csv file with the desired adapter plate wells\n  def upload_and_csv\n    up_csv = show do\n      title \"Make CSV file of Adapters\"\n      note \"Please make a <b>CSV</B> file of all required adapters\"\n      note \"Row 1 is Reserved for headers\"\n      note \"Column 1: \'#{PLATE_ID}\'\"\n      note \"Column 2: \'#{WELL_LOCATION}\' (e.g. A1, B1)\"\n      upload var: CSV_KEY.to_sym\n    end\n    if debug\n      return CSV_DEBUG\n    else\n      return up_csv.get_response(CSV_KEY.to_sym)\n    end\n  end\n\n\n\n\n  #Parses CSV and returns an array of all the samples required\n  #@ CSV  CSV a csv file of thee adapter plate wells\n  #\n  #returns hash[key: collection, array[parts]]\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n      csv.each_with_index do |row, idx|\n        if idx != 0\n          collection = Collection.find(row[0])\n          part = part_alpha_num(collection, row[1])\n          parts.push(part)\n        end\n      end\n    end\n    return parts.group_by{|part| part.containing_collection}\n  end\nend\n',4,'OperationType','2020-03-24 00:29:51','2020-03-24 00:29:51',1),(493,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\n    ADAPTER_PLATE = \"Adapter Plate\"\n    ADAPTER = \"Adapter Item\"\n\n    INPUT_PLATE = \"Input Plate\"\n    INPUT_ITEM = \"Input Item\"\n\nend',6,'Library','2020-03-24 00:31:24','2020-03-24 00:31:24',1),(494,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n#This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n    MAX_INPUTS = 96\n    C_TYPE = \"96 Well Sample Plate\"\n    CON_KEY = \"Stock Conc (ng/ul)\"\n    QC2_KEY = \"C-DNA QC\"\n    CSV_KEY = \"csv\"\n\n    ADAPTER_PLATE = \"Adapter Plate\"\n    ADAPTER = \"Adapter Item\"\n\n    INPUT_PLATE = \"Input Plate\"\n    INPUT_ITEM = \"Input Item\"\n\nend',6,'Library','2020-03-24 00:31:24','2020-03-24 00:31:24',1),(495,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n\n    associate_plate_to_plate(working_collection, input_collection, \"Input Plate\", \"Input Item\")\n\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\n\n\n  #associates all items in the added_plate to the items in the base plate\n  # Associates corrosponding well locations.  Assocaites plate to plate and well to well\n  # Only associates to wells that have a part in them\n  #\n  #@base_plate collcetion the plate that is getting the association\n  #@added_plate collection the plate that is transfering the association\n  def associate_plate_to_plate(base_plate, added_plate, plate_key, item_key)\n    base_plate.associate(plate_key, added_plate)\n    added_parts = added_plate.parts\n    base_parts = base_plate.parts\n    base_parts.each_with_index do |part, idx|\n      part.assocaite(item_key, added_parts[idx])\n    end\n  end\nend',4,'Library','2020-03-24 00:31:27','2020-03-24 00:31:27',1),(496,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n\n    associate_plate_to_plate(working_collection, input_collection, \"Input Plate\", \"Input Item\")\n\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\n\n\n  #associates all items in the added_plate to the items in the base plate\n  # Associates corrosponding well locations.  Assocaites plate to plate and well to well\n  # Only associates to wells that have a part in them\n  #\n  #@base_plate collcetion the plate that is getting the association\n  #@added_plate collection the plate that is transfering the association\n  def associate_plate_to_plate(base_plate, added_plate, plate_key, item_key)\n    base_plate.associate(plate_key, added_plate)\n    added_parts = added_plate.parts\n    base_parts = base_plate.parts\n    base_parts.each_with_index do |part, idx|\n      part.assocaite(item_key, added_parts[idx])\n    end\n  end\nend',4,'Library','2020-03-24 00:31:28','2020-03-24 00:31:28',1),(497,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n\n    associate_plate_to_plate(working_collection, input_collection, \"Input Plate\", \"Input Item\")\n\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\n\n\n  #associates all items in the added_plate to the items in the base plate\n  # Associates corrosponding well locations.  Assocaites plate to plate and well to well\n  # Only associates to wells that have a part in them\n  #\n  #@base_plate collcetion the plate that is getting the association\n  #@added_plate collection the plate that is transfering the association\n  def associate_plate_to_plate(base_plate, added_plate, plate_key, item_key)\n    base_plate.associate(plate_key, added_plate)\n    added_parts = added_plate.parts\n    base_parts = base_plate.parts\n    base_parts.each_with_index do |part, idx|\n      part.associate(item_key, added_parts[idx])\n    end\n  end\nend',4,'Library','2020-03-24 00:32:41','2020-03-24 00:32:41',1),(498,'source','#Cannon Mallory\n#malloc3@uw.edu\n#\n# This module includes helfpul methods for transferring items into and out of collections\n# Currently it only has collection --> collection transfers \n#TODO Item --> collection and collection --> item transfers. (not applicable for current project so not added)\nneeds \"Standard Libs/Units\"\n\nmodule CollectionTransfer\n  \n  include Units\n\n\n  #Provides instructions to transfer sample from an input_collection to a working_working collection\n  #The array of samples must exist in both collections.  Both collections must already have the samples\n  #associated with it else an error will be thrown.\n  #\n  # @input_collection Collection  the collection that samples will be transfered from\n  # @working_collection Collection the collection that samples will be transfered to\n  # @transfer_vol Int volume in ul of sample to transfer\n  #\n  # @arry_samples  Array[Sample] Optional an array of all the samples that are to be transfered\n        #if black then all samples will be transfered\n  def transfer_to_working_plate(input_collection, working_collection, arry_sample = nil, transfer_vol)\n    if arry_sample == nil\n      arry_sample = input_collection.parts.map{|part| part.sample if part.class != \"Sample\"}\n    end\n    input_rcx = []\n    output_rcx = []\n    arry_sample.each do |sample|\n      input_location_array = get_item_sample_location(input_collection, sample)\n      input_sample_location = get_alpha_num_location(input_collection, sample)\n\n      output_location_array = get_item_sample_location(working_collection, sample)\n      output_sample_location = get_alpha_num_location(input_collection, sample)\n\n      input_location_array.each do |sub_array|\n        sub_array.push(input_sample_location)\n        input_rcx.push(sub_array)\n      end\n\n      output_location_array.each do |sub_array|\n          sub_array.push(output_sample_location)\n          output_rcx.push(sub_array)\n      end\n    end\n\n    associate_plate_to_plate(working_collection, input_collection, \"Input Plate\", \"Input Item\")\n\n    show do \n      title \"Transfer from Stock Plate to Working Plate\"\n      note \"Please transfer #{transfer_vol} #{MICROLITERS} from stock plate (ID:#{input_collection.id}) to working \n                                plate (ID:#{working_collection.id}) per tables below\"\n      note \"Separator\"\n      note \"Stock Plate (ID: #{input_collection.id}):\"\n      table highlight_rcx(input_collection, input_rcx)  #TODO need RCX list for transfer here!! not whole collection\n      note \"Working Plate (ID: #{working_collection}):\"\n      table highlight_rcx(working_collection, output_rcx)\n    end\n  end\n\n\n  #Instructions to transfer from input plates to working_plates when an array of samples in collections is used\n  #Will group samples in same collection together for easier transfer.  Uses transfer_to_working_plate method\n  #\n  # @working_plate Collection (Should have samples already associated to it)\n  # @input_fv_array Array[FieldValues] an array of field values of collections.  Typically from\n        # op.input_array(INPUT_ARRAY_NAME) when the individual inputs are samples in a collection\n  # @transfer_vol Int volume in ul of sample to transfer\n  def transfer_from_array_collections(input_fv_array, working_plate, transfer_vol)\n    sample_arry_by_collection = input_fv_array.group_by{|fv| fv.collection}\n    sample_arry_by_collection.each do |input_collection, fv_array|\n      sample_array = fv_array.map{|fv| fv.sample}\n      transfer_to_working_plate(input_collection, working_plate, sample_array, transfer_vol)\n    end\n  end\n\n\n  #Instructions on relabeling plates to new plate ID\n  #\n  #@plate1 Collection plate to be relabel\n  #@plate2 Collection new plate label\n  def relabel_plate(plate1, plate2)\n    show do\n      title \"Rename Plate\"\n      note \"Relabel plate #{plate1.id} with #{plate2.id}\"\n    end\n  end\n\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_input_plates?(operations)\n    if get_num_plates(operations, \'input\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #determins if there are multiple output plate\n  #\n  #@operations OperationList list of operations in job\n  #returns boolean true if multiple plates \n  def multi_output_plates?(operations)\n    if get_num_plates(operations, \'output\') > 1\n      return true\n    else\n      return false \n    end\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Int the number of plates \n  def get_num_plates(operations, in_out)\n    return get_array_of_collections(operations, in_out).length\n  end\n\n  #gets the number of plate\n  #\n  #@operations OperationList list of operations in job\n  #@in_out String input or output determines if its input or output collections\n  #returns Array[collection] the number of plates \n  def get_array_of_collections(operations, in_out)\n    collection_array = []\n    operations.each do |op|\n      obj_array = op.inputs if in_out = \"input\"\n      obj_array = op.outputs if in_out = \"output\"\n      obj_array.each do |fv|\n        if fv.collection != nil\n          collection_array.push(fv.collection)\n        end\n      end\n    end\n    return collection_array.uniq\n  end\n\n\n  #associates all items in the added_plate to the items in the base plate\n  # Associates corrosponding well locations.  Assocaites plate to plate and well to well\n  # Only associates to wells that have a part in them\n  #\n  #@base_plate collcetion the plate that is getting the association\n  #@added_plate collection the plate that is transfering the association\n  def associate_plate_to_plate(base_plate, added_plate, plate_key, item_key)\n    base_plate.associate(plate_key, added_plate)\n    added_parts = added_plate.parts\n    base_parts = base_plate.parts\n    base_parts.each_with_index do |part, idx|\n      part.associate(item_key, added_parts[idx])\n    end\n  end\nend',4,'Library','2020-03-24 00:32:41','2020-03-24 00:32:41',1),(499,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',7,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(500,'precondition','def precondition(op)\n  true\nend',7,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(501,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',7,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(502,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',7,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(503,'test','',7,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(504,'protocol','\n\n# This is a default, one-size-fits all protocol that shows how you can\n# access the inputs and outputs of the operations associated with a job.\n# Add specific instructions for this protocol!\n\nclass Protocol\n\n  def main\n\n    operations.retrieve.make\n\n    tin  = operations.io_table \'input\'\n    tout = operations.io_table \'output\'\n\n    show do\n      title \'Input Table\'\n      table tin.all.render\n    end\n\n    show do\n      title \'Output Table\'\n      table tout.all.render\n    end\n\n    operations.store\n\n    {}\n\n  end\n\nend\n',8,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(505,'precondition','def precondition(_op)\n  false\nend',8,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(506,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',8,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(507,'documentation','This `Canceled` OperationType does nothing except indicate which parts of the plan are canceled and will always be either in the *delayed* or *errored* status.\n\nThis is automatically created in other functional blocks and is not intended to be submitted by users.',8,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(508,'test','',8,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(509,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n      op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\")\n    end\n\n  end\n\nend\n',9,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(510,'precondition','def precondition(_op)\n  plan = _op.plan\n  plan.associate(\'debug\', Time.zone.now)\n  if plan\n    _op = Operation.find(_op)\n    #\n    t = _op.input(\"Time\").val\n    unit = _op.input(\"Unit\").val\n    target_time = {unit.to_sym => t}\n    num_seconds = (target_time[:minutes] || 0) * 60 +\n        (target_time[:hours] || 0) * 60 * 60 +\n        (target_time[:days] || 0) * 60 * 60 * 24\n\n    key = \"Time remaining (Delay)\"\n    plan_key = \"#{key} [#{_op.id}]\"\n\n    input_fv = _op.input(\"Input\")\n\n    t1 = nil\n    if input_fv.predecessors.any?\n      t1 = input_fv.predecessors.first.updated_at\n    elsif\n    log_status(_op, \"no predecessors found!\")\n      return false\n    end\n    t2 = Time.now\n    delta_t = t2 - t1\n    remaining_seconds = num_seconds - delta_t\n    ready = compare_time(delta_t, {unit.to_sym=>t})\n\n    if ready\n      _op.pass(\"Input\", \"Output\")\n      _op.change_status \"done\"\n      _op.save()\n      # _op.save\n      log_status(_op, \"#{0} #{unit}\")\n      return false\n    end\n\n    delta_t = t2 - t1\n    msg = \"#{remaining_seconds} #{unit}\"\n    log_status(_op, msg)\n  end\n  return false\nend\n\ndef log_status(op, msg)\n  key = \"Time remaining (Delay)\"\n  plan_key = \"#{key} [#{op.id}]\"\n  op.associate(key, msg)\n  op.plan.associate(plan_key, msg)\nend\n\ndef compare_time delta_time, target_time\n\n  num_seconds = (target_time[:minutes] || 0) * 60 +\n      (target_time[:hours] || 0) * 60 * 60 +\n      (target_time[:days] || 0) * 60 * 60 * 24\n  return delta_time >= num_seconds\nend\n\ndef get_t1 input_fv\n  if input_fv.predecessors.any?\n    pred = input_fv.predecessors.first\n    if pred.status == \'done\'\n      return pred.updated_at\n    else\n      # return -1 if still waiting for predecessors\n      return -1\n    end\n  else\n    return false\n  end\nend',9,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(511,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',9,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(512,'documentation','Delays the next operation for the specified amount of time.\n\nNote that plans only *step* at irregular intervals. Because of this, timing will not be exact.',9,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(513,'test','',9,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(514,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',10,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(515,'precondition','def precondition(_op)\n    plan = _op.plan\n    if plan\n        \n    end\n    return false\nend',10,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(516,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',10,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(517,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',10,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(518,'test','',10,'OperationType','2020-03-24 15:41:54','2020-03-24 15:41:54',1),(519,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',11,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(520,'precondition','def precondition(_op)\n  #   this is done so that Operation instance methods are available\n  _op = Operation.find(_op)\n  _op.pass(\"Input\", \"Output\")\n  _op.status = \"done\"\n  _op.save\n  return true\nend',11,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(521,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',11,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(522,'documentation','This Control Block passes an input item to and output item. This is useful if you want a single \'handle\' to adjust several inputs of downstream operations and to ensure all inputs receive exactly the same item.\n\n[![Screen_Shot_2018-09-02_at_2.15.21_PM.png](https://s22.postimg.cc/dkxhmrdwx/Screen_Shot_2018-09-02_at_2.15.21_PM.png)](https://postimg.cc/image/eag9z4egd/)',11,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(523,'test','',11,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(524,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',12,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(525,'precondition','def precondition(op)\n  op.inputs.each do |input|\n      if not input.item.nil?\n        \n      end\n  end\nend',12,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(526,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',12,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(527,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',12,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(528,'test','',12,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(529,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',13,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(530,'precondition','def precondition(_op)\n  if _op.plan\n      _op = Operation.find(_op.id)\n      status_key = \"Recieve from Operation status\"\n      plan_status_key = \"#{status_key} (#{_op.id})\"\n      \n      output = _op.output(\"Output\")\n      other_op_id = _op.input(\"Operation Id\").val.to_i\n      other_op = Operation.find(other_op_id)\n      \n      if other_op.nil?\n        msg = \"No Operation with id #{other_op_id} found\"\n        _op.plan.associate(plan_status_key, msg)\n        _op.associate(status_key, msg)\n        return false\n      end\n      \n      other_output_fv_name = _op.input(\"Output Field Value Name\").val\n      other_output_fv = other_op.output(other_output_fv_name)\n      if other_output_fv.nil?\n        msg = \"No Field value with name #{other_output_fv_name} found. Available outputs: #{other_op.outputs.map { |fv| fv.name }}\"\n        _op.plan.associate(plan_status_key, msg)\n        _op.associate(status_key, msg)\n        return false\n      end\n      \n      other_output_sample = other_output_fv.sample\n      if other_output_sample.id != output.sample.id\n        msg = \"Output sample #{output.sample.id}: #{output.sample.name} does not match output sample #{other_output_sample.id} #{other_output_sample.name}\"\n        _op.plan.associate(plan_status_key, msg)\n        _op.associate(status_key, msg)\n        return false\n      end\n      \n      other_output_ot = other_output_fv.object_type\n      if other_output_ot.id != output.object_type.id\n        msg = \"Output object type #{output.object_type.id}: #{output.object_type.name} does not match output sample #{other_output_ot.id} #{other_output_ot.name}\"\n        _op.plan.associate(plan_status_key, msg)\n        _op.associate(status_key, msg)\n        return false\n      end\n      \n      other_output_item = other_output_fv.item\n      if other_output_item.nil?\n        msg = \"Waiting for item from Operation #{other_op.id} in Plan #{other_op.plan.id}\"\n        _op.plan.associate(plan_status_key, msg)\n        _op.associate(status_key, msg)\n        return false\n      else\n        msg = \"Item #{other_output_item.id} found from operation #{other_op.id}\"\n        _op.plan.associate(plan_status_key, msg)\n        _op.associate(status_key, msg)\n        _op.output(\"Output\").set(item: other_output_item)\n        _op.status = \"done\"\n        _op.save()\n        return true\n      end\n      \n      return false\n  end\n  return false\nend',13,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(531,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',13,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(532,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',13,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(533,'test','',13,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(534,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',14,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(535,'precondition','def precondition(_op)\n  _op = Operation.find(_op)\n  plan = _op.plan\n  subject = _op.input(\"Subject\").val\n  message = _op.input(\"Message\").val\n  aq_url = Parameter.get(\"URL\")\n  message += \"<br><a href=\'#{aq_url}/plans?plan_id=#{plan.id}\'>#{plan.id} - #{plan.name}</a>\"\n  user = _op.user\n  user.send_email subject, message\n  _op.status = \"done\"\n  _op.save\nend',14,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(536,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',14,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(537,'documentation','Simply sends an email when the operation is ready. Moves status to \"done\".\n\nOptionally include attachements from the item into the email?',14,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(538,'test','',14,'OperationType','2020-03-24 15:41:55','2020-03-24 15:41:55',1),(539,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',15,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(540,'precondition','def precondition(_op)\n    plan = _op.plan\n    if plan\n        \n        # select operations of same operation type\n        ops = plan.operations.select { |op| op.operation_type.id == _op.operation_type.id }\n        \n        # experiment\n        experiment = _op.input(\"Experiment Number\").val.to_i\n        \n        # message key\n        key = \"Experiment #{experiment} (\\\"Waiting for All\\\")\"\n        ops = ops.select { |op| op.input(\"Experiment Number\").val.to_i == experiment }\n\n        _op.plan.associate(\"debug\", \"found #{ops.length} operations for experiment #{experiment}\")\n        \n        waiting_ops = ops.reject { |op| [\"delayed\", \"pending\", \"done\"].include? op.status }\n        _op.plan.associate(\"debug2\", \"found #{waiting_ops.length} operations\")\n        if waiting_ops.length == 0\n            ops.each do |op|\n                message = \"Experiment #{experiment} is ready.\"\n                ops.each do |op|\n                    op.associate(key, message)\n                end\n                _op.plan.associate(key, message)\n                \n                # re-route inputs to outputs\n                op.output(\"Output\").set(item: op.input(\"Input\").item)\n                op.status = \'done\'\n                op.save()\n            end\n            return true\n        else\n            message = \"Experiment #{experiment} is waiting for other operations #{waiting_ops.map { |op| op.id}} to complete.\"\n            ops.each do |op|\n                op.associate(key, message)\n            end\n            _op.plan.associate(key, message)\n        end\n    end\n    return false\nend',15,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(541,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',15,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(542,'documentation','This operation waits for all other \"Wait for All\" operations to be ready. This is useful for setting up where you require operations *in the same plan* to be batched together. User chooses an experiment number and some notes. The precondition for all operations will simply be delayed until all `Wait for All` operations of the same experiment number are in \"delayed\", with input items available\nSets precondition notes (e.g. \"Waiting for operations ..., ... ,...\")\n\nNote that this block only works with operations **in the same plan**. \n\nAlso note that you **must** set the **Experiment Number** parameter for each `Wait for All` operation. This will indicate which experiment the operation belongs to.',15,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(543,'test','',15,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(544,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',16,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(545,'precondition','eval Library.find_by_name(\"ControlBlock\").code(\"source\").content\nextend ControlBlock\n\ndef precondition(_op)\n  plan = _op.plan\n\n  message = _op.input(\"Response Message\").val\n  plan_message = \"(#{_op.id}) \" + message\n  precondition_key = \"Waiting for User Input\"\n  plan_key = \"(#{_op.id}) \" + precondition_key\n  yes = _op.input(\"Expected Yes\").val\n  no = _op.input(\"Expected No\").val\n  default_response = \"#{yes}; #{no}\"\n  choices = [yes.downcase, no.downcase]\n\n  input_fv = \"Input\"\n  yes_fv_name = \"Yes Response\"\n  no_fv_name = \"No Response\"\n\n\n  # TODO: set operation children to error\n\n  if plan\n    # get response from plan\n    plan_response = _op.plan.get(plan_message)\n    if plan_response.nil?\n      plan_response = default_response\n      _op.plan.associate(plan_message, default_response)\n    end\n\n    # get response for operation\n    op_response = _op.get(message)\n    if op_response.nil?\n      op_response = default_response\n      _op.associate(message, default_response)\n    end\n\n    plan_response.downcase!\n    op_response.downcase!\n\n    # check for conflicting responses\n    if choices.include?(plan_response) and choices.include?(op_response)\n      if plan_response != op_response\n        error_message = \"Conflicting responses between operation #{_op.id} and plan #{_op.plan.id}. Please resolve.\"\n        _op.associate(precondition_key, error_message)\n        _op.plan.associate(plan_key, error_message)\n        _op.associate(message, default_response)\n        _op.plan.associate(plan_message, default_response)\n        return false\n      end\n    end\n\n    # default to plan response\n    res = default_response\n    if choices.include? plan_response\n      res = plan_response\n    else\n      choices.include? op_response\n      res = op_response\n    end\n    _op.associate(message, res)\n    _op.plan.associate(plan_message, res)\n\n    # TODO: somehow set other branch to errored in plan...\n    # if YES or NO, reroute and save, finally associate messages\n    response_message = \"User has not selected either \\\"yes\\\" or \\\"no\\\".\"\n    if res.downcase == yes.downcase\n      response_message = \"User selected \\\"Yes\\\" (#{yes}).\"\n      _op.output(yes_fv_name).set(item: _op.input(input_fv).item)\n      _op.output(no_fv_name).set(item: nil)\n      op = Operation.find(_op.id)\n\n      cancel_branches [op.output(no_fv_name)]\n\n      op.change_status(\"done\")\n      op.save()\n\n      # _op.output(no_fv_name).successors.each do |fv|\n      #     op_id = fv.operation.id\n      #     fv_op = Operation.find(op_id)\n      #     fv_op.associate(\"debug\", \"set to error\")\n      #     fv_op.status = \"error\"\n      #     fv_op.save()\n      # end\n    elsif res.downcase == no.downcase\n      response_message = \"User selected \\\"No\\\" (#{no}).\"\n      _op.output(no_fv_name).set(item: _op.input(input_fv).item)\n      _op.output(yes_fv_name).set(item: nil)\n      op = Operation.find(_op.id)\n\n      cancel_branches [op.output(yes_fv_name)]\n\n      op.change_status(\"done\")\n      op.save()\n    end\n    _op.associate(precondition_key, response_message)\n    _op.plan.associate(plan_key, response_message)\n  end\n  return false\nend',16,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(546,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',16,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(547,'documentation','**WARNING: BETA VERSION. USE WITH CAUTION**\n\nThis is a control block that waits for specific response from the user. The precondition will:\n\n1. attach a key-value to the operation\'s plan\n2. wait for response\n3. re-route the item to either the \"Yes Response\" or \"No Response\". Other response will simply have no item.\n4. set this operation to \"done\"\n5. attach a response message to this operation and the plan (using special key for each operation)\n6. \n\nIf there is already a key-value for the response, the operation will not create a new key-value, but will wait for the value to appear to respond',16,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(548,'test','',16,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(549,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',17,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(550,'precondition','def precondition(_op)\n  #   this is done so that Operation instance methods are available\n  _op = Operation.find(_op)\n  _op.pass(\"Sample\", \"Sample\")\n\n  item = _op.input(\"Sample\").item\n  associations = _op.input(\"Associations\").val\n  associations.each do |k, v|\n    item.associate(k, v)\n  end\n\n  _op.status = \"done\"\n  _op.save\n  return true\nend',17,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(551,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',17,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(552,'documentation','Associates key-values to the input item and passes to the output item. The association JSON should be of the form:\n```\n{\n    \"key1\": \"value1\",\n    \"key2\": [1,2,3,4],\n    \"key3\": true,\n    \"key4\": false\n    ...\n}\n```',17,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(553,'test','',17,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(554,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',18,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(555,'precondition','eval Library.find_by_name(\"ControlBlock\").code(\"source\").content\nextend ControlBlock\n\n#TODO add check for output possibilities number matches the number of conditions\ndef precondition(op)\n  op = Operation.find(op.id)\n  input = op.input(\"Case Sample\")\n  outputs = op.array_output(\"Route Possibilites\")\n  cases = op.input(\"Branch Conditions\").val\n  \n  # Concern about field value arrays: are they mutable? Is the ordering of field value arrays always the same??\n  # 1: doesn\'t matter if the fv arrays are mutable since we are only effecting the field values themselves which are held in that array as references (setting an item field)\n  #         an immutable arry\n  # 2: Not sure, but some experiments, and some inspection in codebase on how fv arrays are built and filled could answer this\n  \n  good_outputs = []\n  \n  # evaluate a user given condition for each route\n  cases.each do |route_idx, condition|\n    condition = if condition[0..2] == \':::\'\n        condition[3..-1]\n    else\n        \'input.\' + condition\n    end\n    \n    if eval(condition)\n        good_outputs << outputs[route_idx]\n    end\n  end\n  \n  DynamicBranching::affirm_branches(good_outputs)\n  DynamicBranching::cancel_branches(outputs - good_outputs)\n  \n  op.status = \"done\"\n  op.save\nend\n',18,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(556,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',18,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(557,'documentation','**WARNING: BETA VERSION. USE WITH CAUTION**\n\nThis is a general purpose experimental workflow logic block\n\nSwitch logic is encoded into the JSON parameter as an array of boolean expressions to be evaluated on the input, where each index in the condition array corresponds to an index in the output array. **The amount of output paths must match the amount of conditional expressions.**\n\nThe following example assumes 3 output paths. It will trigger the first branch coming from this block if the item passed through has an association: \"Verified\" => \"yes\".\nIt will trigger the second and third branch if the item has \"Verified\" => \"no\" instead\n\n```\n  {\n    [\n        \'item.get(\"Verified\") == \"yes\"\',\n        \'item.get(\"Verified\") == \"no\"\',\n        \'item.get(\"Verified\") == \"no\"\'\n    ]\n  }\n```\n\nAt the end of all switch cases, any remaining output routes that have not been triggered will be errored. For the above example, supposing the verification answer was \'yes\', then branch 0 would start execution, while branch 1 and 2 would error out.\n\nWe can case on any information associated with the input item, the input sample, or any other data relation of the input object. See the [FieldValue Documentation](http://klavinslab.org/aquarium/api/FieldValue.html) for a reference of all the attributes of input objects. Input objects are a form of a FieldValue object.\n\nIf you would like to encode an arbitrary conditional expression to be evaluated in the namespace of the functional block rather than fields of the input object, append the condition for that route with `:::`\n\n\n```\n  {\n    [\n        \':::User.find(op.plan.user_id).name == \"Abe Miller\"\',\n        \':::User.find(op.plan.user_id).name == \"Bill Gates\"\',\n    ]\n  }\n```\n\nNow, if Abe owns the plan, branch 0 will run. If Bill owns the plan, branch 1 will run. And if someone else besides Abe or Bill owns the plan, then both branches will cancel. \n',18,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(558,'test','',18,'OperationType','2020-03-24 15:41:56','2020-03-24 15:41:56',1),(559,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',19,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(560,'precondition','def precondition(_op)\n    _op = Operation.find(_op.id)\n    channel = _op.input(\"Channel\").val\n    key = \"Channel #{channel} status\"\n    \n    plan = _op.plan\n  \n    if plan\n        if _op.inputs.length == 0\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        senders = get_senders(_op)\n        selector = _op.input(\"Selection Method\").val\n        \n        sender = nil\n        \n        case selector\n        when \"First\"\n            sender = senders.first\n        when \"Last\"\n            sender = senders.last\n        when \"Random\"\n            sender = sender.sample\n        end\n        \n        if sender.nil?\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        \n        item = sender.output(\"Output\").item\n        plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n        \n        _op.set_input(\"Input\", item.sample)\n        _op.output(\"Output\").set(item: item)\n        _op.status = \"done\"\n        _op.save\n        \n    end\n  \n    return false\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',19,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(561,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',19,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(562,'documentation','A `Listen to Channel` operation listens for items to be generated by the `Send to Channel` operation. The **channel** is set by the **Channel** input parameter. The Sample and the Channel between `Listen to Channel` and `Send to Channel` must be the same for the operations to talk to each other. \n\nThe selection method when multiple items are available is available in the **Selection Method** input parameter.\n\nUse in conjunction with `Wait for All` to synchronize all items.',19,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(563,'test','',19,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(564,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',20,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(565,'precondition','eval Library.find_by_name(\"ControlBlock\").code(\"source\").content\nextend ControlBlock\n\n\ndef precondition(_op)\n  if _op.plan\n    input_fv = \"Input\"\n    yes_fv = \"True Response\"\n    no_fv = \"False Response\"\n    yes_output = \"True\"\n    no_output = \"False\"\n\n    # level = _op.input(\"Response Level\").val\n    level = \"Plan\"\n    yes = _op.input(yes_fv).val.downcase\n    no = _op.input(no_fv).val.downcase\n    choices = [yes, no]\n    message = _op.input(\"Response\").val\n    precondition_key = \"Respond to Key-Value Association (\\\"#{message}\\\" for #{level})\"\n    plan_key = \"(#{_op.id}) \" + precondition_key\n\n    #   res = \"\"\n    case level\n    when \"Plan\"\n      res = _op.plan.get(message)\n    when \"Operation\"\n      res = _op.get(message)\n    when \"Sample\"\n      res = _op.input(input_fv).sample.properties[message].to_s\n      _op.associate(\"debug\", res)\n    when \"Item\"\n      res = _op.input(input_fv).item.get(message)\n    end\n    res ||= \"\"\n    response_message = \"No true or false response found.\"\n    if res.downcase == yes.downcase\n      response_message = \"True response found (#{yes}).\"\n      _op.output(yes_output).set(item: _op.input(input_fv).item)\n      _op.output(no_output).set(item: nil)\n      cancel_branches [_op.output(no_output)]\n      _op.pass(\"Input\", \"True\")\n      op = Operation.find(_op.id)\n      op.status = \"done\"\n      op.save()\n    elsif res.downcase == no.downcase\n      response_message = \"False response found (#{no}).\"\n      _op.output(no_output).set(item: _op.input(input_fv).item)\n      _op.output(yes_output).set(item: nil)\n      cancel_branches [_op.output(yes_output)]\n      op = Operation.find(_op.id)\n      op.status = \"done\"\n      op.save()\n    end\n    _op.associate(precondition_key, response_message)\n    _op.plan.associate(plan_key, response_message)\n  end\n  return false\nend',20,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(566,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',20,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(567,'documentation','Similar to Wiat for User Input, but does not create the key-value in the plan',20,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(568,'test','',20,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(569,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',21,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(570,'precondition','eval Library.find_by_name(\"ControlBlock\").code(\"source\").content\nextend ControlBlock\n\n# Generic response block that is fully paramaterizable from the planner. Asks user for a response,\n# waits for the response before continuing, then once the response is recieved: associates\n# response to the item being passed through this operation and continues the workflow \ndef precondition(_op)\n    # gain access to operation instance methods \n    op = Operation.find(_op.id)\n    \n    # get params\n    response_request = op.input(\"Response Request Message\").val\n    response_regex = op.input(\"Response Regex Format\").val\n    response_tag = op.input(\"Response Tag\").val\n    response_status_tag = \"Response Block status\"\n    response_level = op.input(\"Response Level\").val\n    \n    case response_level\n    when \"Plan\"\n        obj = _op.plan\n        response_tag += \" [#{_op.id}]\"\n        response_status_tag += \" [#{_op.id}]\"\n    when \"Operation\"\n        obj = _op\n    when \"Item\"\n        obj = _op.input(\"Sample\").item\n    end\n    \n    # library method from ControlBlock (Could this interface be improved?)\n    user_response = get_user_response(op, response_request_message: response_request, response_regex: response_regex)\n    \n    # if the user hasn\'t responded yet, fail and keep downstream operations in waiting\n    return false if user_response.nil?\n    \n    # Response recieved!\n    \n    # associate response to the item being passed through\n    obj.associate(response_tag, user_response)\n    \n    # associate note on operation to indicate that you cant retroactively change response\n    op.associate \"Response Block status\", \"Your response was successfully recorded as \\\"#{user_response}\\\"\"\n    \n    # pass input, allowing downstream operations to begin\n    op.pass(\"Sample\", \"Sample\")\n\n    # set status to done, so this block will not be evaluated again\n    op.status = \"done\"\n    op.save\n    \n    return true\nend',21,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(571,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',21,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(572,'documentation','**WARNING: BETA VERSION. USE WITH CAUTION**\n\nCollect a response from the researcher to be associated with the item that passes through this block.\nThe association on this item will have downstream effects on the workflow.\n\n**Inputs**\nResponse Request Message - message for user to send response\n\nResponse Tag - the data association key that will associate the response\n\n\n\nValidate user input by optionally providing a regex format. All input that doesn\'t conform to the regex format will be denied.\n\nSee <a href=\"http://rubular.com/\">rubular</a> for testing your regex expressions\n',21,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(573,'test','',21,'OperationType','2020-03-24 15:41:57','2020-03-24 15:41:57',1),(574,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',22,'OperationType','2020-03-24 15:41:58','2020-03-24 15:41:58',1),(575,'precondition','def precondition(_op)\n    #   this is done so that Operation instance methods are available\n    _op = Operation.find(_op)\n#-----------------------------------------------------------------------------------------\n\n    #   pass input, allowing downstream operations to begin\n    _op.pass(\"Input\", \"Output\")\n\n    #   set status to done, so this block will not be evaluated again\n    _op.status = \"done\"\n    _op.save\n    \n    return true\nend',22,'OperationType','2020-03-24 15:41:58','2020-03-24 15:41:58',1),(576,'cost_model','def cost(op)\n  { labor: 0, materials: 0 }\nend',22,'OperationType','2020-03-24 15:41:58','2020-03-24 15:41:58',1),(577,'documentation','Sends the item to a *channel*. A `Listen to Channel` operation listens for items to be generated by the `Send to Channel` operation. The **channel** is set by the **Channel** input parameter. The Sample and the Channel between `Listen to Channel` and `Send to Channel` must be the same for the operations to talk to each other. Use in conjunction with `Wait for All` to synchronize all items.',22,'OperationType','2020-03-24 15:41:58','2020-03-24 15:41:58',1),(578,'test','',22,'OperationType','2020-03-24 15:41:58','2020-03-24 15:41:58',1),(579,'source','# ControlBlock module has library methods for use in preconditions and functional blocks\n# that cover common use cases of implementing control structures and decision logic into aquarium plans\n#\nmodule ControlBlock\n\n  # Convienence method for debugging preconditions and functional Blocks\n  def log_out op, str\n    op.associate str, \"debugging log\"\n  end\n\n  # DynamicBranching module has methods that are helpful for programming functional blocks which\n  # control execution of a plan in full or part.\n  # Theoretically these methods could be called from any operations, to affect any other operations, regardless\n  # of if they are functional blocks. The intended use case is for them to be run from a functional block code,\n  # to affect the outputs and wires of that same functional block.\n  # NOTE: Correct use of routing ids while definiting functional blocks is crucial for\n  # taking advantage of this module\n  # module DynamicBranching\n\n  # Triggers execution of a subset of the possible output branches from an operation by satisfying their item\n  # No new output items are made by this call, branches are triggered when the routed input is passed through to outputs\n  # Output branches are assumed to be proper forkings from the same input, they should all be routed from this input\n  #\n  # @param outputs  [Array<FieldValue>] affirmed outputs that will recieve items\n  def affirm_branches outputs\n    begin\n      op = outputs.map { |output| output.operation }.uniq.first\n      route = outputs.map { |output| FieldType.find(output.field_type_id).routing }.uniq.first\n      input = op.inputs.select { |input| FieldType.find(input.field_type_id).routing == route }.uniq.first\n    rescue IndexError\n      raise \"in a operation/block which affirms a subset of its outputs, the outputs must be proper forkings of a single input from that block (sharing route id)\"\n    end\n    outputs.each do |output|\n      # pass input item up to good outputs\n      output.set item: input.item\n      output.save\n    end\n  end\n\n  # For each output in the given list of outputs, errors the full downstream branch\n  # Can be used in conjunction with affirm_branches to make functional blocks which trigger\n  # execution of some branches and error the rest\n  #\n  # @param outputs  [Array<FieldValue>] outputs that start a path towards a branch that will be cancelled\n  def cancel_branches outputs, message=nil\n    threads = []\n    outputs.each do |bad_out|\n      threads << Thread.new do\n        bad_out.wires_as_source.each do |bad_wire|\n          bad_op = FieldValue.find(bad_wire.to_id).operation\n          recursively_error_downstream(bad_op, message)\n          # bad_wire.delete\n        end\n      end\n    end\n\n    threads.each { |thr| thr.join }\n\n    plan = outputs[0].operation.plan\n\n    outputs.each do |bad_out|\n      bad_out.wires_as_source.each do |bad_wire|\n        to_op = bad_wire.to.operation\n\n        # create new \"Canceled\" operation, with single input and output\n        ot = OperationType.where({\"deployed\"=> true, \"name\"=>\"Canceled\", \"Category\"=>bad_out.operation.operation_type.category})[0]\n        new_op = ot.operations.create(status: \"error\", user_id: plan.user_id)\n\n        # create new input\n        input_aft = ot.field_types.find {|ft| ft.name == \"Input\"}.allowable_field_types[0]\n        new_op.set_property \"Input\", bad_out.sample, \"input\", false, nil\n        new_op.input(\"Input\").set item: nil\n\n        # create new output\n        output_aft = ot.field_types.find {|ft| ft.name == \"Output\"}.allowable_field_types[0]\n        new_op.set_property \"Output\", bad_out.sample, \"output\", false, nil\n        new_op.output(\"Output\").set item: nil\n\n        # adjust coordinates\n        new_op.x = to_op.x\n        new_op.y = to_op.y + 75\n        new_op.save()\n\n        new_wire = Wire.new from_id: new_op.outputs[0].id, to_id: bad_wire.to_id\n        new_wire.save()\n\n        plan.plan_associations.create operation_id: new_op.id\n        bad_wire.to_id = new_op.inputs[0].id\n        bad_wire.save()\n      end\n    end\n    outputs[0].operation.plan.save()\n  end\n\n  # ot = OperationType.find_by_name(\"Clean Up Sequencing\")\n  # new_op = ot.operations.create(\n  #     status: \"waiting\",\n  #     user_id: op.user_id\n  # )\n  # op.plan.plan_associations.create operation_id: new_op.id\n  #\n  # aft = ot.field_types.find {|ft| ft.name == \"Stock\"}.allowable_field_types[0]\n  # new_op.set_property \"Stock\", stock.sample, \"input\", false, aft\n  # new_op.input(\"Stock\").set item: stock\n  #\n  # aft = ot.field_types.find {|ft| ft.name == \"Plate\"}.allowable_field_types[0]\n  # new_op.set_property \"Plate\", stock.sample, \"input\", false, aft\n  # new_op.input(\"Plate\").set item: plate\n  #\n  # op.plan.reload\n  # new_op.reload\n  #\n  # Recursively error all operations in the downstream branch, starting from the given root op\n  def recursively_error_downstream(op, message=nil)\n    if op.status != \"error\"\n      op.change_status(\"error\")\n      err_msg = message || \"this operation was canceled by a control block\"\n      op.associate(\"canceled\", err_msg)\n      next_ops = collect_downstream_ops(op)\n      next_ops.each do |nop|\n        recursively_error_downstream(nop)\n      end\n    end\n  end\n\n  # Return an array of the direct downstream children of the given operation\n  # TODO if speed becomes an issue for recuresively navigating branches, this algorithm could be improved\n  def collect_downstream_ops(op)\n    op.outputs.map { |out| out.wires_as_source.map { |wire| FieldValue.find(wire.to_id).operation } }.flatten\n  end\n  # end\n\n  # UI module has methods for (in the plan view) requesting input from the user\n  # and showing output to the user\n  #\n  # module UI\n  # Creates an input box for accepting user response in the given operation\n  # Returns nil and notifies user until user responds correctly in\n  # the input box for the given operation and once a response is recieved, returns that response\n  #\n  # @param op  [Operation] the operation to which the user must respond to\n  # @param opts  [Hash] required method arguments, specifying how to collect response\n  # @option response_request_message  [String] the label of the input textbox shown to user\n  # @option response_regex  [String]  Regex expression as a string to validate user response\n  #                           by default no validation will be done\n  # @return  [String] user response if given, nil if still waiting on response\n  def get_user_response(op, opts = {})\n    response_request = opts[:response_request_message]\n    response_regex = opts[:response_regex]\n\n    # TODO parameterize notifications with operation type name so they can be found on plan easier\n\n    # Notifications for user while waiting on response, or for when response fails to meet required format\n    plan_waiting_notification = \"Waiting for your input on operation #{op.id}\"\n    plan_rejection_notification = \"Response rejected on operation #{op.id}. Expects pattern \\\"#{response_regex}\\\"\"\n    op_rejection_notification = \"Given response did not meet the required format\"\n    generic_disclaimer = \"Plan will not move forward until a response is received\"\n\n    # Generate input textbox for user if it does not yet exist\n    # Alert user on plan that there is an operation awaiting their input\n    op_response = op.get(response_request)\n    if op_response.nil? || op_response == \"\"\n      op.associate(response_request, \"\")\n      op.plan.associate(plan_waiting_notification, generic_disclaimer) if op.plan\n      return nil\n    end\n\n    # Response recieved - validate response with regex, if regex given\n    # If response fails format, notify user\n    if response_regex && response_regex != \"\" && !(Regexp.new(response_regex).match(op_response))\n      op.associate(op_rejection_notification, generic_disclaimer)\n      op.plan.associate(plan_rejection_notification, generic_disclaimer)\n      return nil\n    end\n\n    # Response is valid - Remove notifications that remind user to answer response\n    op.plan.get_association(plan_waiting_notification).delete if op.plan.get_association(plan_waiting_notification)\n    op.plan.get_association(plan_rejection_notification).delete if op.plan.get_association(plan_rejection_notification)\n    op.get_association(op_rejection_notification).delete if op.get_association(op_rejection_notification)\n\n    # return response\n    return op_response\n  end\n  # end\nend',13,'Library','2020-03-24 15:41:58','2020-03-24 15:41:58',1),(580,'protocol','# frozen_string_literal: true\n\n# This is a default, one-size-fits all protocol that shows how you can\n# access the inputs and outputs of the operations associated with a job.\n# Add specific instructions for this protocol!\n\nclass Protocol\n\n  def main\n\n    operations.retrieve.make\n\n    tin  = operations.io_table \'input\'\n    tout = operations.io_table \'output\'\n\n    show do\n      title \'Input Table\'\n      table tin.all.render\n    end\n\n    show do\n      title \'Output Table\'\n      table tout.all.render\n    end\n\n    operations.store\n\n    {}\n\n  end\n\nend\n',23,'OperationType','2020-03-24 15:49:42','2020-03-24 15:49:42',1),(581,'precondition','def precondition(_op)\n  true\nend',23,'OperationType','2020-03-24 15:49:42','2020-03-24 15:49:42',1),(582,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',23,'OperationType','2020-03-24 15:49:42','2020-03-24 15:49:42',1),(583,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',23,'OperationType','2020-03-24 15:49:42','2020-03-24 15:49:42',1),(584,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',23,'OperationType','2020-03-24 15:52:04','2020-03-24 15:52:04',1),(585,'precondition','def precondition(_op)\n    _op = Operation.find(_op.id)\n    channel = _op.input(\"Channel\").val\n    key = \"Channel #{channel} status\"\n    \n    plan = _op.plan\n  \n    if plan\n        if _op.inputs.length == 0\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        senders = get_senders(_op)\n        selector = _op.input(\"Selection Method\").val\n        \n        sender = nil\n        \n        case selector\n        when \"First\"\n            sender = senders.first\n        when \"Last\"\n            sender = senders.last\n        when \"Random\"\n            sender = sender.sample\n        end\n        \n        if sender.nil?\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        \n        item = sender.output(\"Output\").item\n        plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n        \n        _op.set_input(\"Input\", item.sample)\n        _op.output(\"Output\").set(item: item)\n        _op.status = \"done\"\n        _op.save\n        \n    end\n  \n    return false\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 15:52:15','2020-03-24 15:52:15',1),(586,'protocol','# frozen_string_literal: true\n\n# This is a default, one-size-fits all protocol that shows how you can\n# access the inputs and outputs of the operations associated with a job.\n# Add specific instructions for this protocol!\n\nclass Protocol\n\n  def main\n\n    operations.retrieve.make\n\n    tin  = operations.io_table \'input\'\n    tout = operations.io_table \'output\'\n\n    show do\n      title \'Input Table\'\n      table tin.all.render\n    end\n\n    show do\n      title \'Output Table\'\n      table tout.all.render\n    end\n\n    operations.store\n\n    {}\n\n  end\n\nend\n',24,'OperationType','2020-03-24 15:59:46','2020-03-24 15:59:46',1),(587,'precondition','def precondition(_op)\n  true\nend',24,'OperationType','2020-03-24 15:59:46','2020-03-24 15:59:46',1),(588,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',24,'OperationType','2020-03-24 15:59:46','2020-03-24 15:59:46',1),(589,'documentation','Documentation here. Start with a paragraph, not a heading or title, as in most views, the title will be supplied by the view.',24,'OperationType','2020-03-24 15:59:46','2020-03-24 15:59:46',1),(590,'protocol','class Protocol\n\n  def main\n\n    operations.each do |op|\n        op.error(\"Control block error\", \"Control blocks are not intended to be run by a technician.\") \n    end\n\n  end\n\nend\n',24,'OperationType','2020-03-24 16:02:30','2020-03-24 16:02:30',1),(591,'precondition','def precondition(_op)\n    #   this is done so that Operation instance methods are available\n    _op = Operation.find(_op)\n#-----------------------------------------------------------------------------------------\n\n    #   pass input, allowing downstream operations to begin\n    _op.pass(\"Input\", \"Output\")\n\n    #   set status to done, so this block will not be evaluated again\n    _op.status = \"done\"\n    _op.save\n    \n    return true\nend',24,'OperationType','2020-03-24 16:02:41','2020-03-24 16:02:41',1),(592,'cost_model','Sends the item to a *channel*. A `Listen to Channel` operation listens for items to be generated by the `Send to Channel` operation. The **channel** is set by the **Channel** input parameter. The Sample and the Channel between `Listen to Channel` and `Send to Channel` must be the same for the operations to talk to each other. Use in conjunction with `Wait for All` to synchronize all items.',24,'OperationType','2020-03-24 16:06:03','2020-03-24 16:06:03',1),(593,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-24 17:56:55','2020-03-24 17:56:55',1),(594,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-24 17:56:56','2020-03-24 17:56:56',1),(595,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This Protocol is to Quality check the C-DNA created.\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(QC2_KEY, \"Pass\")\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(QC2_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will assume to pass\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',2,'OperationType','2020-03-24 17:56:56','2020-03-24 17:56:56',1),(596,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    working_plate = make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-24 18:21:00','2020-03-24 18:21:00',1),(597,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    working_plate = make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-24 18:21:01','2020-03-24 18:21:01',1),(598,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\n\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement, CollectionActions\n  include WorkflowValidation, CommonInputOutputNames, KeywordLib\n  C_TYPE = \"96 Well Sample Plate\"\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n\n    validate_inputs(operations, inputs_match_outputs = true)\n\n    validate_cdna_qc(operations)\n\n    multi_plate = multi_input_plates?(operations)\n\n    working_plate = make_new_plate(C_TYPE, multi_plate)\n  \n    operations.retrieve\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      output_fv_array = op.output_array(OUTPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      make_output_plate(output_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL) if multi_plate\n    end\n\n    if !multi_plate\n      input_plate = operations.first.input_array(INPUT_ARRAY).first.collection\n      relabel_plate(input_plate,working_plate) if !multi_plate\n      input_plate.mark_as_deleted\n    else\n      trash_object(get_array_of_collections(operations, \'input\')) if multi_plate\n    end\n\n    normalization_pooling(working_plate)\n\n    store_output_collections(operations, \'Freezer\')\n  end\n\n  #Instructions for performing RNA_PREP\n  #\n  # @working_plate collection the plate that has all samples in it\n  def normalization_pooling(working_plate)\n    show do\n      title \"Do the Normalization Pooling Steps\"\n      note \"Run typical Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate)\n    end\n  end\nend\n',3,'OperationType','2020-03-24 18:21:01','2020-03-24 18:21:01',1),(599,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.make\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-24 18:30:56','2020-03-24 18:30:56',1),(600,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.make\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-24 18:30:56','2020-03-24 18:30:56',1),(601,'protocol','#Cannon Mallory\n#UW-BIOFAB\n#03/04/2019\n#malloc3@uw.edu\n#\n#\n#This protocol is for total RNA QC.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a QC protocols including\n#getting the concentrations of the original sampole.  These concentrations will then be associated\n#with the original sample for use later.\n\n\n#Currently build plate needs a bit of work.  It works by order of input array and not by order of sample location on plate\n\n\nneeds \"Standard Libs/Debug\"\nneeds \"Standard Libs/CommonInputOutputNames\"\nneeds \"Standard Libs/Units\"\nneeds \"Collection_Management/CollectionDisplay\"\nneeds \"Collection_Management/CollectionTransfer\"\nneeds \"Collection_Management/CollectionActions\"\nneeds \"Collection_Management/SampleManagement\"\nneeds \"RNA_Seq/WorkflowValidation\"\nneeds \"RNA_Seq/KeywordLib\"\n\n\nclass Protocol\n  include Debug, CollectionDisplay, CollectionTransfer, SampleManagement\n  include CollectionActions, WorkflowValidation, CommonInputOutputNames, KeywordLib\n\n  TRANSFER_VOL = 20   #volume of sample to be transfered in ul\n\n\n  def main\n    validate_inputs(operations)\n    \n    working_plate = make_new_plate(C_TYPE)\n    \n    operations.retrieve\n\n    operations.make\n\n    operations.each do |op|\n      input_fv_array = op.input_array(INPUT_ARRAY)\n      add_fv_array_samples_to_collection(input_fv_array, working_plate)\n      transfer_from_array_collections(input_fv_array, working_plate, TRANSFER_VOL)\n    end\n    \n    store_input_collections(operations)\n    take_qc_measurments(working_plate)\n    trash_object(working_plate)\n\n  end\n\n\n  # Instruction on taking the QC measurements themselves.\n  # Currently not operational but associates random concentrations for testing\n  #\n  #TODO complete this and make it actually look at CSV Files\n  def take_qc_measurments(working_plate)\n    input_rcx = []\n    operations.each do |op|\n      input_array = op.input_array(INPUT_ARRAY)\n      input_items = input_array.map{|fv| fv.item}\n      arry_sample = input_array.map{|fv| fv.sample}\n      input_items.each_with_index do |item, idx|\n        item.associate(CON_KEY, rand(50..100))\n        sample = arry_sample[idx]\n        working_plate_loc_array = working_plate.find(sample)\n        working_plate_loc_array.each do |sub_array|\n          sub_array.push(\"#{item.get(CON_KEY)}\")\n          input_rcx.push(sub_array)\n        end\n      end\n    end\n\n    show do\n      title \"Perform QC Measurements\"\n      note \"Please Attach excel files\"\n      note \"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"\n      note \"This will eventually come from a CSV file\"\n      table highlight_rcx(working_plate, input_rcx)\n    end\n  end\nend\n',5,'OperationType','2020-03-24 18:30:57','2020-03-24 18:30:57',1),(602,'documentation','Sends the item to a *channel*. A `Listen to Channel` operation listens for items to be generated by the `Send to Channel` operation. The **channel** is set by the **Channel** input parameter. The Sample and the Channel between `Listen to Channel` and `Send to Channel` must be the same for the operations to talk to each other. Use in conjunction with `Wait for All` to synchronize all items.',24,'OperationType','2020-03-24 19:01:52','2020-03-24 19:01:52',1),(603,'cost_model','def cost(_op)\n  { labor: 0, materials: 0 }\nend',24,'OperationType','2020-03-24 19:02:02','2020-03-24 19:02:02',1),(604,'precondition','def precondition(_op)\n    _op = Operation.find(_op.id)\n    channel = _op.input(\"Channel\").val\n    key = \"Channel #{channel} status\"\n    \n    plan = _op.plan\n  \n    if plan\n        if _op.inputs.length == 0\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        senders = get_senders(_op)\n        selector = _op.input(\"Selection Method\").val\n        \n        sender = nil\n        \n        case selector\n        when \"First\"\n            sender = senders.first\n        when \"Last\"\n            sender = senders.last\n        when \"Random\"\n            sender = sender.sample\n        end\n        \n        if sender.nil?\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        \n        item = sender.output(\"Output\").item\n        plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n        \n        _op.set_input(\"Input\", item.sample)\n        _op.output(\"Output\").set(item: item)\n        _op.status = \"done\"\n        _op.save\n        \n    end\n  \n    return True\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 19:55:47','2020-03-24 19:55:47',1),(605,'precondition','def precondition(_op)\n    _op = Operation.find(_op.id)\n    channel = _op.input(\"Channel\").val\n    key = \"Channel #{channel} status\"\n    \n    plan = _op.plan\n  \n    if plan\n        if _op.inputs.length == 0\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        senders = get_senders(_op)\n        selector = _op.input(\"Selection Method\").val\n        \n        sender = nil\n        \n        case selector\n        when \"First\"\n            sender = senders.first\n        when \"Last\"\n            sender = senders.last\n        when \"Random\"\n            sender = sender.sample\n        end\n        \n        if sender.nil?\n            plan.associate(key, \"Listening for items...\")\n            return false\n        end\n        \n        item = sender.output(\"Output\").item\n        plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n        \n        _op.set_input(\"Input\", item.sample)\n        _op.output(\"Output\").set(item: item)\n        _op.status = \"done\"\n        _op.save\n        \n    end\n  \n    return true\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 20:02:20','2020-03-24 20:02:20',1),(606,'precondition','def precondition(_op)\n    #_op = Operation.find(_op.id)\n    #channel = _op.input(\"Channel\").val\n    #key = \"Channel #{channel} status\"\n    \n    #plan = _op.plan\n  \n    #if plan\n    #    if _op.inputs.length == 0\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    senders = get_senders(_op)\n    #    selector = _op.input(\"Selection Method\").val\n    #    \n    #    sender = nil\n    #    \n    #    case selector\n    #    when \"First\"\n    #        sender = senders.first\n    #    when \"Last\"\n    #        sender = senders.last\n    #    when \"Random\"\n    #        sender = sender.sample\n    #    end\n    #    \n    #    if sender.nil?\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    \n    #    item = sender.output(\"Output\").item\n    #    plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n    #    \n    #    _op.set_input(\"Input\", item.sample)\n    #    _op.output(\"Output\").set(item: item)\n    #    _op.status = \"done\"\n    #    _op.save\n    #    \n    end\n  \n    return true\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 20:05:10','2020-03-24 20:05:10',1),(607,'precondition','def precondition(_op)\n    #_op = Operation.find(_op.id)\n    #channel = _op.input(\"Channel\").val\n    #key = \"Channel #{channel} status\"\n    \n    #plan = _op.plan\n  \n    #if plan\n    #    if _op.inputs.length == 0\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    senders = get_senders(_op)\n    #    selector = _op.input(\"Selection Method\").val\n    #    \n    #    sender = nil\n    #    \n    #    case selector\n    #    when \"First\"\n    #        sender = senders.first\n    #    when \"Last\"\n    #        sender = senders.last\n    #    when \"Random\"\n    #        sender = sender.sample\n    #    end\n    #    \n    #    if sender.nil?\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    \n    #    item = sender.output(\"Output\").item\n    #    plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n    #    \n    #    _op.set_input(\"Input\", item.sample)\n    #    _op.output(\"Output\").set(item: item)\n    #    _op.status = \"done\"\n    #    _op.save\n    #    \n    #end\n  \n    return true\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 20:05:16','2020-03-24 20:05:16',1),(608,'precondition','def precondition(_op)\n    #_op = Operation.find(_op.id)\n    #channel = _op.input(\"Channel\").val\n    #key = \"Channel #{channel} status\"\n    \n    #plan = _op.plan\n  \n    #if plan\n    #    if _op.inputs.length == 0\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    senders = get_senders(_op)\n    #    selector = _op.input(\"Selection Method\").val\n    #    \n    #    sender = nil\n    #    \n    #    case selector\n    #    when \"First\"\n    #        sender = senders.first\n    #    when \"Last\"\n    #        sender = senders.last\n    #    when \"Random\"\n    #        sender = sender.sample\n    #    end\n    #    \n    #    if sender.nil?\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    \n    #    item = sender.output(\"Output\").item\n    #    plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n    #    \n    #    _op.set_input(\"Input\", item.sample)\n    #    _op.output(\"Output\").set(item: item)\n    #    _op.status = \"done\"\n    #    _op.save\n    #    \n    #end\n    _op.status = \"done\"\n    _op.save\n    return true\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 20:09:26','2020-03-24 20:09:26',1),(609,'precondition','def precondition(_op)\n    _op = Operation.find(_op.id)\n    #channel = _op.input(\"Channel\").val\n    #key = \"Channel #{channel} status\"\n    \n    #plan = _op.plan\n  \n    #if plan\n    #    if _op.inputs.length == 0\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    senders = get_senders(_op)\n    #    selector = _op.input(\"Selection Method\").val\n    #    \n    #    sender = nil\n    #    \n    #    case selector\n    #    when \"First\"\n    #        sender = senders.first\n    #    when \"Last\"\n    #        sender = senders.last\n    #    when \"Random\"\n    #        sender = sender.sample\n    #    end\n    #    \n    #    if sender.nil?\n    #        plan.associate(key, \"Listening for items...\")\n    #        return false\n    #    end\n    #    \n    #    item = sender.output(\"Output\").item\n    #    plan.associate(key, \"Selected #{selector.downcase} item ##{item.id} from operation ##{sender.id}\")\n    #    \n    #    _op.set_input(\"Input\", item.sample)\n    #    _op.output(\"Output\").set(item: item)\n    #    _op.status = \"done\"\n    #    _op.save\n    #    \n    #end\n    _op.status = \"done\"\n    _op.save\n    return true\nend\n\ndef get_senders(listener_op)\n    op_type_name = \"[ADV USERS ONLY] Send to Channel\"\n    send_op_type = OperationType.where({\"name\": op_type_name, \"category\": listener_op.operation_type.category}).first\n    if send_op_type.nil?\n        listener_op.associate(\"no sender type found\", \"No OperationType #{op_type_name} found.\")\n        return []\n    end\n    \n    senders = plan.operations.select { |op| op.operation_type.id == send_op_type.id }\n    senders.select! { |op| op.input(\"Channel\").val == listener_op.input(\"Channel\").val }\n    senders.select! { |op| op.output(\"Output\").sample.id == listener_op.output(\"Output\").sample.id }\n    senders.select! { |op| !op.output(\"Output\").item.nil? }\n    return senders\nend',23,'OperationType','2020-03-24 20:10:13','2020-03-24 20:10:13',1);
/*!40000 ALTER TABLE `codes` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `data_associations`
--

DROP TABLE IF EXISTS `data_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `data_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `parent_class` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `key` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `upload_id` int(11) DEFAULT NULL,
  `object` text COLLATE utf8_unicode_ci,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_data_associations_on_upload_id` (`upload_id`)
) ENGINE=InnoDB AUTO_INCREMENT=468 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `data_associations`
--

LOCK TABLES `data_associations` WRITE;
/*!40000 ALTER TABLE `data_associations` DISABLE KEYS */;
INSERT INTO `data_associations` VALUES (1,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 4, 3 was changed from 297 to 272.\"}','2020-03-19 18:45:48','2020-03-19 18:45:48'),(2,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 0, 5 was changed from 283 to 285.\"}','2020-03-19 18:47:39','2020-03-19 18:47:39'),(3,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 6, 5 was changed from 292 to 291.\"}','2020-03-19 18:49:15','2020-03-19 18:49:15'),(4,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 7, 5 was changed from 293 to 292.\"}','2020-03-19 18:49:27','2020-03-19 18:49:27'),(5,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 5, 6 was changed from 323 to 323.\"}','2020-03-19 18:53:09','2020-03-19 18:53:09'),(6,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 5, 6 was changed from 323 to 323.\"}','2020-03-19 18:53:16','2020-03-19 18:53:16'),(7,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 5, 6 was changed from 323 to 298.\"}','2020-03-19 18:53:24','2020-03-19 18:53:24'),(8,3,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 6, 9 was changed from 245 to 323.\"}','2020-03-19 18:58:21','2020-03-19 18:58:21'),(9,100,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 3, 7 was changed from 532 to 533.\"}','2020-03-19 19:13:56','2020-03-19 19:13:56'),(13,5,'Operation','csv',NULL,'{\"csv\":[{\"id\":3,\"job_id\":6,\"upload_file_name\":\"Oligos.csv\",\"upload_content_type\":\"text/plain\",\"upload_file_size\":3294,\"upload_updated_at\":\"2020-03-19T13:36:26.000-07:00\",\"created_at\":\"2020-03-19T13:36:26.000-07:00\",\"updated_at\":\"2020-03-19T13:36:26.000-07:00\"}]}','2020-03-19 20:21:04','2020-03-19 20:36:27'),(14,5,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-19 by Joe Neptune\"}','2020-03-19 20:34:39','2020-03-19 20:34:39'),(15,5,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 6 crashed\"}','2020-03-19 20:35:36','2020-03-19 20:36:28'),(16,5,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-19 by Joe Neptune\"}','2020-03-19 20:36:15','2020-03-19 20:36:15'),(38,32,'Plan','replan',NULL,'{\"replan\":\"Based on plan 4. Replanned 2020-03-20.\"}','2020-03-20 16:58:17','2020-03-20 16:58:17'),(39,200,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 6, 0 was changed from 7 to 8.\"}','2020-03-20 18:41:29','2020-03-20 18:41:29'),(40,200,'Collection','Sample Reassigned',NULL,'{\"Sample Reassigned\":\"The sample at 6, 0 was changed from 8 to 7.\"}','2020-03-20 18:41:36','2020-03-20 18:41:36'),(72,200,'Item','Stock Conc (ng/ul)',NULL,'{\"Stock Conc (ng/ul)\":58}','2020-03-23 20:11:20','2020-03-24 20:02:53'),(73,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 20:11:56','2020-03-23 20:11:56'),(74,6,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 84 crashed\"}','2020-03-23 20:14:13','2020-03-24 00:32:16'),(75,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 20:16:44','2020-03-23 20:16:44'),(76,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 20:17:18','2020-03-23 20:17:18'),(77,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 20:20:53','2020-03-23 20:20:53'),(78,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 20:22:11','2020-03-23 20:22:11'),(79,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:12:10','2020-03-23 21:12:10'),(80,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:19:26','2020-03-23 21:19:26'),(81,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:20:01','2020-03-23 21:20:01'),(85,6,'Operation','aborted',NULL,'{\"aborted\":\"Operation was canceled when job 82 was aborted\"}','2020-03-23 21:22:59','2020-03-24 00:30:16'),(86,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:23:03','2020-03-23 21:23:03'),(87,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:23:59','2020-03-23 21:23:59'),(88,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:24:34','2020-03-23 21:24:34'),(89,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:25:31','2020-03-23 21:25:31'),(90,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 21:27:43','2020-03-23 21:27:43'),(91,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 22:49:18','2020-03-23 22:49:18'),(92,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 22:59:59','2020-03-23 22:59:59'),(93,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:00:14','2020-03-23 23:00:14'),(94,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:02:21','2020-03-23 23:02:21'),(95,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:04:08','2020-03-23 23:04:08'),(96,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:05:10','2020-03-23 23:05:10'),(97,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:05:19','2020-03-23 23:05:19'),(98,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:06:57','2020-03-23 23:06:57'),(99,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:10:10','2020-03-23 23:10:10'),(100,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:10:50','2020-03-23 23:10:50'),(101,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:10:50','2020-03-23 23:10:50'),(102,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:14:57','2020-03-23 23:14:57'),(103,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:22:07','2020-03-23 23:22:07'),(104,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:22:52','2020-03-23 23:22:52'),(105,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:24:12','2020-03-23 23:24:12'),(106,6,'Operation','input error',NULL,'{\"input error\":\"Could not find input Adapter Plate: - / -\"}','2020-03-23 23:26:10','2020-03-23 23:26:10'),(107,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:29:49','2020-03-23 23:29:49'),(108,6,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 363, 363\"}','2020-03-23 23:29:49','2020-03-23 23:29:49'),(109,363,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-23 23:29:49','2020-03-23 23:29:49'),(110,363,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-23 23:29:49','2020-03-23 23:29:49'),(111,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:32:36','2020-03-23 23:32:36'),(112,6,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 432, 432\"}','2020-03-23 23:32:36','2020-03-23 23:32:36'),(113,432,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-23 23:32:36','2020-03-23 23:32:36'),(114,432,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-23 23:32:36','2020-03-23 23:32:36'),(115,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:34:32','2020-03-23 23:34:32'),(116,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:45:28','2020-03-23 23:45:28'),(117,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:46:59','2020-03-23 23:46:59'),(118,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:49:08','2020-03-23 23:49:08'),(119,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:53:15','2020-03-23 23:53:15'),(120,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:56:30','2020-03-23 23:56:30'),(121,6,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 547, 547\"}','2020-03-23 23:56:30','2020-03-23 23:56:30'),(122,547,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-23 23:56:30','2020-03-23 23:56:30'),(123,547,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-23 23:56:30','2020-03-23 23:56:30'),(124,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:57:13','2020-03-23 23:57:13'),(125,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:58:06','2020-03-23 23:58:06'),(126,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:58:53','2020-03-23 23:58:53'),(127,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-23 23:59:41','2020-03-23 23:59:41'),(128,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-24 00:01:09','2020-03-24 00:01:09'),(129,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-24 00:30:20','2020-03-24 00:30:20'),(130,6,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 609, 609\"}','2020-03-24 00:30:20','2020-03-24 00:30:20'),(131,609,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-24 00:30:20','2020-03-24 00:30:20'),(132,609,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-24 00:30:20','2020-03-24 00:30:20'),(133,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-24 00:31:42','2020-03-24 00:31:42'),(134,696,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":100,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":5,\"created_at\":\"2020-03-19T12:05:36.000-07:00\",\"updated_at\":\"2020-03-19T12:05:36.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 00:32:16','2020-03-24 00:32:16'),(135,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-23 by Joe Neptune\"}','2020-03-24 00:32:51','2020-03-24 00:32:51'),(136,728,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":3,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":5,\"created_at\":\"2020-03-19T11:39:55.000-07:00\",\"updated_at\":\"2020-03-19T11:39:55.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(137,729,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":4,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:13.000-07:00\",\"updated_at\":\"2020-03-19T11:40:13.000-07:00\",\"inuse\":0,\"sample_id\":245,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(138,730,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":12,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:23.000-07:00\",\"updated_at\":\"2020-03-19T11:41:23.000-07:00\",\"inuse\":0,\"sample_id\":247,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(139,731,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":20,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:22.000-07:00\",\"updated_at\":\"2020-03-19T11:42:22.000-07:00\",\"inuse\":0,\"sample_id\":260,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(140,732,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":28,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:37.000-07:00\",\"updated_at\":\"2020-03-19T11:43:37.000-07:00\",\"inuse\":0,\"sample_id\":268,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(141,733,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":36,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:22.000-07:00\",\"updated_at\":\"2020-03-19T11:46:22.000-07:00\",\"inuse\":0,\"sample_id\":276,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(142,734,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":44,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:28.000-07:00\",\"updated_at\":\"2020-03-19T11:47:39.000-07:00\",\"inuse\":0,\"sample_id\":285,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(143,735,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":52,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:36.000-07:00\",\"updated_at\":\"2020-03-19T11:49:36.000-07:00\",\"inuse\":0,\"sample_id\":293,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(144,736,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":60,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:44.000-07:00\",\"updated_at\":\"2020-03-19T11:54:44.000-07:00\",\"inuse\":0,\"sample_id\":301,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(145,737,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":68,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:40.000-07:00\",\"updated_at\":\"2020-03-19T11:55:40.000-07:00\",\"inuse\":0,\"sample_id\":309,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(146,738,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":76,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:38.000-07:00\",\"updated_at\":\"2020-03-19T11:56:38.000-07:00\",\"inuse\":0,\"sample_id\":317,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(147,739,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":84,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:46.000-07:00\",\"updated_at\":\"2020-03-19T11:58:46.000-07:00\",\"inuse\":0,\"sample_id\":325,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(148,740,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":92,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:49.000-07:00\",\"updated_at\":\"2020-03-19T11:59:49.000-07:00\",\"inuse\":0,\"sample_id\":333,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(149,741,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":5,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:23.000-07:00\",\"updated_at\":\"2020-03-19T11:40:23.000-07:00\",\"inuse\":0,\"sample_id\":248,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(150,742,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":13,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:33.000-07:00\",\"updated_at\":\"2020-03-19T11:41:33.000-07:00\",\"inuse\":0,\"sample_id\":253,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(151,743,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":21,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:40.000-07:00\",\"updated_at\":\"2020-03-19T11:42:40.000-07:00\",\"inuse\":0,\"sample_id\":261,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(152,744,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":29,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:44.000-07:00\",\"updated_at\":\"2020-03-19T11:43:44.000-07:00\",\"inuse\":0,\"sample_id\":269,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(153,745,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":37,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:30.000-07:00\",\"updated_at\":\"2020-03-19T11:46:30.000-07:00\",\"inuse\":0,\"sample_id\":277,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(154,746,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":45,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:48.000-07:00\",\"updated_at\":\"2020-03-19T11:47:48.000-07:00\",\"inuse\":0,\"sample_id\":286,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(155,747,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":53,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:45.000-07:00\",\"updated_at\":\"2020-03-19T11:49:45.000-07:00\",\"inuse\":0,\"sample_id\":294,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(156,748,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":61,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:49.000-07:00\",\"updated_at\":\"2020-03-19T11:54:49.000-07:00\",\"inuse\":0,\"sample_id\":302,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(157,749,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":69,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:49.000-07:00\",\"updated_at\":\"2020-03-19T11:55:49.000-07:00\",\"inuse\":0,\"sample_id\":310,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(158,750,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":77,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:27.000-07:00\",\"updated_at\":\"2020-03-19T11:57:27.000-07:00\",\"inuse\":0,\"sample_id\":318,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(159,751,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":85,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:57.000-07:00\",\"updated_at\":\"2020-03-19T11:58:57.000-07:00\",\"inuse\":0,\"sample_id\":326,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(160,752,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":93,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:58.000-07:00\",\"updated_at\":\"2020-03-19T11:59:58.000-07:00\",\"inuse\":0,\"sample_id\":334,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(161,753,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":6,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:35.000-07:00\",\"updated_at\":\"2020-03-19T11:40:35.000-07:00\",\"inuse\":0,\"sample_id\":249,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(162,754,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":14,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:41.000-07:00\",\"updated_at\":\"2020-03-19T11:41:41.000-07:00\",\"inuse\":0,\"sample_id\":254,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(163,755,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":22,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:48.000-07:00\",\"updated_at\":\"2020-03-19T11:42:48.000-07:00\",\"inuse\":0,\"sample_id\":262,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(164,756,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":30,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:57.000-07:00\",\"updated_at\":\"2020-03-19T11:43:57.000-07:00\",\"inuse\":0,\"sample_id\":270,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(165,757,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":38,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:38.000-07:00\",\"updated_at\":\"2020-03-19T11:46:38.000-07:00\",\"inuse\":0,\"sample_id\":278,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(166,758,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":46,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:02.000-07:00\",\"updated_at\":\"2020-03-19T11:48:02.000-07:00\",\"inuse\":0,\"sample_id\":287,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:12','2020-03-24 00:33:17'),(167,759,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":54,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:51.000-07:00\",\"updated_at\":\"2020-03-19T11:49:51.000-07:00\",\"inuse\":0,\"sample_id\":295,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(168,760,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":62,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:57.000-07:00\",\"updated_at\":\"2020-03-19T11:54:57.000-07:00\",\"inuse\":0,\"sample_id\":303,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(169,761,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":70,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:55.000-07:00\",\"updated_at\":\"2020-03-19T11:55:55.000-07:00\",\"inuse\":0,\"sample_id\":311,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(170,762,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":78,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:34.000-07:00\",\"updated_at\":\"2020-03-19T11:57:34.000-07:00\",\"inuse\":0,\"sample_id\":319,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(171,763,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":86,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:09.000-07:00\",\"updated_at\":\"2020-03-19T11:59:09.000-07:00\",\"inuse\":0,\"sample_id\":327,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(172,764,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":94,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:04.000-07:00\",\"updated_at\":\"2020-03-19T12:00:04.000-07:00\",\"inuse\":0,\"sample_id\":335,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(173,765,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":7,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:43.000-07:00\",\"updated_at\":\"2020-03-19T11:40:43.000-07:00\",\"inuse\":0,\"sample_id\":250,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(174,766,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":15,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:46.000-07:00\",\"updated_at\":\"2020-03-19T11:41:46.000-07:00\",\"inuse\":0,\"sample_id\":255,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(175,767,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":23,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:57.000-07:00\",\"updated_at\":\"2020-03-19T11:42:57.000-07:00\",\"inuse\":0,\"sample_id\":263,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(176,768,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":31,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:45:26.000-07:00\",\"updated_at\":\"2020-03-19T11:45:26.000-07:00\",\"inuse\":0,\"sample_id\":271,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(177,769,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":39,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:48.000-07:00\",\"updated_at\":\"2020-03-19T11:46:48.000-07:00\",\"inuse\":0,\"sample_id\":279,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(178,770,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":47,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:10.000-07:00\",\"updated_at\":\"2020-03-19T11:48:10.000-07:00\",\"inuse\":0,\"sample_id\":288,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(179,771,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":55,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:57.000-07:00\",\"updated_at\":\"2020-03-19T11:49:57.000-07:00\",\"inuse\":0,\"sample_id\":296,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(180,772,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":63,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:04.000-07:00\",\"updated_at\":\"2020-03-19T11:55:04.000-07:00\",\"inuse\":0,\"sample_id\":304,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(181,773,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":71,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:03.000-07:00\",\"updated_at\":\"2020-03-19T11:56:03.000-07:00\",\"inuse\":0,\"sample_id\":312,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(182,774,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":79,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:42.000-07:00\",\"updated_at\":\"2020-03-19T11:57:42.000-07:00\",\"inuse\":0,\"sample_id\":320,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(183,775,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":87,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:15.000-07:00\",\"updated_at\":\"2020-03-19T11:59:15.000-07:00\",\"inuse\":0,\"sample_id\":328,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(184,776,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":95,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:11.000-07:00\",\"updated_at\":\"2020-03-19T12:00:11.000-07:00\",\"inuse\":0,\"sample_id\":336,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(185,777,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":8,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:52.000-07:00\",\"updated_at\":\"2020-03-19T11:40:52.000-07:00\",\"inuse\":0,\"sample_id\":251,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(186,778,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":16,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:53.000-07:00\",\"updated_at\":\"2020-03-19T11:41:53.000-07:00\",\"inuse\":0,\"sample_id\":256,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:17','2020-03-24 00:33:17'),(187,727,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:20','2020-03-24 00:33:20'),(188,779,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:20','2020-03-24 00:33:20'),(189,780,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:20','2020-03-24 00:33:20'),(190,727,'Collection','Adapter Plate',NULL,'{\"Adapter Plate\":{\"id\":728,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":3,\"created_at\":\"2020-03-23T17:32:59.000-07:00\",\"updated_at\":\"2020-03-23T17:32:59.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:24','2020-03-24 00:33:24'),(191,779,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":729,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-23T17:33:11.000-07:00\",\"updated_at\":\"2020-03-23T17:33:11.000-07:00\",\"inuse\":0,\"sample_id\":471,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:24','2020-03-24 00:33:24'),(192,780,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":730,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-23T17:33:11.000-07:00\",\"updated_at\":\"2020-03-23T17:33:11.000-07:00\",\"inuse\":0,\"sample_id\":481,\"data\":null,\"locator_id\":null}}','2020-03-24 00:33:24','2020-03-24 00:33:24'),(193,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-24 by Joe Neptune\"}','2020-03-24 15:15:09','2020-03-24 15:15:09'),(194,6,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 727, 727\"}','2020-03-24 15:15:09','2020-03-24 15:15:09'),(195,727,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-24 15:15:09','2020-03-24 15:15:09'),(196,727,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to pending from error.\"}','2020-03-24 15:15:09','2020-03-24 15:15:09'),(197,782,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":3,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":5,\"created_at\":\"2020-03-19T11:39:55.000-07:00\",\"updated_at\":\"2020-03-19T11:39:55.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(198,783,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":4,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:13.000-07:00\",\"updated_at\":\"2020-03-19T11:40:13.000-07:00\",\"inuse\":0,\"sample_id\":245,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(199,784,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":12,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:23.000-07:00\",\"updated_at\":\"2020-03-19T11:41:23.000-07:00\",\"inuse\":0,\"sample_id\":247,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(200,785,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":20,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:22.000-07:00\",\"updated_at\":\"2020-03-19T11:42:22.000-07:00\",\"inuse\":0,\"sample_id\":260,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(201,786,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":28,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:37.000-07:00\",\"updated_at\":\"2020-03-19T11:43:37.000-07:00\",\"inuse\":0,\"sample_id\":268,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(202,787,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":36,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:22.000-07:00\",\"updated_at\":\"2020-03-19T11:46:22.000-07:00\",\"inuse\":0,\"sample_id\":276,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(203,788,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":44,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:28.000-07:00\",\"updated_at\":\"2020-03-19T11:47:39.000-07:00\",\"inuse\":0,\"sample_id\":285,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(204,789,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":52,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:36.000-07:00\",\"updated_at\":\"2020-03-19T11:49:36.000-07:00\",\"inuse\":0,\"sample_id\":293,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(205,790,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":60,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:44.000-07:00\",\"updated_at\":\"2020-03-19T11:54:44.000-07:00\",\"inuse\":0,\"sample_id\":301,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(206,791,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":68,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:40.000-07:00\",\"updated_at\":\"2020-03-19T11:55:40.000-07:00\",\"inuse\":0,\"sample_id\":309,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(207,792,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":76,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:38.000-07:00\",\"updated_at\":\"2020-03-19T11:56:38.000-07:00\",\"inuse\":0,\"sample_id\":317,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(208,793,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":84,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:46.000-07:00\",\"updated_at\":\"2020-03-19T11:58:46.000-07:00\",\"inuse\":0,\"sample_id\":325,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(209,794,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":92,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:49.000-07:00\",\"updated_at\":\"2020-03-19T11:59:49.000-07:00\",\"inuse\":0,\"sample_id\":333,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(210,795,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":5,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:23.000-07:00\",\"updated_at\":\"2020-03-19T11:40:23.000-07:00\",\"inuse\":0,\"sample_id\":248,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(211,796,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":13,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:33.000-07:00\",\"updated_at\":\"2020-03-19T11:41:33.000-07:00\",\"inuse\":0,\"sample_id\":253,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(212,797,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":21,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:40.000-07:00\",\"updated_at\":\"2020-03-19T11:42:40.000-07:00\",\"inuse\":0,\"sample_id\":261,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(213,798,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":29,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:44.000-07:00\",\"updated_at\":\"2020-03-19T11:43:44.000-07:00\",\"inuse\":0,\"sample_id\":269,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(214,799,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":37,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:30.000-07:00\",\"updated_at\":\"2020-03-19T11:46:30.000-07:00\",\"inuse\":0,\"sample_id\":277,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(215,800,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":45,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:48.000-07:00\",\"updated_at\":\"2020-03-19T11:47:48.000-07:00\",\"inuse\":0,\"sample_id\":286,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(216,801,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":53,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:45.000-07:00\",\"updated_at\":\"2020-03-19T11:49:45.000-07:00\",\"inuse\":0,\"sample_id\":294,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(217,802,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":61,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:49.000-07:00\",\"updated_at\":\"2020-03-19T11:54:49.000-07:00\",\"inuse\":0,\"sample_id\":302,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(218,803,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":69,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:49.000-07:00\",\"updated_at\":\"2020-03-19T11:55:49.000-07:00\",\"inuse\":0,\"sample_id\":310,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(219,804,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":77,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:27.000-07:00\",\"updated_at\":\"2020-03-19T11:57:27.000-07:00\",\"inuse\":0,\"sample_id\":318,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(220,805,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":85,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:57.000-07:00\",\"updated_at\":\"2020-03-19T11:58:57.000-07:00\",\"inuse\":0,\"sample_id\":326,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(221,806,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":93,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:58.000-07:00\",\"updated_at\":\"2020-03-19T11:59:58.000-07:00\",\"inuse\":0,\"sample_id\":334,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(222,807,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":6,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:35.000-07:00\",\"updated_at\":\"2020-03-19T11:40:35.000-07:00\",\"inuse\":0,\"sample_id\":249,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(223,808,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":14,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:41.000-07:00\",\"updated_at\":\"2020-03-19T11:41:41.000-07:00\",\"inuse\":0,\"sample_id\":254,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(224,809,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":22,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:48.000-07:00\",\"updated_at\":\"2020-03-19T11:42:48.000-07:00\",\"inuse\":0,\"sample_id\":262,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(225,810,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":30,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:57.000-07:00\",\"updated_at\":\"2020-03-19T11:43:57.000-07:00\",\"inuse\":0,\"sample_id\":270,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(226,811,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":38,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:38.000-07:00\",\"updated_at\":\"2020-03-19T11:46:38.000-07:00\",\"inuse\":0,\"sample_id\":278,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(227,812,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":46,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:02.000-07:00\",\"updated_at\":\"2020-03-19T11:48:02.000-07:00\",\"inuse\":0,\"sample_id\":287,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:29','2020-03-24 15:15:34'),(228,813,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":54,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:51.000-07:00\",\"updated_at\":\"2020-03-19T11:49:51.000-07:00\",\"inuse\":0,\"sample_id\":295,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(229,814,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":62,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:57.000-07:00\",\"updated_at\":\"2020-03-19T11:54:57.000-07:00\",\"inuse\":0,\"sample_id\":303,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(230,815,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":70,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:55.000-07:00\",\"updated_at\":\"2020-03-19T11:55:55.000-07:00\",\"inuse\":0,\"sample_id\":311,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(231,816,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":78,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:34.000-07:00\",\"updated_at\":\"2020-03-19T11:57:34.000-07:00\",\"inuse\":0,\"sample_id\":319,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(232,817,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":86,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:09.000-07:00\",\"updated_at\":\"2020-03-19T11:59:09.000-07:00\",\"inuse\":0,\"sample_id\":327,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(233,818,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":94,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:04.000-07:00\",\"updated_at\":\"2020-03-19T12:00:04.000-07:00\",\"inuse\":0,\"sample_id\":335,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(234,819,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":7,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:43.000-07:00\",\"updated_at\":\"2020-03-19T11:40:43.000-07:00\",\"inuse\":0,\"sample_id\":250,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(235,820,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":15,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:46.000-07:00\",\"updated_at\":\"2020-03-19T11:41:46.000-07:00\",\"inuse\":0,\"sample_id\":255,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(236,821,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":23,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:57.000-07:00\",\"updated_at\":\"2020-03-19T11:42:57.000-07:00\",\"inuse\":0,\"sample_id\":263,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:34','2020-03-24 15:15:34'),(237,822,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":31,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:45:26.000-07:00\",\"updated_at\":\"2020-03-19T11:45:26.000-07:00\",\"inuse\":0,\"sample_id\":271,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(238,823,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":39,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:48.000-07:00\",\"updated_at\":\"2020-03-19T11:46:48.000-07:00\",\"inuse\":0,\"sample_id\":279,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(239,824,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":47,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:10.000-07:00\",\"updated_at\":\"2020-03-19T11:48:10.000-07:00\",\"inuse\":0,\"sample_id\":288,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(240,825,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":55,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:57.000-07:00\",\"updated_at\":\"2020-03-19T11:49:57.000-07:00\",\"inuse\":0,\"sample_id\":296,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(241,826,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":63,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:04.000-07:00\",\"updated_at\":\"2020-03-19T11:55:04.000-07:00\",\"inuse\":0,\"sample_id\":304,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(242,827,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":71,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:03.000-07:00\",\"updated_at\":\"2020-03-19T11:56:03.000-07:00\",\"inuse\":0,\"sample_id\":312,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(243,828,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":79,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:42.000-07:00\",\"updated_at\":\"2020-03-19T11:57:42.000-07:00\",\"inuse\":0,\"sample_id\":320,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(244,829,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":87,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:15.000-07:00\",\"updated_at\":\"2020-03-19T11:59:15.000-07:00\",\"inuse\":0,\"sample_id\":328,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(245,830,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":95,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:11.000-07:00\",\"updated_at\":\"2020-03-19T12:00:11.000-07:00\",\"inuse\":0,\"sample_id\":336,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(246,831,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":8,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:52.000-07:00\",\"updated_at\":\"2020-03-19T11:40:52.000-07:00\",\"inuse\":0,\"sample_id\":251,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(247,832,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":16,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:53.000-07:00\",\"updated_at\":\"2020-03-19T11:41:53.000-07:00\",\"inuse\":0,\"sample_id\":256,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:35','2020-03-24 15:15:35'),(248,781,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:39','2020-03-24 15:15:39'),(249,833,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:39','2020-03-24 15:15:39'),(250,834,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 15:15:39','2020-03-24 15:15:39'),(251,781,'Collection','Adapter Plate',NULL,'{\"Adapter Plate\":{\"id\":782,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":3,\"created_at\":\"2020-03-24T08:15:15.000-07:00\",\"updated_at\":\"2020-03-24T08:15:15.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 15:22:20','2020-03-24 15:22:20'),(252,833,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":783,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T08:15:28.000-07:00\",\"updated_at\":\"2020-03-24T08:15:28.000-07:00\",\"inuse\":0,\"sample_id\":471,\"data\":null,\"locator_id\":null}}','2020-03-24 15:22:20','2020-03-24 15:22:20'),(253,834,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":784,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T08:15:28.000-07:00\",\"updated_at\":\"2020-03-24T08:15:28.000-07:00\",\"inuse\":0,\"sample_id\":481,\"data\":null,\"locator_id\":null}}','2020-03-24 15:22:20','2020-03-24 15:22:20'),(254,835,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(255,836,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(256,837,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(257,838,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":217,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T10:11:36.000-07:00\",\"updated_at\":\"2020-03-20T10:11:36.000-07:00\",\"inuse\":0,\"sample_id\":3,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(258,839,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":218,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:07.000-07:00\",\"updated_at\":\"2020-03-20T11:41:07.000-07:00\",\"inuse\":0,\"sample_id\":4,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(259,840,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":219,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:13.000-07:00\",\"updated_at\":\"2020-03-20T11:41:13.000-07:00\",\"inuse\":0,\"sample_id\":5,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(260,841,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":220,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:18.000-07:00\",\"updated_at\":\"2020-03-20T11:41:18.000-07:00\",\"inuse\":0,\"sample_id\":6,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(261,842,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":221,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:23.000-07:00\",\"updated_at\":\"2020-03-20T11:41:36.000-07:00\",\"inuse\":0,\"sample_id\":7,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(262,843,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":222,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:49.000-07:00\",\"updated_at\":\"2020-03-20T11:41:49.000-07:00\",\"inuse\":0,\"sample_id\":8,\"data\":null,\"locator_id\":null}}','2020-03-24 15:24:00','2020-03-24 15:24:00'),(263,845,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":3,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":5,\"created_at\":\"2020-03-19T11:39:55.000-07:00\",\"updated_at\":\"2020-03-19T11:39:55.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(264,846,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":4,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:13.000-07:00\",\"updated_at\":\"2020-03-19T11:40:13.000-07:00\",\"inuse\":0,\"sample_id\":245,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(265,847,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":12,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:23.000-07:00\",\"updated_at\":\"2020-03-19T11:41:23.000-07:00\",\"inuse\":0,\"sample_id\":247,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(266,848,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":20,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:22.000-07:00\",\"updated_at\":\"2020-03-19T11:42:22.000-07:00\",\"inuse\":0,\"sample_id\":260,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(267,849,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":28,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:37.000-07:00\",\"updated_at\":\"2020-03-19T11:43:37.000-07:00\",\"inuse\":0,\"sample_id\":268,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(268,850,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":36,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:22.000-07:00\",\"updated_at\":\"2020-03-19T11:46:22.000-07:00\",\"inuse\":0,\"sample_id\":276,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(269,851,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":44,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:28.000-07:00\",\"updated_at\":\"2020-03-19T11:47:39.000-07:00\",\"inuse\":0,\"sample_id\":285,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(270,852,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":52,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:36.000-07:00\",\"updated_at\":\"2020-03-19T11:49:36.000-07:00\",\"inuse\":0,\"sample_id\":293,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(271,853,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":60,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:44.000-07:00\",\"updated_at\":\"2020-03-19T11:54:44.000-07:00\",\"inuse\":0,\"sample_id\":301,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(272,854,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":68,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:40.000-07:00\",\"updated_at\":\"2020-03-19T11:55:40.000-07:00\",\"inuse\":0,\"sample_id\":309,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(273,855,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":76,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:38.000-07:00\",\"updated_at\":\"2020-03-19T11:56:38.000-07:00\",\"inuse\":0,\"sample_id\":317,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(274,856,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":84,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:46.000-07:00\",\"updated_at\":\"2020-03-19T11:58:46.000-07:00\",\"inuse\":0,\"sample_id\":325,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(275,857,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":92,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:49.000-07:00\",\"updated_at\":\"2020-03-19T11:59:49.000-07:00\",\"inuse\":0,\"sample_id\":333,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(276,858,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":5,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:23.000-07:00\",\"updated_at\":\"2020-03-19T11:40:23.000-07:00\",\"inuse\":0,\"sample_id\":248,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(277,859,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":13,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:33.000-07:00\",\"updated_at\":\"2020-03-19T11:41:33.000-07:00\",\"inuse\":0,\"sample_id\":253,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(278,860,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":21,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:40.000-07:00\",\"updated_at\":\"2020-03-19T11:42:40.000-07:00\",\"inuse\":0,\"sample_id\":261,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(279,861,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":29,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:44.000-07:00\",\"updated_at\":\"2020-03-19T11:43:44.000-07:00\",\"inuse\":0,\"sample_id\":269,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(280,862,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":37,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:30.000-07:00\",\"updated_at\":\"2020-03-19T11:46:30.000-07:00\",\"inuse\":0,\"sample_id\":277,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(281,863,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":45,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:48.000-07:00\",\"updated_at\":\"2020-03-19T11:47:48.000-07:00\",\"inuse\":0,\"sample_id\":286,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(282,864,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":53,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:45.000-07:00\",\"updated_at\":\"2020-03-19T11:49:45.000-07:00\",\"inuse\":0,\"sample_id\":294,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(283,865,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":61,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:49.000-07:00\",\"updated_at\":\"2020-03-19T11:54:49.000-07:00\",\"inuse\":0,\"sample_id\":302,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(284,866,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":69,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:49.000-07:00\",\"updated_at\":\"2020-03-19T11:55:49.000-07:00\",\"inuse\":0,\"sample_id\":310,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(285,867,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":77,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:27.000-07:00\",\"updated_at\":\"2020-03-19T11:57:27.000-07:00\",\"inuse\":0,\"sample_id\":318,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(286,868,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":85,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:57.000-07:00\",\"updated_at\":\"2020-03-19T11:58:57.000-07:00\",\"inuse\":0,\"sample_id\":326,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(287,869,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":93,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:58.000-07:00\",\"updated_at\":\"2020-03-19T11:59:58.000-07:00\",\"inuse\":0,\"sample_id\":334,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(288,870,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":6,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:35.000-07:00\",\"updated_at\":\"2020-03-19T11:40:35.000-07:00\",\"inuse\":0,\"sample_id\":249,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(289,871,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":14,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:41.000-07:00\",\"updated_at\":\"2020-03-19T11:41:41.000-07:00\",\"inuse\":0,\"sample_id\":254,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(290,872,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":22,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:48.000-07:00\",\"updated_at\":\"2020-03-19T11:42:48.000-07:00\",\"inuse\":0,\"sample_id\":262,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(291,873,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":30,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:57.000-07:00\",\"updated_at\":\"2020-03-19T11:43:57.000-07:00\",\"inuse\":0,\"sample_id\":270,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:27','2020-03-24 16:06:32'),(292,874,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":38,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:38.000-07:00\",\"updated_at\":\"2020-03-19T11:46:38.000-07:00\",\"inuse\":0,\"sample_id\":278,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:28','2020-03-24 16:06:32'),(293,875,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":46,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:02.000-07:00\",\"updated_at\":\"2020-03-19T11:48:02.000-07:00\",\"inuse\":0,\"sample_id\":287,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:28','2020-03-24 16:06:32'),(294,876,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":54,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:51.000-07:00\",\"updated_at\":\"2020-03-19T11:49:51.000-07:00\",\"inuse\":0,\"sample_id\":295,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(295,877,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":62,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:57.000-07:00\",\"updated_at\":\"2020-03-19T11:54:57.000-07:00\",\"inuse\":0,\"sample_id\":303,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(296,878,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":70,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:55.000-07:00\",\"updated_at\":\"2020-03-19T11:55:55.000-07:00\",\"inuse\":0,\"sample_id\":311,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(297,879,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":78,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:34.000-07:00\",\"updated_at\":\"2020-03-19T11:57:34.000-07:00\",\"inuse\":0,\"sample_id\":319,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(298,880,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":86,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:09.000-07:00\",\"updated_at\":\"2020-03-19T11:59:09.000-07:00\",\"inuse\":0,\"sample_id\":327,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(299,881,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":94,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:04.000-07:00\",\"updated_at\":\"2020-03-19T12:00:04.000-07:00\",\"inuse\":0,\"sample_id\":335,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(300,882,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":7,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:43.000-07:00\",\"updated_at\":\"2020-03-19T11:40:43.000-07:00\",\"inuse\":0,\"sample_id\":250,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(301,883,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":15,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:46.000-07:00\",\"updated_at\":\"2020-03-19T11:41:46.000-07:00\",\"inuse\":0,\"sample_id\":255,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(302,884,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":23,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:57.000-07:00\",\"updated_at\":\"2020-03-19T11:42:57.000-07:00\",\"inuse\":0,\"sample_id\":263,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(303,885,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":31,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:45:26.000-07:00\",\"updated_at\":\"2020-03-19T11:45:26.000-07:00\",\"inuse\":0,\"sample_id\":271,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(304,886,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":39,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:48.000-07:00\",\"updated_at\":\"2020-03-19T11:46:48.000-07:00\",\"inuse\":0,\"sample_id\":279,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(305,887,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":47,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:10.000-07:00\",\"updated_at\":\"2020-03-19T11:48:10.000-07:00\",\"inuse\":0,\"sample_id\":288,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(306,888,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":55,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:57.000-07:00\",\"updated_at\":\"2020-03-19T11:49:57.000-07:00\",\"inuse\":0,\"sample_id\":296,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(307,889,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":63,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:04.000-07:00\",\"updated_at\":\"2020-03-19T11:55:04.000-07:00\",\"inuse\":0,\"sample_id\":304,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(308,890,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":71,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:03.000-07:00\",\"updated_at\":\"2020-03-19T11:56:03.000-07:00\",\"inuse\":0,\"sample_id\":312,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(309,891,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":79,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:42.000-07:00\",\"updated_at\":\"2020-03-19T11:57:42.000-07:00\",\"inuse\":0,\"sample_id\":320,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(310,892,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":87,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:15.000-07:00\",\"updated_at\":\"2020-03-19T11:59:15.000-07:00\",\"inuse\":0,\"sample_id\":328,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(311,893,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":95,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:11.000-07:00\",\"updated_at\":\"2020-03-19T12:00:11.000-07:00\",\"inuse\":0,\"sample_id\":336,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(312,894,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":8,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:52.000-07:00\",\"updated_at\":\"2020-03-19T11:40:52.000-07:00\",\"inuse\":0,\"sample_id\":251,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(313,895,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":16,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:53.000-07:00\",\"updated_at\":\"2020-03-19T11:41:53.000-07:00\",\"inuse\":0,\"sample_id\":256,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:32','2020-03-24 16:06:32'),(314,844,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(315,896,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(316,897,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(317,898,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":217,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T10:11:36.000-07:00\",\"updated_at\":\"2020-03-20T10:11:36.000-07:00\",\"inuse\":0,\"sample_id\":3,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(318,899,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":218,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:07.000-07:00\",\"updated_at\":\"2020-03-20T11:41:07.000-07:00\",\"inuse\":0,\"sample_id\":4,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(319,900,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":219,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:13.000-07:00\",\"updated_at\":\"2020-03-20T11:41:13.000-07:00\",\"inuse\":0,\"sample_id\":5,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(320,901,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":220,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:18.000-07:00\",\"updated_at\":\"2020-03-20T11:41:18.000-07:00\",\"inuse\":0,\"sample_id\":6,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(321,902,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":221,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:23.000-07:00\",\"updated_at\":\"2020-03-20T11:41:36.000-07:00\",\"inuse\":0,\"sample_id\":7,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(322,903,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":222,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:49.000-07:00\",\"updated_at\":\"2020-03-20T11:41:49.000-07:00\",\"inuse\":0,\"sample_id\":8,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:38','2020-03-24 16:06:38'),(323,844,'Collection','Adapter Plate',NULL,'{\"Adapter Plate\":{\"id\":845,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":3,\"created_at\":\"2020-03-24T09:06:13.000-07:00\",\"updated_at\":\"2020-03-24T09:06:13.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(324,896,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":846,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":471,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(325,897,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":847,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":481,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(326,898,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":848,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":489,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(327,899,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":849,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":498,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(328,900,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":850,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":506,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(329,901,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":851,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":514,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(330,902,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":852,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":522,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(331,903,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":853,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:06:27.000-07:00\",\"updated_at\":\"2020-03-24T09:06:27.000-07:00\",\"inuse\":0,\"sample_id\":530,\"data\":null,\"locator_id\":null}}','2020-03-24 16:06:44','2020-03-24 16:06:44'),(332,6,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to done on 2020-03-24 by Joe Neptune\"}','2020-03-24 16:07:02','2020-03-24 16:07:02'),(333,6,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 781, 781\"}','2020-03-24 16:07:02','2020-03-24 16:07:02'),(334,781,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to done from error.\"}','2020-03-24 16:07:02','2020-03-24 16:07:02'),(335,781,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 6 when its status was changed to done from error.\"}','2020-03-24 16:07:02','2020-03-24 16:07:02'),(336,40,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 89 crashed\"}','2020-03-24 16:07:16','2020-03-24 16:07:16'),(337,70,'Plan','replan',NULL,'{\"replan\":\"Based on plan 32. Replanned 2020-03-24.\"}','2020-03-24 16:08:07','2020-03-24 16:08:07'),(338,41,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 90 crashed\"}','2020-03-24 16:16:56','2020-03-24 16:16:56'),(339,904,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(340,905,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(341,906,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(342,907,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":217,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T10:11:36.000-07:00\",\"updated_at\":\"2020-03-20T10:11:36.000-07:00\",\"inuse\":0,\"sample_id\":3,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(343,908,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":218,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:07.000-07:00\",\"updated_at\":\"2020-03-20T11:41:07.000-07:00\",\"inuse\":0,\"sample_id\":4,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(344,909,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":219,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:13.000-07:00\",\"updated_at\":\"2020-03-20T11:41:13.000-07:00\",\"inuse\":0,\"sample_id\":5,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(345,910,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":220,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:18.000-07:00\",\"updated_at\":\"2020-03-20T11:41:18.000-07:00\",\"inuse\":0,\"sample_id\":6,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(346,911,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":221,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:23.000-07:00\",\"updated_at\":\"2020-03-20T11:41:36.000-07:00\",\"inuse\":0,\"sample_id\":7,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(347,912,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":222,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:49.000-07:00\",\"updated_at\":\"2020-03-20T11:41:49.000-07:00\",\"inuse\":0,\"sample_id\":8,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:10','2020-03-24 16:17:10'),(348,914,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":3,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":5,\"created_at\":\"2020-03-19T11:39:55.000-07:00\",\"updated_at\":\"2020-03-19T11:39:55.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:41'),(349,915,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":4,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:13.000-07:00\",\"updated_at\":\"2020-03-19T11:40:13.000-07:00\",\"inuse\":0,\"sample_id\":245,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(350,916,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":12,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:23.000-07:00\",\"updated_at\":\"2020-03-19T11:41:23.000-07:00\",\"inuse\":0,\"sample_id\":247,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(351,917,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":20,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:22.000-07:00\",\"updated_at\":\"2020-03-19T11:42:22.000-07:00\",\"inuse\":0,\"sample_id\":260,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(352,918,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":28,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:37.000-07:00\",\"updated_at\":\"2020-03-19T11:43:37.000-07:00\",\"inuse\":0,\"sample_id\":268,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(353,919,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":36,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:22.000-07:00\",\"updated_at\":\"2020-03-19T11:46:22.000-07:00\",\"inuse\":0,\"sample_id\":276,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(354,920,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":44,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:28.000-07:00\",\"updated_at\":\"2020-03-19T11:47:39.000-07:00\",\"inuse\":0,\"sample_id\":285,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(355,921,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":52,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:36.000-07:00\",\"updated_at\":\"2020-03-19T11:49:36.000-07:00\",\"inuse\":0,\"sample_id\":293,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(356,922,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":60,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:44.000-07:00\",\"updated_at\":\"2020-03-19T11:54:44.000-07:00\",\"inuse\":0,\"sample_id\":301,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(357,923,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":68,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:40.000-07:00\",\"updated_at\":\"2020-03-19T11:55:40.000-07:00\",\"inuse\":0,\"sample_id\":309,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(358,924,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":76,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:38.000-07:00\",\"updated_at\":\"2020-03-19T11:56:38.000-07:00\",\"inuse\":0,\"sample_id\":317,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(359,925,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":84,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:46.000-07:00\",\"updated_at\":\"2020-03-19T11:58:46.000-07:00\",\"inuse\":0,\"sample_id\":325,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(360,926,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":92,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:49.000-07:00\",\"updated_at\":\"2020-03-19T11:59:49.000-07:00\",\"inuse\":0,\"sample_id\":333,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(361,927,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":5,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:23.000-07:00\",\"updated_at\":\"2020-03-19T11:40:23.000-07:00\",\"inuse\":0,\"sample_id\":248,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(362,928,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":13,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:33.000-07:00\",\"updated_at\":\"2020-03-19T11:41:33.000-07:00\",\"inuse\":0,\"sample_id\":253,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(363,929,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":21,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:40.000-07:00\",\"updated_at\":\"2020-03-19T11:42:40.000-07:00\",\"inuse\":0,\"sample_id\":261,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(364,930,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":29,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:44.000-07:00\",\"updated_at\":\"2020-03-19T11:43:44.000-07:00\",\"inuse\":0,\"sample_id\":269,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(365,931,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":37,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:30.000-07:00\",\"updated_at\":\"2020-03-19T11:46:30.000-07:00\",\"inuse\":0,\"sample_id\":277,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(366,932,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":45,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:47:48.000-07:00\",\"updated_at\":\"2020-03-19T11:47:48.000-07:00\",\"inuse\":0,\"sample_id\":286,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(367,933,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":53,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:45.000-07:00\",\"updated_at\":\"2020-03-19T11:49:45.000-07:00\",\"inuse\":0,\"sample_id\":294,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(368,934,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":61,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:49.000-07:00\",\"updated_at\":\"2020-03-19T11:54:49.000-07:00\",\"inuse\":0,\"sample_id\":302,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(369,935,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":69,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:49.000-07:00\",\"updated_at\":\"2020-03-19T11:55:49.000-07:00\",\"inuse\":0,\"sample_id\":310,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(370,936,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":77,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:27.000-07:00\",\"updated_at\":\"2020-03-19T11:57:27.000-07:00\",\"inuse\":0,\"sample_id\":318,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(371,937,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":85,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:58:57.000-07:00\",\"updated_at\":\"2020-03-19T11:58:57.000-07:00\",\"inuse\":0,\"sample_id\":326,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(372,938,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":93,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:58.000-07:00\",\"updated_at\":\"2020-03-19T11:59:58.000-07:00\",\"inuse\":0,\"sample_id\":334,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(373,939,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":6,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:35.000-07:00\",\"updated_at\":\"2020-03-19T11:40:35.000-07:00\",\"inuse\":0,\"sample_id\":249,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(374,940,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":14,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:41.000-07:00\",\"updated_at\":\"2020-03-19T11:41:41.000-07:00\",\"inuse\":0,\"sample_id\":254,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(375,941,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":22,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:48.000-07:00\",\"updated_at\":\"2020-03-19T11:42:48.000-07:00\",\"inuse\":0,\"sample_id\":262,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(376,942,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":30,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:43:57.000-07:00\",\"updated_at\":\"2020-03-19T11:43:57.000-07:00\",\"inuse\":0,\"sample_id\":270,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(377,943,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":38,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:38.000-07:00\",\"updated_at\":\"2020-03-19T11:46:38.000-07:00\",\"inuse\":0,\"sample_id\":278,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(378,944,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":46,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:02.000-07:00\",\"updated_at\":\"2020-03-19T11:48:02.000-07:00\",\"inuse\":0,\"sample_id\":287,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:38','2020-03-24 16:17:42'),(379,945,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":54,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:51.000-07:00\",\"updated_at\":\"2020-03-19T11:49:51.000-07:00\",\"inuse\":0,\"sample_id\":295,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(380,946,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":62,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:54:57.000-07:00\",\"updated_at\":\"2020-03-19T11:54:57.000-07:00\",\"inuse\":0,\"sample_id\":303,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(381,947,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":70,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:55.000-07:00\",\"updated_at\":\"2020-03-19T11:55:55.000-07:00\",\"inuse\":0,\"sample_id\":311,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(382,948,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":78,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:34.000-07:00\",\"updated_at\":\"2020-03-19T11:57:34.000-07:00\",\"inuse\":0,\"sample_id\":319,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(383,949,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":86,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:09.000-07:00\",\"updated_at\":\"2020-03-19T11:59:09.000-07:00\",\"inuse\":0,\"sample_id\":327,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(384,950,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":94,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:04.000-07:00\",\"updated_at\":\"2020-03-19T12:00:04.000-07:00\",\"inuse\":0,\"sample_id\":335,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(385,951,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":7,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:43.000-07:00\",\"updated_at\":\"2020-03-19T11:40:43.000-07:00\",\"inuse\":0,\"sample_id\":250,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(386,952,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":15,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:46.000-07:00\",\"updated_at\":\"2020-03-19T11:41:46.000-07:00\",\"inuse\":0,\"sample_id\":255,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(387,953,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":23,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:42:57.000-07:00\",\"updated_at\":\"2020-03-19T11:42:57.000-07:00\",\"inuse\":0,\"sample_id\":263,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(388,954,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":31,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:45:26.000-07:00\",\"updated_at\":\"2020-03-19T11:45:26.000-07:00\",\"inuse\":0,\"sample_id\":271,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(389,955,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":39,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:46:48.000-07:00\",\"updated_at\":\"2020-03-19T11:46:48.000-07:00\",\"inuse\":0,\"sample_id\":279,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(390,956,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":47,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:48:10.000-07:00\",\"updated_at\":\"2020-03-19T11:48:10.000-07:00\",\"inuse\":0,\"sample_id\":288,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(391,957,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":55,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:49:57.000-07:00\",\"updated_at\":\"2020-03-19T11:49:57.000-07:00\",\"inuse\":0,\"sample_id\":296,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(392,958,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":63,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:55:04.000-07:00\",\"updated_at\":\"2020-03-19T11:55:04.000-07:00\",\"inuse\":0,\"sample_id\":304,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(393,959,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":71,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:56:03.000-07:00\",\"updated_at\":\"2020-03-19T11:56:03.000-07:00\",\"inuse\":0,\"sample_id\":312,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(394,960,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":79,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:57:42.000-07:00\",\"updated_at\":\"2020-03-19T11:57:42.000-07:00\",\"inuse\":0,\"sample_id\":320,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(395,961,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":87,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:59:15.000-07:00\",\"updated_at\":\"2020-03-19T11:59:15.000-07:00\",\"inuse\":0,\"sample_id\":328,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(396,962,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":95,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T12:00:11.000-07:00\",\"updated_at\":\"2020-03-19T12:00:11.000-07:00\",\"inuse\":0,\"sample_id\":336,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(397,963,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":8,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:40:52.000-07:00\",\"updated_at\":\"2020-03-19T11:40:52.000-07:00\",\"inuse\":0,\"sample_id\":251,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(398,964,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":16,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T11:41:53.000-07:00\",\"updated_at\":\"2020-03-19T11:41:53.000-07:00\",\"inuse\":0,\"sample_id\":256,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:42','2020-03-24 16:17:42'),(399,913,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(400,965,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(401,966,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(402,967,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":217,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T10:11:36.000-07:00\",\"updated_at\":\"2020-03-20T10:11:36.000-07:00\",\"inuse\":0,\"sample_id\":3,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(403,968,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":218,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:07.000-07:00\",\"updated_at\":\"2020-03-20T11:41:07.000-07:00\",\"inuse\":0,\"sample_id\":4,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(404,969,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":219,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:13.000-07:00\",\"updated_at\":\"2020-03-20T11:41:13.000-07:00\",\"inuse\":0,\"sample_id\":5,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(405,970,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":220,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:18.000-07:00\",\"updated_at\":\"2020-03-20T11:41:18.000-07:00\",\"inuse\":0,\"sample_id\":6,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(406,971,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":221,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:23.000-07:00\",\"updated_at\":\"2020-03-20T11:41:36.000-07:00\",\"inuse\":0,\"sample_id\":7,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(407,972,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":222,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-20T11:41:49.000-07:00\",\"updated_at\":\"2020-03-20T11:41:49.000-07:00\",\"inuse\":0,\"sample_id\":8,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:48','2020-03-24 16:17:48'),(408,913,'Collection','Adapter Plate',NULL,'{\"Adapter Plate\":{\"id\":914,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":3,\"created_at\":\"2020-03-24T09:17:29.000-07:00\",\"updated_at\":\"2020-03-24T09:17:29.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(409,965,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":915,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":471,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(410,966,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":916,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":481,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(411,967,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":917,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":489,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(412,968,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":918,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":498,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(413,969,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":919,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":506,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(414,970,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":920,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":514,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(415,971,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":921,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":522,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(416,972,'Item','Adapter Item',NULL,'{\"Adapter Item\":{\"id\":922,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:37.000-07:00\",\"updated_at\":\"2020-03-24T09:17:37.000-07:00\",\"inuse\":0,\"sample_id\":530,\"data\":null,\"locator_id\":null}}','2020-03-24 16:17:52','2020-03-24 16:17:52'),(417,84,'Operation','input_item_replaced',NULL,'{\"input_item_replaced\":\"Input Input Array was 781 but was replaced by 913 (likely when its predecessor recomputed an output)\"}','2020-03-24 16:17:59','2020-03-24 16:17:59'),(418,84,'Operation','input_item_replaced',NULL,'{\"input_item_replaced\":\"Input Input Array was 844 but was replaced by 913 (likely when its predecessor recomputed an output)\"}','2020-03-24 16:17:59','2020-03-24 16:17:59'),(419,84,'Operation','input_item_replaced',NULL,'{\"input_item_replaced\":\"Input Input Array was 844 but was replaced by 913 (likely when its predecessor recomputed an output)\"}','2020-03-24 16:17:59','2020-03-24 16:17:59'),(420,84,'Operation','input_item_replaced',NULL,'{\"input_item_replaced\":\"Input Input Array was 844 but was replaced by 913 (likely when its predecessor recomputed an output)\"}','2020-03-24 16:17:59','2020-03-24 16:17:59'),(421,84,'Operation','input_item_replaced',NULL,'{\"input_item_replaced\":\"Input Input Array was 844 but was replaced by 913 (likely when its predecessor recomputed an output)\"}','2020-03-24 16:17:59','2020-03-24 16:17:59'),(422,84,'Operation','input_item_replaced',NULL,'{\"input_item_replaced\":\"Input Input Array was 844 but was replaced by 913 (likely when its predecessor recomputed an output)\"}','2020-03-24 16:17:59','2020-03-24 16:17:59'),(423,83,'Operation','job_crash',NULL,'{\"job_crash\":\"Operation canceled when job 93 crashed\"}','2020-03-24 17:54:42','2020-03-24 17:54:42'),(424,83,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-24 by Joe Neptune\"}','2020-03-24 17:57:03','2020-03-24 17:57:03'),(425,974,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":913,\"location\":\"Freezer\",\"quantity\":1,\"object_type_id\":3,\"created_at\":\"2020-03-24T09:17:27.000-07:00\",\"updated_at\":\"2020-03-24T09:17:57.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(426,975,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":965,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(427,976,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":966,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(428,977,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":967,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":3,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(429,978,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":968,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":4,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(430,979,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":969,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":5,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(431,980,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":970,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":6,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(432,981,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":971,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":7,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(433,982,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":972,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-24T09:17:48.000-07:00\",\"updated_at\":\"2020-03-24T09:17:48.000-07:00\",\"inuse\":0,\"sample_id\":8,\"data\":null,\"locator_id\":null}}','2020-03-24 17:57:10','2020-03-24 17:57:10'),(434,913,'Item','C-DNA QC',NULL,'{\"C-DNA QC\":\"Pass\"}','2020-03-24 17:57:15','2020-03-24 17:57:15'),(435,84,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-24 by Joe Neptune\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(436,84,'Operation','previously_used_items',NULL,'{\"previously_used_items\":\"Items previously generated by this operation: 983, 983, 983, 983, 983, 983, 983, 983\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(437,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(438,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(439,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(440,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(441,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(442,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(443,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(444,983,'Item','operation_status_change',NULL,'{\"operation_status_change\":\"This item was an output of operation 84 when its status was changed to pending from done.\"}','2020-03-24 18:21:19','2020-03-24 18:21:19'),(445,71,'Plan','replan',NULL,'{\"replan\":\"Based on plan 70. Replanned 2020-03-24.\"}','2020-03-24 18:28:27','2020-03-24 18:28:27'),(446,72,'Plan','replan',NULL,'{\"replan\":\"Based on plan 71. Replanned 2020-03-24.\"}','2020-03-24 18:31:12','2020-03-24 18:31:12'),(447,73,'Plan','replan',NULL,'{\"replan\":\"Based on plan 4. Replanned 2020-03-24.\"}','2020-03-24 18:32:04','2020-03-24 18:32:04'),(448,73,'Plan','Precondition Evaluation Error',NULL,'{\"Precondition Evaluation Error\":\"undefined method `sample\' for nil:NilClass: line:24:in `precondition\'\"}','2020-03-24 19:02:17','2020-03-24 19:02:17'),(449,1001,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 19:07:31','2020-03-24 19:07:31'),(450,1003,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 19:07:31','2020-03-24 19:07:31'),(451,1004,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 19:07:31','2020-03-24 19:07:31'),(452,106,'Operation','status_change',NULL,'{\"status_change\":\"Status changed to pending on 2020-03-24 by Joe Neptune\"}','2020-03-24 19:09:08','2020-03-24 19:09:08'),(453,74,'Plan','replan',NULL,'{\"replan\":\"Based on plan 73. Replanned 2020-03-24.\"}','2020-03-24 19:14:18','2020-03-24 19:14:18'),(454,74,'Plan','Channel 1.0 status',NULL,'{\"Channel 1.0 status\":\"Listening for items...\"}','2020-03-24 19:15:29','2020-03-24 19:15:29'),(455,1005,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 19:15:54','2020-03-24 19:15:54'),(456,1007,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 19:15:54','2020-03-24 19:15:54'),(457,1008,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 19:15:54','2020-03-24 19:15:54'),(458,75,'Plan','replan',NULL,'{\"replan\":\"Based on plan 74. Replanned 2020-03-24.\"}','2020-03-24 19:58:28','2020-03-24 19:58:28'),(459,75,'Plan','Channel 1.0 status',NULL,'{\"Channel 1.0 status\":\"Listening for items...\"}','2020-03-24 19:58:35','2020-03-24 19:58:35'),(460,1009,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 19:59:18','2020-03-24 19:59:18'),(461,1011,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 19:59:18','2020-03-24 19:59:18'),(462,1012,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 19:59:18','2020-03-24 19:59:18'),(463,76,'Plan','replan',NULL,'{\"replan\":\"Based on plan 74. Replanned 2020-03-24.\"}','2020-03-24 20:01:50','2020-03-24 20:01:50'),(464,76,'Plan','Channel 1.0 status',NULL,'{\"Channel 1.0 status\":\"Listening for items...\"}','2020-03-24 20:02:35','2020-03-24 20:02:35'),(465,1013,'Collection','Input Plate',NULL,'{\"Input Plate\":{\"id\":200,\"location\":\"Bench\",\"quantity\":1,\"object_type_id\":4,\"created_at\":\"2020-03-19T13:07:10.000-07:00\",\"updated_at\":\"2020-03-19T13:07:10.000-07:00\",\"inuse\":0,\"sample_id\":null,\"data\":null,\"locator_id\":null}}','2020-03-24 20:02:47','2020-03-24 20:02:47'),(466,1015,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":201,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:20.000-07:00\",\"updated_at\":\"2020-03-19T13:07:20.000-07:00\",\"inuse\":0,\"sample_id\":1,\"data\":null,\"locator_id\":null}}','2020-03-24 20:02:47','2020-03-24 20:02:47'),(467,1016,'Item','Input Item',NULL,'{\"Input Item\":{\"id\":202,\"location\":\"Part of Collection\",\"quantity\":1,\"object_type_id\":1,\"created_at\":\"2020-03-19T13:07:27.000-07:00\",\"updated_at\":\"2020-03-19T13:07:27.000-07:00\",\"inuse\":0,\"sample_id\":2,\"data\":null,\"locator_id\":null}}','2020-03-24 20:02:47','2020-03-24 20:02:47');
/*!40000 ALTER TABLE `data_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `field_types`
--

DROP TABLE IF EXISTS `field_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `field_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `ftype` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `choices` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `array` tinyint(1) DEFAULT NULL,
  `required` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `parent_class` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `role` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `part` tinyint(1) DEFAULT NULL,
  `routing` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `preferred_operation_type_id` int(11) DEFAULT NULL,
  `preferred_field_type_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_field_types_on_sample_type_id` (`parent_id`)
) ENGINE=InnoDB AUTO_INCREMENT=130 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `field_types`
--

LOCK TABLES `field_types` WRITE;
/*!40000 ALTER TABLE `field_types` DISABLE KEYS */;
INSERT INTO `field_types` VALUES (1,1,'Customer','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(2,1,'Code','string',NULL,0,1,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(3,1,'Version','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(4,1,'Type','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(5,1,'Label','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(6,1,'Organism','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(7,1,'Conc','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(8,1,'Volume','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(9,1,'Pool','string',NULL,0,0,'2020-03-19 17:30:41','2020-03-19 17:30:41','SampleType',NULL,NULL,NULL,NULL,NULL),(10,2,'Input Array','sample',NULL,1,NULL,'2020-03-19 17:30:41','2020-03-19 17:30:41','OperationType','input',0,'IA',3,12),(11,3,'Input Array','sample',NULL,1,NULL,'2020-03-19 17:30:41','2020-03-19 17:30:41','OperationType','input',0,'IA',NULL,NULL),(12,3,'Output Array','sample',NULL,1,NULL,'2020-03-19 17:30:41','2020-03-19 17:30:41','OperationType','output',0,'IA',NULL,NULL),(13,4,'Input Array','sample',NULL,1,NULL,'2020-03-19 17:30:41','2020-03-19 17:30:41','OperationType','input',0,'R',NULL,NULL),(14,4,'Output Array','sample',NULL,1,NULL,'2020-03-19 17:30:41','2020-03-19 17:30:41','OperationType','output',0,'R',NULL,NULL),(15,5,'Input Array','sample',NULL,1,NULL,'2020-03-19 17:30:41','2020-03-19 17:30:41','OperationType','input',1,'IS',NULL,NULL),(16,2,'Sequence A','string',NULL,0,1,'2020-03-19 18:05:56','2020-03-19 18:07:51','SampleType',NULL,NULL,NULL,NULL,NULL),(17,2,'Sequence B','string',NULL,0,1,'2020-03-19 18:07:51','2020-03-19 18:07:51','SampleType',NULL,NULL,NULL,NULL,NULL),(21,6,'Output Sample','sample',NULL,NULL,NULL,'2020-03-19 20:09:26','2020-03-19 20:09:26','OperationType','output',NULL,'O',NULL,NULL),(22,3,'Sequence','url',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(23,3,'Length','number',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(24,3,'Template','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(25,3,'Forward Primer','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(26,3,'Reverse Primer','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(27,3,'Restriction Enzyme(s)','string',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(28,3,'Yeast Marker','string',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(29,3,'Fragment Mix Array','sample',NULL,1,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(30,4,'Sequence','url',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(31,4,'Sequence Verification','url',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(32,4,'Bacterial Marker','string','Amp,Kan,Amp + Kan,Spec,Kan + Spec,Chlor,Tet,NA,Other',0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(33,4,'Yeast Marker','string','HIS,TRP,URA,LEU,NatMX,KanMX,HygMX,BleoMX,5FOA,NA,Other',0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(34,4,'Length','number',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(35,4,'Sequencing Primers','sample',NULL,1,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(36,4,'QC Primer1','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(37,4,'QC Primer2','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(38,4,'QC_length','number',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(39,4,'Transformation Temperature','number','37,30',0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(40,4,'Comp Cells','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(41,5,'Overhang Sequence','string',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(42,5,'Anneal Sequence','string',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(43,5,'T Anneal','number',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(44,6,'Parent','sample',NULL,NULL,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(45,7,'Parent','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(46,7,'Integrant','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(47,7,'Plasmid','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(48,7,'Integrated Marker(s)','string',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(49,7,'Plasmid Marker(s)','string',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(50,7,'Mating Type','string','MATa,MATalpha,Diploid',0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(51,7,'QC Primer1','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(52,7,'QC Primer2','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(53,7,'QC_length','number','',0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(54,7,'Comp_cell_limit','string','Yes,No',0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(55,7,'Media','string',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(56,7,'Has this strain passed QC?','string','No,Yes',0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(57,7,'Haploids','sample',NULL,1,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(58,8,'Oligo Pool','sample',NULL,0,0,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(59,9,'Manufacturer','string',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(60,9,'Oligo Library ID','number',NULL,0,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(61,9,'inner forward primer (array)','sample',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(62,9,'inner reverse primer (array)','sample',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(63,9,'sublibrary forward primer (array)','sample',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(64,9,'sublibrary reverse primer (array)','sample',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(65,9,'min length (nt) (array)','number',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(66,9,'max length (nt) (array)','number',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(67,9,'variants (array)','number',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(68,9,'sublibrary name (array)','string',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(69,9,'forward priming site (array)','string',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(70,9,'reverse priming site (array)','string',NULL,1,1,'2020-03-24 15:41:53','2020-03-24 15:41:53','SampleType',NULL,NULL,NULL,NULL,NULL),(71,7,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','input',0,'X',NULL,NULL),(72,7,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','output',0,'X',NULL,NULL),(73,8,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','input',0,'X',NULL,NULL),(74,8,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','output',0,'X',NULL,NULL),(75,9,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','input',0,'X',NULL,NULL),(76,9,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','output',0,'X',NULL,NULL),(77,10,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:54','2020-03-24 15:41:54','OperationType','input',0,'X',NULL,NULL),(78,11,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,'X',NULL,NULL),(79,11,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','output',0,'X',NULL,NULL),(80,12,'Input','sample',NULL,1,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,'X',NULL,NULL),(81,12,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','output',0,'X',NULL,NULL),(82,13,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','output',0,'O',NULL,NULL),(83,13,'Operation Id','number',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,NULL,NULL,NULL),(84,13,'Output Field Value Name','string',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,NULL,NULL,NULL),(85,14,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,'X',NULL,NULL),(86,14,'Message','string',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,NULL,NULL,NULL),(87,14,'Subject','string',NULL,0,NULL,'2020-03-24 15:41:55','2020-03-24 15:41:55','OperationType','input',0,NULL,NULL,NULL),(88,15,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,'X',NULL,NULL),(89,15,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','output',0,'X',NULL,NULL),(90,15,'Experiment Number','number',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,NULL,NULL,NULL),(91,16,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,'X',NULL,NULL),(92,16,'Yes Response','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','output',0,'X',NULL,NULL),(93,16,'Response Message','string',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,NULL,NULL,NULL),(94,16,'Expected Yes','string',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,NULL,NULL,NULL),(95,16,'Expected No','string',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,NULL,NULL,NULL),(96,16,'No Response','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','output',0,'X',NULL,NULL),(97,17,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,'X',NULL,NULL),(98,17,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','output',0,'X',NULL,NULL),(99,17,'Associations','json',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,NULL,NULL,NULL),(100,18,'Case Sample','sample',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,'X',NULL,NULL),(101,18,'Route Possibilites','sample',NULL,1,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','output',0,'X',NULL,NULL),(102,18,'Switch','json',NULL,0,NULL,'2020-03-24 15:41:56','2020-03-24 15:41:56','OperationType','input',0,NULL,NULL,NULL),(103,19,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','output',0,'X',NULL,NULL),(104,19,'Channel','number',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(105,19,'Selection Method','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(106,20,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,'X',NULL,NULL),(107,20,'True','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','output',0,'X',NULL,NULL),(108,20,'Response','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(109,20,'True Response','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(110,20,'False Response','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(111,20,'False','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','output',0,'X',NULL,NULL),(112,21,'Sample','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,'X',NULL,NULL),(113,21,'Sample','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','output',0,'X',NULL,NULL),(114,21,'Response Request Message','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(115,21,'Response Tag','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(116,21,'Response Regex Format','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(117,21,'Response Level','string',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,NULL,NULL,NULL),(118,22,'Input','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','input',0,'X',NULL,NULL),(119,22,'Output','sample',NULL,0,NULL,'2020-03-24 15:41:57','2020-03-24 15:41:57','OperationType','output',0,'X',NULL,NULL),(120,22,'Channel','number',NULL,0,NULL,'2020-03-24 15:41:58','2020-03-24 15:41:58','OperationType','input',0,NULL,NULL,NULL),(121,23,'Channel','number',NULL,NULL,NULL,'2020-03-24 15:50:37','2020-03-24 15:50:37','OperationType','input',NULL,NULL,NULL,NULL),(122,23,'Selection Method','string',NULL,NULL,NULL,'2020-03-24 15:50:37','2020-03-24 15:50:37','OperationType','input',NULL,NULL,NULL,NULL),(123,23,'Output','sample',NULL,NULL,NULL,'2020-03-24 15:51:41','2020-03-24 15:51:41','OperationType','output',NULL,'X',NULL,NULL),(124,24,'Input','sample',NULL,NULL,NULL,'2020-03-24 16:01:17','2020-03-24 16:01:17','OperationType','input',NULL,'X',NULL,NULL),(125,24,'Output','sample',NULL,NULL,NULL,'2020-03-24 16:01:17','2020-03-24 16:01:17','OperationType','output',NULL,'X',NULL,NULL),(126,24,'New output','sample',NULL,NULL,NULL,'2020-03-24 16:01:17','2020-03-24 16:01:17','OperationType','output',NULL,NULL,NULL,NULL),(127,24,'Channel','number',NULL,NULL,NULL,'2020-03-24 16:01:17','2020-03-24 16:01:17','OperationType','input',NULL,NULL,NULL,NULL),(128,4,'Frag_Example','sample',NULL,NULL,NULL,'2020-03-24 18:29:56','2020-03-24 18:29:56','OperationType','input',NULL,'F',NULL,NULL),(129,5,'Frag_out','sample',NULL,NULL,NULL,'2020-03-24 18:30:30','2020-03-24 18:30:30','OperationType','output',NULL,'f',NULL,NULL);
/*!40000 ALTER TABLE `field_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `field_values`
--

DROP TABLE IF EXISTS `field_values`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `field_values` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `value` text COLLATE utf8_unicode_ci,
  `child_sample_id` int(11) DEFAULT NULL,
  `child_item_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `parent_class` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `role` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `field_type_id` int(11) DEFAULT NULL,
  `row` int(11) DEFAULT NULL,
  `column` int(11) DEFAULT NULL,
  `allowable_field_type_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_field_values_on_allowable_field_type_id` (`allowable_field_type_id`),
  KEY `index_field_values_on_field_type_id` (`field_type_id`),
  KEY `index_field_values_on_sample_id` (`parent_id`)
) ENGINE=InnoDB AUTO_INCREMENT=2111 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `field_values`
--

LOCK TABLES `field_values` WRITE;
/*!40000 ALTER TABLE `field_values` DISABLE KEYS */;
INSERT INTO `field_values` VALUES (1,1,'A',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(2,1,'1-S1',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Code','Sample',NULL,NULL,NULL,NULL,NULL),(3,1,'1',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Version','Sample',NULL,NULL,NULL,NULL,NULL),(4,1,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Type','Sample',NULL,NULL,NULL,NULL,NULL),(5,1,'AS_S1_062519',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Label','Sample',NULL,NULL,NULL,NULL,NULL),(6,1,'',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(7,1,'153.75',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(8,1,'50',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(9,1,'',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(10,2,'A',NULL,NULL,'2020-03-19 17:58:24','2020-03-19 17:58:24','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(11,2,'1-S2',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(12,2,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(13,2,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(14,2,'AS_S2_062519',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(15,2,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(16,2,'54.05',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(17,2,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(18,2,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(19,3,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(20,3,'1-S3',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(21,3,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(22,3,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(23,3,'BCSS_S1_062519',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(24,3,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(25,3,'73.25',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(26,3,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(27,3,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(28,4,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(29,4,'1-S4',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(30,4,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(31,4,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(32,4,'BCSS_S2_062519',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(33,4,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(34,4,'57.6',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(35,4,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(36,4,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(37,5,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(38,5,'1-S5',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(39,5,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(40,5,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(41,5,'AS_S1_062520',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(42,5,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(43,5,'113.8',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(44,5,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(45,5,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(46,6,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(47,6,'1-S6',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(48,6,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(49,6,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(50,6,'AS_S2_062520',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(51,6,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(52,6,'28.9',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(53,6,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(54,6,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(55,7,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(56,7,'1-S7',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(57,7,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(58,7,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(59,7,'BCSS_S1_062520',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(60,7,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(61,7,'121.4',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(62,7,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(63,7,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(64,8,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(65,8,'1-S8',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(66,8,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(67,8,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(68,8,'BCSS_S2_062520',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(69,8,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(70,8,'66.2',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(71,8,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(72,8,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(73,9,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(74,9,'1-S9',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(75,9,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(76,9,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(77,9,'AS_S1_062521',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(78,9,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(79,9,'64.71071429',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(80,9,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(81,9,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(82,10,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(83,10,'1-S10',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(84,10,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(85,10,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(86,10,'AS_S2_062521',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(87,10,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(88,10,'60.50892857',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(89,10,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(90,10,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(91,11,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(92,11,'1-S11',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(93,11,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(94,11,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(95,11,'BCSS_S1_062521',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(96,11,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(97,11,'56.30714286',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(98,11,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(99,11,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(100,12,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(101,12,'1-S12',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(102,12,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(103,12,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(104,12,'BCSS_S2_062521',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(105,12,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(106,12,'52.10535714',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(107,12,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(108,12,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(109,13,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(110,13,'1-S13',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(111,13,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(112,13,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(113,13,'AS_S1_062522',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(114,13,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(115,13,'47.90357143',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(116,13,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(117,13,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(118,14,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(119,14,'1-S14',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(120,14,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(121,14,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(122,14,'AS_S2_062522',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(123,14,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(124,14,'43.70178571',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(125,14,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(126,14,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(127,15,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(128,15,'1-S15',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(129,15,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(130,15,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(131,15,'BCSS_S1_062522',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(132,15,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(133,15,'39.5',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(134,15,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(135,15,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(136,16,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(137,16,'1-S16',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(138,16,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(139,16,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(140,16,'BCSS_S2_062522',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(141,16,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(142,16,'35.29821429',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(143,16,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(144,16,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(145,17,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(146,17,'1-S17',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(147,17,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(148,17,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(149,17,'AS_S1_062523',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(150,17,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(151,17,'31.09642857',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(152,17,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(153,17,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(154,18,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(155,18,'1-S18',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(156,18,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(157,18,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(158,18,'AS_S2_062523',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(159,18,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(160,18,'26.89464286',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(161,18,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(162,18,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(163,19,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(164,19,'1-S19',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(165,19,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(166,19,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(167,19,'BCSS_S1_062523',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(168,19,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(169,19,'22.69285714',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(170,19,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(171,19,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(172,20,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(173,20,'1-S20',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(174,20,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(175,20,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(176,20,'BCSS_S2_062523',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(177,20,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(178,20,'18.49107143',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(179,20,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(180,20,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(181,21,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(182,21,'1-S21',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(183,21,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(184,21,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(185,21,'AS_S1_062524',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(186,21,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(187,21,'14.28928571',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(188,21,'50',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(189,21,'',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(190,22,'A',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(191,22,'1-S22',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Code','Sample',NULL,NULL,NULL,NULL,NULL),(192,22,'1',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Version','Sample',NULL,NULL,NULL,NULL,NULL),(193,22,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Type','Sample',NULL,NULL,NULL,NULL,NULL),(194,22,'AS_S2_062524',NULL,NULL,'2020-03-19 17:58:25','2020-03-19 17:58:25','Label','Sample',NULL,NULL,NULL,NULL,NULL),(195,22,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(196,22,'10.0875',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(197,22,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(198,22,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(199,23,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(200,23,'1-S23',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(201,23,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(202,23,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(203,23,'BCSS_S1_062524',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(204,23,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(205,23,'5.885714286',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(206,23,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(207,23,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(208,24,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(209,24,'1-S24',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(210,24,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(211,24,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(212,24,'BCSS_S2_062524',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(213,24,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(214,24,'1.683928571',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(215,24,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(216,24,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(217,25,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(218,25,'1-S25',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(219,25,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(220,25,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(221,25,'AS_S1_062525',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(222,25,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(223,25,'153.75',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(224,25,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(225,25,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(226,26,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(227,26,'1-S26',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(228,26,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(229,26,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(230,26,'AS_S2_062525',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(231,26,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(232,26,'54.05',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(233,26,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(234,26,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(235,27,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(236,27,'1-S27',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(237,27,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(238,27,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(239,27,'BCSS_S1_062525',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(240,27,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(241,27,'73.25',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(242,27,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(243,27,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(244,28,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(245,28,'1-S28',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(246,28,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(247,28,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(248,28,'BCSS_S2_062525',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(249,28,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(250,28,'57.6',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(251,28,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(252,28,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(253,29,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(254,29,'1-S29',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(255,29,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(256,29,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(257,29,'AS_S1_062526',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(258,29,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(259,29,'113.8',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(260,29,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(261,29,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(262,30,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(263,30,'1-S30',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(264,30,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(265,30,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(266,30,'AS_S2_062526',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(267,30,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(268,30,'28.9',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(269,30,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(270,30,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(271,31,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(272,31,'1-S31',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(273,31,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(274,31,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(275,31,'BCSS_S1_062526',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(276,31,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(277,31,'121.4',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(278,31,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(279,31,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(280,32,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(281,32,'1-S32',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(282,32,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(283,32,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(284,32,'BCSS_S2_062526',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(285,32,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(286,32,'66.2',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(287,32,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(288,32,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(289,33,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(290,33,'1-S33',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(291,33,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(292,33,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(293,33,'AS_S1_062527',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(294,33,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(295,33,'64.71071429',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(296,33,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(297,33,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(298,34,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(299,34,'1-S34',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(300,34,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(301,34,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(302,34,'AS_S2_062527',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(303,34,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(304,34,'60.50892857',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(305,34,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(306,34,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(307,35,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(308,35,'1-S35',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(309,35,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(310,35,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(311,35,'BCSS_S1_062527',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(312,35,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(313,35,'56.30714286',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(314,35,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(315,35,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(316,36,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(317,36,'1-S36',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(318,36,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(319,36,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(320,36,'BCSS_S2_062527',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(321,36,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(322,36,'52.10535714',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(323,36,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(324,36,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(325,37,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(326,37,'1-S37',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(327,37,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(328,37,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(329,37,'AS_S1_062528',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(330,37,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(331,37,'47.90357143',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(332,37,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(333,37,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(334,38,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(335,38,'1-S38',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(336,38,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(337,38,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(338,38,'AS_S2_062528',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(339,38,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(340,38,'43.70178571',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(341,38,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(342,38,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(343,39,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(344,39,'1-S39',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(345,39,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(346,39,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(347,39,'BCSS_S1_062528',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(348,39,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(349,39,'39.5',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(350,39,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(351,39,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(352,40,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(353,40,'1-S40',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(354,40,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(355,40,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(356,40,'BCSS_S2_062528',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(357,40,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(358,40,'35.29821429',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(359,40,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(360,40,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(361,41,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(362,41,'1-S41',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(363,41,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(364,41,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(365,41,'AS_S1_062529',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(366,41,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(367,41,'31.09642857',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(368,41,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(369,41,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(370,42,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(371,42,'1-S42',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(372,42,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(373,42,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(374,42,'AS_S2_062529',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(375,42,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(376,42,'26.89464286',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(377,42,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(378,42,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(379,43,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(380,43,'1-S43',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(381,43,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(382,43,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(383,43,'BCSS_S1_062529',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Label','Sample',NULL,NULL,NULL,NULL,NULL),(384,43,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(385,43,'22.69285714',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(386,43,'50',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(387,43,'',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(388,44,'A',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(389,44,'1-S44',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Code','Sample',NULL,NULL,NULL,NULL,NULL),(390,44,'1',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Version','Sample',NULL,NULL,NULL,NULL,NULL),(391,44,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:26','2020-03-19 17:58:26','Type','Sample',NULL,NULL,NULL,NULL,NULL),(392,44,'BCSS_S2_062529',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(393,44,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(394,44,'18.49107143',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(395,44,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(396,44,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(397,45,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(398,45,'1-S45',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(399,45,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(400,45,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(401,45,'AS_S1_062530',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(402,45,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(403,45,'14.28928571',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(404,45,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(405,45,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(406,46,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(407,46,'1-S46',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(408,46,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(409,46,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(410,46,'AS_S2_062530',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(411,46,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(412,46,'10.0875',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(413,46,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(414,46,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(415,47,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(416,47,'1-S47',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(417,47,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(418,47,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(419,47,'BCSS_S1_062530',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(420,47,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(421,47,'5.885714286',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(422,47,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(423,47,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(424,48,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(425,48,'1-S48',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(426,48,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(427,48,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(428,48,'BCSS_S2_062530',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(429,48,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(430,48,'1.683928571',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(431,48,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(432,48,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(433,49,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(434,49,'1-S49',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(435,49,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(436,49,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(437,49,'AS_S1_062531',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(438,49,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(439,49,'153.75',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(440,49,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(441,49,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(442,50,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(443,50,'1-S50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(444,50,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(445,50,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(446,50,'AS_S2_062531',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(447,50,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(448,50,'54.05',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(449,50,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(450,50,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(451,51,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(452,51,'1-S51',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(453,51,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(454,51,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(455,51,'BCSS_S1_062531',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(456,51,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(457,51,'73.25',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(458,51,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(459,51,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(460,52,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(461,52,'1-S52',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(462,52,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(463,52,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(464,52,'BCSS_S2_062531',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(465,52,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(466,52,'57.6',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(467,52,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(468,52,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(469,53,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(470,53,'1-S53',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(471,53,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(472,53,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(473,53,'AS_S1_062532',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(474,53,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(475,53,'113.8',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(476,53,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(477,53,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(478,54,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(479,54,'1-S54',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(480,54,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(481,54,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(482,54,'AS_S2_062532',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(483,54,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(484,54,'28.9',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(485,54,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(486,54,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(487,55,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(488,55,'1-S55',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(489,55,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(490,55,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(491,55,'BCSS_S1_062532',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(492,55,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(493,55,'121.4',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(494,55,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(495,55,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(496,56,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(497,56,'1-S56',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(498,56,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(499,56,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(500,56,'BCSS_S2_062532',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(501,56,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(502,56,'66.2',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(503,56,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(504,56,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(505,57,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(506,57,'1-S57',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(507,57,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(508,57,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(509,57,'AS_S1_062533',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(510,57,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(511,57,'64.71071429',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(512,57,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(513,57,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(514,58,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(515,58,'1-S58',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(516,58,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(517,58,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(518,58,'AS_S2_062533',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(519,58,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(520,58,'60.50892857',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(521,58,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(522,58,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(523,59,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(524,59,'1-S59',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(525,59,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(526,59,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(527,59,'BCSS_S1_062533',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(528,59,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(529,59,'56.30714286',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(530,59,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(531,59,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(532,60,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(533,60,'1-S60',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(534,60,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(535,60,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(536,60,'BCSS_S2_062533',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(537,60,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(538,60,'52.10535714',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(539,60,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(540,60,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(541,61,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(542,61,'1-S61',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(543,61,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(544,61,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(545,61,'AS_S1_062534',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(546,61,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(547,61,'47.90357143',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(548,61,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(549,61,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(550,62,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(551,62,'1-S62',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(552,62,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(553,62,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(554,62,'AS_S2_062534',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(555,62,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(556,62,'43.70178571',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(557,62,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(558,62,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(559,63,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(560,63,'1-S63',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(561,63,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(562,63,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(563,63,'BCSS_S1_062534',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(564,63,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(565,63,'39.5',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(566,63,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(567,63,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(568,64,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(569,64,'1-S64',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(570,64,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(571,64,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(572,64,'BCSS_S2_062534',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(573,64,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(574,64,'35.29821429',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(575,64,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(576,64,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(577,65,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(578,65,'1-S65',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(579,65,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(580,65,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(581,65,'AS_S1_062535',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(582,65,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(583,65,'31.09642857',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(584,65,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(585,65,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(586,66,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(587,66,'1-S66',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(588,66,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(589,66,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(590,66,'AS_S2_062535',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(591,66,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(592,66,'26.89464286',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(593,66,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(594,66,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(595,67,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(596,67,'1-S67',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(597,67,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Version','Sample',NULL,NULL,NULL,NULL,NULL),(598,67,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Type','Sample',NULL,NULL,NULL,NULL,NULL),(599,67,'BCSS_S1_062535',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Label','Sample',NULL,NULL,NULL,NULL,NULL),(600,67,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(601,67,'22.69285714',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(602,67,'50',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(603,67,'',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(604,68,'A',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(605,68,'1-S68',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:27','Code','Sample',NULL,NULL,NULL,NULL,NULL),(606,68,'1',NULL,NULL,'2020-03-19 17:58:27','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(607,68,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(608,68,'BCSS_S2_062535',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(609,68,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(610,68,'18.49107143',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(611,68,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(612,68,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(613,69,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(614,69,'1-S69',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(615,69,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(616,69,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(617,69,'AS_S1_062536',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(618,69,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(619,69,'14.28928571',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(620,69,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(621,69,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(622,70,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(623,70,'1-S70',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(624,70,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(625,70,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(626,70,'AS_S2_062536',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(627,70,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(628,70,'10.0875',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(629,70,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(630,70,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(631,71,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(632,71,'1-S71',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(633,71,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(634,71,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(635,71,'BCSS_S1_062536',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(636,71,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(637,71,'5.885714286',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(638,71,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(639,71,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(640,72,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(641,72,'1-S72',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(642,72,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(643,72,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(644,72,'BCSS_S2_062536',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(645,72,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(646,72,'1.683928571',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(647,72,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(648,72,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(649,73,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(650,73,'1-S73',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(651,73,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(652,73,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(653,73,'AS_S1_062537',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(654,73,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(655,73,'153.75',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(656,73,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(657,73,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(658,74,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(659,74,'1-S74',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(660,74,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(661,74,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(662,74,'AS_S2_062537',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(663,74,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(664,74,'54.05',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(665,74,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(666,74,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(667,75,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(668,75,'1-S75',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(669,75,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(670,75,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(671,75,'BCSS_S1_062537',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(672,75,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(673,75,'73.25',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(674,75,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(675,75,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(676,76,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(677,76,'1-S76',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(678,76,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(679,76,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(680,76,'BCSS_S2_062537',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(681,76,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(682,76,'57.6',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(683,76,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(684,76,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(685,77,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(686,77,'1-S77',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(687,77,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(688,77,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(689,77,'AS_S1_062538',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(690,77,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(691,77,'113.8',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(692,77,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(693,77,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(694,78,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(695,78,'1-S78',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(696,78,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(697,78,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(698,78,'AS_S2_062538',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(699,78,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(700,78,'28.9',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(701,78,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(702,78,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(703,79,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(704,79,'1-S79',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(705,79,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(706,79,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(707,79,'BCSS_S1_062538',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(708,79,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(709,79,'121.4',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(710,79,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(711,79,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(712,80,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(713,80,'1-S80',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(714,80,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(715,80,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(716,80,'BCSS_S2_062538',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(717,80,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(718,80,'66.2',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(719,80,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(720,80,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(721,81,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(722,81,'1-S81',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(723,81,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(724,81,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(725,81,'AS_S1_062539',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(726,81,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(727,81,'64.71071429',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(728,81,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(729,81,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(730,82,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(731,82,'1-S82',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(732,82,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(733,82,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(734,82,'AS_S2_062539',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(735,82,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(736,82,'60.50892857',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(737,82,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(738,82,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(739,83,'A',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Customer','Sample',NULL,NULL,NULL,NULL,NULL),(740,83,'1-S83',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Code','Sample',NULL,NULL,NULL,NULL,NULL),(741,83,'1',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Version','Sample',NULL,NULL,NULL,NULL,NULL),(742,83,'DNA-Seq (~500bp insert)',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Type','Sample',NULL,NULL,NULL,NULL,NULL),(743,83,'BCSS_S1_062539',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Label','Sample',NULL,NULL,NULL,NULL,NULL),(744,83,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Organism','Sample',NULL,NULL,NULL,NULL,NULL),(745,83,'56.30714286',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Conc','Sample',NULL,NULL,NULL,NULL,NULL),(746,83,'50',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Volume','Sample',NULL,NULL,NULL,NULL,NULL),(747,83,'',NULL,NULL,'2020-03-19 17:58:28','2020-03-19 17:58:28','Pool','Sample',NULL,NULL,NULL,NULL,NULL),(1070,245,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1071,245,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1072,246,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1073,246,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1074,247,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1075,247,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1076,248,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1077,248,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1078,249,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1079,249,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1080,250,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1081,250,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1082,251,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1083,251,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1084,252,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1085,252,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1086,253,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1087,253,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1088,254,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1089,254,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1090,255,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1091,255,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1092,256,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1093,256,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1094,257,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1095,257,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1096,258,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1097,258,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1098,259,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1099,259,'gattcgt',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:25','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1100,260,'acgtcctg',NULL,NULL,'2020-03-19 18:34:25','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1101,260,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1102,261,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1103,261,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1104,262,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1105,262,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1106,263,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1107,263,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1108,264,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1109,264,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1110,265,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1111,265,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1112,266,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1113,266,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1114,267,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1115,267,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1116,268,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1117,268,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1118,269,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1119,269,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1120,270,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1121,270,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1122,271,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1123,271,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1124,272,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1125,272,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1126,273,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1127,273,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1128,274,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1129,274,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1130,275,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1131,275,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1132,276,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1133,276,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1134,277,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1135,277,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1136,278,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1137,278,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1138,279,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1139,279,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1140,280,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1141,280,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1142,281,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1143,281,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1144,282,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1145,282,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1146,283,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1147,283,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1148,284,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1149,284,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1150,285,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1151,285,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1152,286,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1153,286,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1154,287,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1155,287,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1156,288,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1157,288,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1158,289,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1159,289,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1160,290,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1161,290,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1162,291,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1163,291,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1164,292,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1165,292,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1166,293,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1167,293,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1168,294,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1169,294,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1170,295,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1171,295,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1172,296,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1173,296,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1174,297,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1175,297,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1176,298,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1177,298,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1178,299,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1179,299,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1180,300,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1181,300,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1182,301,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1183,301,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1184,302,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1185,302,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1186,303,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1187,303,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1188,304,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1189,304,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1190,305,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1191,305,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1192,306,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1193,306,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1194,307,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1195,307,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1196,308,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1197,308,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1198,309,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1199,309,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1200,310,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1201,310,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1202,311,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1203,311,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1204,312,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1205,312,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1206,313,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1207,313,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1208,314,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1209,314,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1210,315,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1211,315,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1212,316,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1213,316,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1214,317,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1215,317,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1216,318,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1217,318,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1218,319,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1219,319,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1220,320,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1221,320,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1222,321,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1223,321,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1224,322,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1225,322,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1226,323,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1227,323,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1228,324,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1229,324,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1230,325,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1231,325,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1232,326,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1233,326,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1234,327,'acgtcctg',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1235,327,'gattcgt',NULL,NULL,'2020-03-19 18:34:26','2020-03-19 18:34:26','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1236,328,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1237,328,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1238,329,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1239,329,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1240,330,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1241,330,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1242,331,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1243,331,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1244,332,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1245,332,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1246,333,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1247,333,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1248,334,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1249,334,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1250,335,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1251,335,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1252,336,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1253,336,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1254,337,'acgtcctg',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1255,337,'gattcgt',NULL,NULL,'2020-03-19 18:34:27','2020-03-19 18:34:27','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1520,470,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1521,470,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1522,471,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1523,471,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1524,472,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1525,472,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1526,473,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1527,473,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1528,474,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1529,474,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1530,475,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1531,475,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1532,476,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1533,476,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1534,477,'acgtcctg',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1535,477,'gattcgt',NULL,NULL,'2020-03-19 19:04:34','2020-03-19 19:04:34','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1536,478,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1537,478,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1538,479,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1539,479,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1540,480,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1541,480,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1542,481,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1543,481,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1544,482,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1545,482,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1546,483,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1547,483,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1548,484,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1549,484,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1550,485,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1551,485,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1552,486,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1553,486,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1554,487,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1555,487,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1556,488,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1557,488,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1558,489,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1559,489,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1560,490,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1561,490,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1562,491,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1563,491,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1564,492,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1565,492,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1566,493,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1567,493,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1568,494,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1569,494,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1570,495,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1571,495,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1572,496,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1573,496,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1574,497,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1575,497,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1576,498,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1577,498,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1578,499,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1579,499,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1580,500,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1581,500,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1582,501,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1583,501,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1584,502,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1585,502,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1586,503,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1587,503,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1588,504,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1589,504,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1590,505,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1591,505,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1592,506,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1593,506,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1594,507,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1595,507,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1596,508,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1597,508,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1598,509,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1599,509,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1600,510,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1601,510,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1602,511,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1603,511,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1604,512,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1605,512,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1606,513,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1607,513,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1608,514,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1609,514,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1610,515,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1611,515,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1612,516,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1613,516,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1614,517,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1615,517,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1616,518,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1617,518,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1618,519,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1619,519,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1620,520,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1621,520,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1622,521,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1623,521,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1624,522,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1625,522,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1626,523,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1627,523,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1628,524,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1629,524,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1630,525,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1631,525,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1632,526,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1633,526,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1634,527,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1635,527,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1636,528,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1637,528,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1638,529,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1639,529,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1640,530,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1641,530,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1642,531,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1643,531,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1644,532,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1645,532,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1646,533,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1647,533,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1648,534,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1649,534,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1650,535,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1651,535,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1652,536,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1653,536,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1654,537,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1655,537,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1656,538,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1657,538,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1658,539,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1659,539,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1660,540,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1661,540,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1662,541,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1663,541,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1664,542,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1665,542,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1666,543,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1667,543,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1668,544,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1669,544,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1670,545,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1671,545,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1672,546,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1673,546,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1674,547,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1675,547,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1676,548,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1677,548,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1678,549,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1679,549,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1680,550,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1681,550,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1682,551,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1683,551,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1684,552,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1685,552,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1686,553,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1687,553,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1688,554,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1689,554,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1690,555,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1691,555,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1692,556,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1693,556,'gattcgt',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1694,557,'acgtcctg',NULL,NULL,'2020-03-19 19:04:35','2020-03-19 19:04:35','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1695,557,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1696,558,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1697,558,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1698,559,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1699,559,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1700,560,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1701,560,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1702,561,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1703,561,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1704,562,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1705,562,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1706,563,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1707,563,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1708,564,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1709,564,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1710,565,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1711,565,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1712,566,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1713,566,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1714,567,'acgtcctg',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence A','Sample',NULL,NULL,NULL,NULL,NULL),(1715,567,'gattcgt',NULL,NULL,'2020-03-19 19:04:36','2020-03-19 19:04:36','Sequence B','Sample',NULL,NULL,NULL,NULL,NULL),(1720,5,NULL,NULL,NULL,'2020-03-19 20:07:00','2020-03-19 20:17:57','Output Sample','Operation','output',21,NULL,NULL,NULL),(1721,6,NULL,1,200,'2020-03-19 20:07:00','2020-03-19 20:17:57','Input Array','Operation','input',13,0,0,4),(1722,6,NULL,1,781,'2020-03-19 20:07:00','2020-03-24 15:15:39','Output Array','Operation','output',14,0,0,5),(1723,6,NULL,NULL,NULL,'2020-03-19 20:07:00','2020-03-19 20:17:57','Adapter Plate','Operation','input',22,NULL,NULL,NULL),(1724,6,NULL,2,200,'2020-03-19 20:07:00','2020-03-19 20:17:57','Input Array','Operation','input',13,1,0,4),(1725,6,NULL,2,781,'2020-03-19 20:07:00','2020-03-24 15:15:39','Output Array','Operation','output',14,0,1,5),(1726,7,NULL,1,NULL,'2020-03-19 20:17:57','2020-03-19 20:17:57','Input Array','Operation','input',10,NULL,NULL,1),(1727,7,NULL,2,NULL,'2020-03-19 20:17:57','2020-03-19 20:17:57','Input Array','Operation','input',10,NULL,NULL,1),(1728,8,NULL,1,NULL,'2020-03-19 20:17:57','2020-03-19 20:17:57','Input Array','Operation','input',11,NULL,NULL,2),(1729,8,NULL,1,NULL,'2020-03-19 20:17:57','2020-03-19 20:17:57','Output Array','Operation','output',12,NULL,NULL,3),(1730,8,NULL,2,NULL,'2020-03-19 20:17:57','2020-03-19 20:17:57','Input Array','Operation','input',11,NULL,NULL,2),(1731,8,NULL,2,NULL,'2020-03-19 20:17:57','2020-03-19 20:17:57','Output Array','Operation','output',12,NULL,NULL,3),(1732,9,NULL,1,200,'2020-03-19 20:17:57','2020-03-19 20:17:57','Input Array','Operation','input',15,0,0,6),(1733,9,NULL,2,200,'2020-03-19 20:17:57','2020-03-19 20:17:57','Input Array','Operation','input',15,1,0,6),(1763,39,NULL,1,200,'2020-03-20 16:58:17','2020-03-20 17:15:32','Input Array','Operation','input',13,0,0,4),(1764,39,NULL,1,844,'2020-03-20 16:58:17','2020-03-24 16:06:38','Output Array','Operation','output',14,0,0,5),(1766,39,NULL,2,200,'2020-03-20 16:58:17','2020-03-20 17:15:32','Input Array','Operation','input',13,1,0,4),(1767,39,NULL,3,844,'2020-03-20 16:58:17','2020-03-24 16:06:38','Output Array','Operation','output',14,0,2,5),(1768,40,NULL,1,844,'2020-03-20 16:58:17','2020-03-24 16:06:52','Input Array','Operation','input',10,0,0,1),(1769,40,NULL,3,844,'2020-03-20 16:58:17','2020-03-24 16:06:52','Input Array','Operation','input',10,0,2,1),(1770,41,NULL,1,844,'2020-03-20 16:58:17','2020-03-24 16:06:52','Input Array','Operation','input',11,0,0,2),(1771,41,NULL,1,NULL,'2020-03-20 16:58:17','2020-03-20 16:58:17','Output Array','Operation','output',12,NULL,NULL,3),(1772,41,NULL,3,844,'2020-03-20 16:58:17','2020-03-24 16:06:52','Input Array','Operation','input',11,0,2,2),(1773,41,NULL,2,NULL,'2020-03-20 16:58:17','2020-03-20 16:58:17','Output Array','Operation','output',12,NULL,NULL,3),(1774,42,NULL,1,200,'2020-03-20 16:58:17','2020-03-20 17:15:32','Input Array','Operation','input',15,0,0,6),(1775,42,NULL,2,200,'2020-03-20 16:58:17','2020-03-20 17:15:32','Input Array','Operation','input',15,1,0,6),(1776,39,NULL,3,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',13,2,0,4),(1777,39,NULL,4,200,'2020-03-20 18:43:06','2020-03-20 18:43:06','Input Array','Operation','input',13,3,0,4),(1778,39,NULL,5,200,'2020-03-20 18:43:06','2020-03-20 18:43:06','Input Array','Operation','input',13,4,0,4),(1779,39,NULL,6,200,'2020-03-20 18:43:06','2020-03-20 18:43:06','Input Array','Operation','input',13,5,0,4),(1780,39,NULL,7,200,'2020-03-20 18:43:06','2020-03-20 18:43:06','Input Array','Operation','input',13,6,0,4),(1781,39,NULL,8,200,'2020-03-20 18:43:06','2020-03-20 18:43:06','Input Array','Operation','input',13,7,0,4),(1782,40,NULL,3,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',10,0,2,1),(1783,40,NULL,4,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',10,0,3,1),(1784,40,NULL,5,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',10,0,4,1),(1785,40,NULL,6,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',10,0,5,1),(1786,40,NULL,7,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',10,0,6,1),(1787,40,NULL,8,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',10,0,7,1),(1788,41,NULL,3,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',11,0,2,2),(1789,41,NULL,4,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',11,0,3,2),(1790,41,NULL,5,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',11,0,4,2),(1791,41,NULL,6,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',11,0,5,2),(1792,41,NULL,7,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',11,0,6,2),(1793,41,NULL,8,844,'2020-03-20 18:43:06','2020-03-24 16:06:52','Input Array','Operation','input',11,0,7,2),(1794,41,NULL,3,NULL,'2020-03-20 18:43:06','2020-03-20 18:46:06','Output Array','Operation','output',12,NULL,NULL,3),(1795,41,NULL,4,NULL,'2020-03-20 18:43:06','2020-03-20 18:46:06','Output Array','Operation','output',12,NULL,NULL,3),(1796,41,NULL,5,NULL,'2020-03-20 18:43:06','2020-03-20 18:46:06','Output Array','Operation','output',12,NULL,NULL,3),(1797,41,NULL,6,NULL,'2020-03-20 18:43:06','2020-03-20 18:46:06','Output Array','Operation','output',12,NULL,NULL,3),(1798,41,NULL,7,NULL,'2020-03-20 18:43:06','2020-03-20 18:46:06','Output Array','Operation','output',12,NULL,NULL,3),(1799,41,NULL,8,NULL,'2020-03-20 18:43:06','2020-03-20 18:46:06','Output Array','Operation','output',12,NULL,NULL,3),(1800,42,NULL,3,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',15,2,0,6),(1801,42,NULL,4,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',15,3,0,6),(1802,42,NULL,5,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',15,4,0,6),(1803,42,NULL,6,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',15,5,0,6),(1804,42,NULL,7,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',15,6,0,6),(1805,42,NULL,8,200,'2020-03-20 18:43:06','2020-03-20 18:46:06','Input Array','Operation','input',15,7,0,6),(1806,39,NULL,3,844,'2020-03-20 18:46:06','2020-03-24 16:06:38','Output Array','Operation','output',14,0,2,5),(1807,39,NULL,4,844,'2020-03-20 18:46:06','2020-03-24 16:06:38','Output Array','Operation','output',14,0,3,5),(1808,39,NULL,5,844,'2020-03-20 18:46:06','2020-03-24 16:06:38','Output Array','Operation','output',14,0,4,5),(1809,39,NULL,6,844,'2020-03-20 18:46:06','2020-03-24 16:06:38','Output Array','Operation','output',14,0,5,5),(1810,39,NULL,7,844,'2020-03-20 18:46:06','2020-03-24 16:06:38','Output Array','Operation','output',14,0,6,5),(1811,39,NULL,8,844,'2020-03-20 18:46:06','2020-03-24 16:06:38','Output Array','Operation','output',14,0,7,5),(1851,82,NULL,1,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,0,0,4),(1852,82,NULL,1,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,0,5),(1853,82,NULL,2,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,1,0,4),(1854,82,NULL,2,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,1,5),(1855,82,NULL,3,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,2,0,4),(1856,82,NULL,4,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,3,0,4),(1857,82,NULL,5,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,4,0,4),(1858,82,NULL,6,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,5,0,4),(1859,82,NULL,7,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,6,0,4),(1860,82,NULL,8,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',13,7,0,4),(1861,82,NULL,3,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,2,5),(1862,82,NULL,4,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,3,5),(1863,82,NULL,5,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,4,5),(1864,82,NULL,6,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,5,5),(1865,82,NULL,7,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,6,5),(1866,82,NULL,8,913,'2020-03-24 16:08:07','2020-03-24 16:17:48','Output Array','Operation','output',14,0,7,5),(1867,83,NULL,1,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,0,1),(1868,83,NULL,2,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,1,1),(1869,83,NULL,3,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,2,1),(1870,83,NULL,4,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,3,1),(1871,83,NULL,5,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,4,1),(1872,83,NULL,6,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,5,1),(1873,83,NULL,7,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,6,1),(1874,83,NULL,8,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',10,0,7,1),(1875,84,NULL,1,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,0,2),(1876,84,NULL,1,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,0,3),(1877,84,NULL,2,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,1,2),(1878,84,NULL,2,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,1,3),(1879,84,NULL,3,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,2,2),(1880,84,NULL,4,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,3,2),(1881,84,NULL,5,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,4,2),(1882,84,NULL,6,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,5,2),(1883,84,NULL,7,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,6,2),(1884,84,NULL,8,913,'2020-03-24 16:08:07','2020-03-24 16:17:59','Input Array','Operation','input',11,0,7,2),(1885,84,NULL,3,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,2,3),(1886,84,NULL,4,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,3,3),(1887,84,NULL,5,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,4,3),(1888,84,NULL,6,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,5,3),(1889,84,NULL,7,992,'2020-03-24 16:08:07','2020-03-24 18:21:27','Output Array','Operation','output',12,0,6,3),(1890,84,NULL,8,992,'2020-03-24 16:08:07','2020-03-24 18:21:28','Output Array','Operation','output',12,0,7,3),(1891,85,NULL,1,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,0,0,6),(1892,85,NULL,2,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,1,0,6),(1893,85,NULL,3,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,2,0,6),(1894,85,NULL,4,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,3,0,6),(1895,85,NULL,5,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,4,0,6),(1896,85,NULL,6,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,5,0,6),(1897,85,NULL,7,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,6,0,6),(1898,85,NULL,8,200,'2020-03-24 16:08:07','2020-03-24 16:08:39','Input Array','Operation','input',15,7,0,6),(2015,100,NULL,1,781,'2020-03-24 18:32:04','2020-03-24 18:59:25','Input Array','Operation','input',10,0,0,1),(2016,100,NULL,2,781,'2020-03-24 18:32:04','2020-03-24 18:59:25','Input Array','Operation','input',10,0,1,1),(2017,101,NULL,1,781,'2020-03-24 18:32:04','2020-03-24 18:59:25','Input Array','Operation','input',11,0,0,2),(2018,101,NULL,1,NULL,'2020-03-24 18:32:04','2020-03-24 18:32:04','Output Array','Operation','output',12,NULL,NULL,3),(2019,101,NULL,2,781,'2020-03-24 18:32:04','2020-03-24 18:59:25','Input Array','Operation','input',11,0,1,2),(2020,101,NULL,2,NULL,'2020-03-24 18:32:04','2020-03-24 18:32:04','Output Array','Operation','output',12,NULL,NULL,3),(2023,103,NULL,1,200,'2020-03-24 18:32:57','2020-03-24 18:59:25','Input Array','Operation','input',15,0,0,6),(2024,103,NULL,568,1002,'2020-03-24 18:32:57','2020-03-24 19:07:31','Frag_out','Operation','output',129,NULL,NULL,478),(2025,104,NULL,1,200,'2020-03-24 18:32:57','2020-03-24 18:59:25','Input Array','Operation','input',13,0,0,4),(2026,104,NULL,1,NULL,'2020-03-24 18:32:57','2020-03-24 18:59:25','Output Array','Operation','output',14,NULL,NULL,5),(2027,104,NULL,568,NULL,'2020-03-24 18:32:57','2020-03-24 18:59:25','Frag_Example','Operation','input',128,NULL,NULL,477),(2028,105,NULL,568,1002,'2020-03-24 18:32:57','2020-03-24 19:07:43','Input','Operation','input',124,NULL,NULL,476),(2029,105,NULL,568,1002,'2020-03-24 18:32:57','2020-03-24 19:07:43','Output','Operation','output',125,NULL,NULL,NULL),(2030,105,NULL,NULL,NULL,'2020-03-24 18:32:57','2020-03-24 18:32:57','New output','Operation','output',126,NULL,NULL,NULL),(2031,105,'1',NULL,NULL,'2020-03-24 18:32:57','2020-03-24 18:59:25','Channel','Operation','input',127,NULL,NULL,NULL),(2032,106,'1',NULL,NULL,'2020-03-24 18:32:57','2020-03-24 18:59:25','Channel','Operation','input',121,NULL,NULL,NULL),(2033,106,'Random',NULL,NULL,'2020-03-24 18:32:57','2020-03-24 19:01:19','Selection Method','Operation','input',122,NULL,NULL,NULL),(2034,106,NULL,568,NULL,'2020-03-24 18:32:57','2020-03-24 18:59:25','Output','Operation','output',123,NULL,NULL,475),(2035,568,'http://please.link.your.sequences.com',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','Sequence','Sample',NULL,NULL,NULL,NULL,NULL),(2036,568,'http://please.link.your.sequences.com',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','Sequence Verification','Sample',NULL,NULL,NULL,NULL,NULL),(2037,568,'Amp',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','Bacterial Marker','Sample',NULL,NULL,NULL,NULL,NULL),(2038,568,'HIS',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','Yeast Marker','Sample',NULL,NULL,NULL,NULL,NULL),(2039,568,'3434.0',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','Length','Sample',NULL,NULL,NULL,NULL,NULL),(2040,568,NULL,NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','QC Primer1','Sample',NULL,NULL,NULL,NULL,NULL),(2041,568,NULL,NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','QC Primer2','Sample',NULL,NULL,NULL,NULL,NULL),(2042,568,'0.0',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','QC_length','Sample',NULL,NULL,NULL,NULL,NULL),(2043,568,'37.0',NULL,NULL,'2020-03-24 18:57:02','2020-03-24 18:57:02','Transformation Temperature','Sample',NULL,NULL,NULL,NULL,NULL),(2044,568,NULL,NULL,NULL,'2020-03-24 18:57:03','2020-03-24 18:57:03','Comp Cells','Sample',NULL,NULL,NULL,NULL,NULL),(2045,103,NULL,2,200,'2020-03-24 18:59:25','2020-03-24 18:59:25','Input Array','Operation','input',15,1,0,6),(2046,104,NULL,2,NULL,'2020-03-24 18:59:25','2020-03-24 18:59:25','Output Array','Operation','output',14,NULL,NULL,5),(2047,104,NULL,2,200,'2020-03-24 18:59:25','2020-03-24 18:59:25','Input Array','Operation','input',13,1,0,4),(2048,107,NULL,1,781,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',10,0,0,1),(2049,107,NULL,2,781,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',10,0,1,1),(2050,108,NULL,1,781,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',11,0,0,2),(2051,108,NULL,1,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Output Array','Operation','output',12,NULL,NULL,3),(2052,108,NULL,2,781,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',11,0,1,2),(2053,108,NULL,2,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Output Array','Operation','output',12,NULL,NULL,3),(2054,109,NULL,1,200,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',15,0,0,6),(2055,109,NULL,568,1006,'2020-03-24 19:14:18','2020-03-24 19:15:54','Frag_out','Operation','output',129,NULL,NULL,478),(2056,109,NULL,2,200,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',15,1,0,6),(2057,110,NULL,1,200,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',13,0,0,4),(2058,110,NULL,1,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Output Array','Operation','output',14,NULL,NULL,5),(2059,110,NULL,568,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Frag_Example','Operation','input',128,NULL,NULL,477),(2060,110,NULL,2,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Output Array','Operation','output',14,NULL,NULL,5),(2061,110,NULL,2,200,'2020-03-24 19:14:18','2020-03-24 19:14:38','Input Array','Operation','input',13,1,0,4),(2062,111,NULL,568,1006,'2020-03-24 19:14:18','2020-03-24 19:16:05','Input','Operation','input',124,NULL,NULL,476),(2063,111,NULL,568,1006,'2020-03-24 19:14:18','2020-03-24 19:16:05','Output','Operation','output',125,NULL,NULL,NULL),(2064,111,NULL,NULL,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','New output','Operation','output',126,NULL,NULL,NULL),(2065,111,'1',NULL,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Channel','Operation','input',127,NULL,NULL,NULL),(2066,112,'1',NULL,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Channel','Operation','input',121,NULL,NULL,NULL),(2067,112,'First',NULL,NULL,'2020-03-24 19:14:18','2020-03-24 19:15:26','Selection Method','Operation','input',122,NULL,NULL,NULL),(2068,112,NULL,568,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18','Output','Operation','output',123,NULL,NULL,475),(2069,113,NULL,1,NULL,'2020-03-24 19:58:28','2020-03-24 19:58:28','Input Array','Operation','input',10,0,0,1),(2070,113,NULL,2,NULL,'2020-03-24 19:58:28','2020-03-24 19:58:28','Input Array','Operation','input',10,0,1,1),(2071,114,NULL,1,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Input Array','Operation','input',11,0,0,2),(2072,114,NULL,1,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Output Array','Operation','output',12,NULL,NULL,3),(2073,114,NULL,2,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Input Array','Operation','input',11,0,1,2),(2074,114,NULL,2,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Output Array','Operation','output',12,NULL,NULL,3),(2075,115,NULL,1,200,'2020-03-24 19:58:29','2020-03-24 19:58:33','Input Array','Operation','input',15,0,0,6),(2076,115,NULL,568,1010,'2020-03-24 19:58:29','2020-03-24 19:59:18','Frag_out','Operation','output',129,NULL,NULL,478),(2077,115,NULL,2,200,'2020-03-24 19:58:29','2020-03-24 19:58:33','Input Array','Operation','input',15,1,0,6),(2078,116,NULL,1,200,'2020-03-24 19:58:29','2020-03-24 19:58:33','Input Array','Operation','input',13,0,0,4),(2079,116,NULL,1,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Output Array','Operation','output',14,NULL,NULL,5),(2080,116,NULL,568,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Frag_Example','Operation','input',128,NULL,NULL,477),(2081,116,NULL,2,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Output Array','Operation','output',14,NULL,NULL,5),(2082,116,NULL,2,200,'2020-03-24 19:58:29','2020-03-24 19:58:33','Input Array','Operation','input',13,1,0,4),(2083,117,NULL,568,1010,'2020-03-24 19:58:29','2020-03-24 19:59:28','Input','Operation','input',124,NULL,NULL,476),(2084,117,NULL,568,1010,'2020-03-24 19:58:29','2020-03-24 19:59:28','Output','Operation','output',125,NULL,NULL,NULL),(2085,117,NULL,NULL,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','New output','Operation','output',126,NULL,NULL,NULL),(2086,117,'1',NULL,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Channel','Operation','input',127,NULL,NULL,NULL),(2087,118,'1',NULL,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Channel','Operation','input',121,NULL,NULL,NULL),(2088,118,'First',NULL,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Selection Method','Operation','input',122,NULL,NULL,NULL),(2089,118,NULL,568,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29','Output','Operation','output',123,NULL,NULL,475),(2090,119,NULL,1,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Input Array','Operation','input',10,0,0,1),(2091,119,NULL,2,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Input Array','Operation','input',10,0,1,1),(2092,120,NULL,1,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Input Array','Operation','input',11,0,0,2),(2093,120,NULL,1,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Output Array','Operation','output',12,NULL,NULL,3),(2094,120,NULL,2,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Input Array','Operation','input',11,0,1,2),(2095,120,NULL,2,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Output Array','Operation','output',12,NULL,NULL,3),(2096,121,NULL,1,200,'2020-03-24 20:01:50','2020-03-24 20:02:31','Input Array','Operation','input',15,0,0,6),(2097,121,NULL,568,1014,'2020-03-24 20:01:50','2020-03-24 20:02:46','Frag_out','Operation','output',129,NULL,NULL,478),(2098,121,NULL,2,200,'2020-03-24 20:01:50','2020-03-24 20:02:31','Input Array','Operation','input',15,1,0,6),(2099,122,NULL,1,200,'2020-03-24 20:01:50','2020-03-24 20:02:31','Input Array','Operation','input',13,0,0,4),(2100,122,NULL,1,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Output Array','Operation','output',14,NULL,NULL,5),(2101,122,NULL,568,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Frag_Example','Operation','input',128,NULL,NULL,477),(2102,122,NULL,2,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Output Array','Operation','output',14,NULL,NULL,5),(2103,122,NULL,2,200,'2020-03-24 20:01:50','2020-03-24 20:02:31','Input Array','Operation','input',13,1,0,4),(2104,123,NULL,568,1014,'2020-03-24 20:01:50','2020-03-24 20:03:15','Input','Operation','input',124,NULL,NULL,476),(2105,123,NULL,568,1014,'2020-03-24 20:01:50','2020-03-24 20:03:15','Output','Operation','output',125,NULL,NULL,NULL),(2106,123,NULL,NULL,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','New output','Operation','output',126,NULL,NULL,NULL),(2107,123,'1',NULL,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Channel','Operation','input',127,NULL,NULL,NULL),(2108,124,'1',NULL,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Channel','Operation','input',121,NULL,NULL,NULL),(2109,124,'First',NULL,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Selection Method','Operation','input',122,NULL,NULL,NULL),(2110,124,NULL,568,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50','Output','Operation','output',123,NULL,NULL,475);
/*!40000 ALTER TABLE `field_values` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `groups`
--

DROP TABLE IF EXISTS `groups`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `groups` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `description` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=237 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `groups`
--

LOCK TABLES `groups` WRITE;
/*!40000 ALTER TABLE `groups` DISABLE KEYS */;
INSERT INTO `groups` VALUES (1,'admin','These users can use administrative functions (make users, etc)','2013-11-15 21:37:36','2013-11-15 21:37:36'),(235,'technicians','People who run jobs','2017-10-02 17:50:56','2017-10-02 17:50:56'),(236,'neptune','','2018-07-25 16:22:30','2018-07-25 16:22:30');
/*!40000 ALTER TABLE `groups` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `invoices`
--

DROP TABLE IF EXISTS `invoices`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `invoices` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `year` int(11) DEFAULT NULL,
  `month` int(11) DEFAULT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `status` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `notes` text COLLATE utf8_unicode_ci,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `invoices`
--

LOCK TABLES `invoices` WRITE;
/*!40000 ALTER TABLE `invoices` DISABLE KEYS */;
/*!40000 ALTER TABLE `invoices` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `items`
--

DROP TABLE IF EXISTS `items`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `items` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `location` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `quantity` int(11) DEFAULT NULL,
  `object_type_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `inuse` int(11) DEFAULT '0',
  `sample_id` int(11) DEFAULT NULL,
  `data` mediumtext COLLATE utf8_unicode_ci,
  `locator_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_items_on_object_type_id` (`object_type_id`)
) ENGINE=InnoDB AUTO_INCREMENT=1017 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `items`
--

LOCK TABLES `items` WRITE;
/*!40000 ALTER TABLE `items` DISABLE KEYS */;
INSERT INTO `items` VALUES (1,'Bench',1,5,'2020-03-19 18:38:04','2020-03-19 18:38:04',0,NULL,NULL,NULL),(2,'Bench',1,5,'2020-03-19 18:39:23','2020-03-19 18:39:23',0,NULL,NULL,NULL),(3,'Bench',1,5,'2020-03-19 18:39:55','2020-03-19 18:39:55',0,NULL,NULL,NULL),(4,NULL,1,1,'2020-03-19 18:40:13','2020-03-19 18:40:13',0,245,NULL,NULL),(5,NULL,1,1,'2020-03-19 18:40:23','2020-03-19 18:40:23',0,248,NULL,NULL),(6,NULL,1,1,'2020-03-19 18:40:35','2020-03-19 18:40:35',0,249,NULL,NULL),(7,NULL,1,1,'2020-03-19 18:40:43','2020-03-19 18:40:43',0,250,NULL,NULL),(8,NULL,1,1,'2020-03-19 18:40:52','2020-03-19 18:40:52',0,251,NULL,NULL),(9,NULL,1,1,'2020-03-19 18:40:58','2020-03-19 18:40:58',0,252,NULL,NULL),(10,NULL,1,1,'2020-03-19 18:41:05','2020-03-19 18:41:05',0,246,NULL,NULL),(11,NULL,1,1,'2020-03-19 18:41:17','2020-03-19 18:41:17',0,247,NULL,NULL),(12,NULL,1,1,'2020-03-19 18:41:23','2020-03-19 18:41:23',0,247,NULL,NULL),(13,NULL,1,1,'2020-03-19 18:41:33','2020-03-19 18:41:33',0,253,NULL,NULL),(14,NULL,1,1,'2020-03-19 18:41:41','2020-03-19 18:41:41',0,254,NULL,NULL),(15,NULL,1,1,'2020-03-19 18:41:46','2020-03-19 18:41:46',0,255,NULL,NULL),(16,NULL,1,1,'2020-03-19 18:41:53','2020-03-19 18:41:53',0,256,NULL,NULL),(17,NULL,1,1,'2020-03-19 18:42:05','2020-03-19 18:42:05',0,257,NULL,NULL),(18,NULL,1,1,'2020-03-19 18:42:11','2020-03-19 18:42:11',0,258,NULL,NULL),(19,NULL,1,1,'2020-03-19 18:42:16','2020-03-19 18:42:16',0,259,NULL,NULL),(20,NULL,1,1,'2020-03-19 18:42:22','2020-03-19 18:42:22',0,260,NULL,NULL),(21,NULL,1,1,'2020-03-19 18:42:40','2020-03-19 18:42:40',0,261,NULL,NULL),(22,NULL,1,1,'2020-03-19 18:42:48','2020-03-19 18:42:48',0,262,NULL,NULL),(23,NULL,1,1,'2020-03-19 18:42:57','2020-03-19 18:42:57',0,263,NULL,NULL),(24,NULL,1,1,'2020-03-19 18:43:03','2020-03-19 18:43:03',0,264,NULL,NULL),(25,NULL,1,1,'2020-03-19 18:43:10','2020-03-19 18:43:10',0,265,NULL,NULL),(26,NULL,1,1,'2020-03-19 18:43:20','2020-03-19 18:43:20',0,266,NULL,NULL),(27,NULL,1,1,'2020-03-19 18:43:29','2020-03-19 18:43:29',0,267,NULL,NULL),(28,NULL,1,1,'2020-03-19 18:43:37','2020-03-19 18:43:37',0,268,NULL,NULL),(29,NULL,1,1,'2020-03-19 18:43:44','2020-03-19 18:43:44',0,269,NULL,NULL),(30,NULL,1,1,'2020-03-19 18:43:57','2020-03-19 18:43:57',0,270,NULL,NULL),(31,NULL,1,1,'2020-03-19 18:45:26','2020-03-19 18:45:26',0,271,NULL,NULL),(32,NULL,1,1,'2020-03-19 18:45:35','2020-03-19 18:45:48',0,272,NULL,NULL),(33,NULL,1,1,'2020-03-19 18:45:57','2020-03-19 18:45:57',0,273,NULL,NULL),(34,NULL,1,1,'2020-03-19 18:46:06','2020-03-19 18:46:06',0,274,NULL,NULL),(35,NULL,1,1,'2020-03-19 18:46:14','2020-03-19 18:46:14',0,275,NULL,NULL),(36,NULL,1,1,'2020-03-19 18:46:22','2020-03-19 18:46:22',0,276,NULL,NULL),(37,NULL,1,1,'2020-03-19 18:46:30','2020-03-19 18:46:30',0,277,NULL,NULL),(38,NULL,1,1,'2020-03-19 18:46:38','2020-03-19 18:46:38',0,278,NULL,NULL),(39,NULL,1,1,'2020-03-19 18:46:48','2020-03-19 18:46:48',0,279,NULL,NULL),(40,NULL,1,1,'2020-03-19 18:46:53','2020-03-19 18:46:53',0,280,NULL,NULL),(41,NULL,1,1,'2020-03-19 18:47:03','2020-03-19 18:47:03',0,281,NULL,NULL),(42,NULL,1,1,'2020-03-19 18:47:12','2020-03-19 18:47:12',0,282,NULL,NULL),(43,NULL,1,1,'2020-03-19 18:47:21','2020-03-19 18:47:21',0,283,NULL,NULL),(44,NULL,1,1,'2020-03-19 18:47:28','2020-03-19 18:47:39',0,285,NULL,NULL),(45,NULL,1,1,'2020-03-19 18:47:48','2020-03-19 18:47:48',0,286,NULL,NULL),(46,NULL,1,1,'2020-03-19 18:48:02','2020-03-19 18:48:02',0,287,NULL,NULL),(47,NULL,1,1,'2020-03-19 18:48:10','2020-03-19 18:48:10',0,288,NULL,NULL),(48,NULL,1,1,'2020-03-19 18:48:19','2020-03-19 18:48:19',0,289,NULL,NULL),(49,NULL,1,1,'2020-03-19 18:48:26','2020-03-19 18:48:26',0,290,NULL,NULL),(50,NULL,1,1,'2020-03-19 18:48:33','2020-03-19 18:49:15',0,291,NULL,NULL),(51,NULL,1,1,'2020-03-19 18:48:44','2020-03-19 18:49:27',0,292,NULL,NULL),(52,NULL,1,1,'2020-03-19 18:49:36','2020-03-19 18:49:36',0,293,NULL,NULL),(53,NULL,1,1,'2020-03-19 18:49:45','2020-03-19 18:49:45',0,294,NULL,NULL),(54,NULL,1,1,'2020-03-19 18:49:51','2020-03-19 18:49:51',0,295,NULL,NULL),(55,NULL,1,1,'2020-03-19 18:49:57','2020-03-19 18:49:57',0,296,NULL,NULL),(56,NULL,1,1,'2020-03-19 18:51:12','2020-03-19 18:51:12',0,297,NULL,NULL),(57,NULL,1,1,'2020-03-19 18:51:24','2020-03-19 18:53:24',0,298,NULL,NULL),(58,NULL,1,1,'2020-03-19 18:53:34','2020-03-19 18:53:34',0,299,NULL,NULL),(59,NULL,1,1,'2020-03-19 18:53:41','2020-03-19 18:53:41',0,300,NULL,NULL),(60,NULL,1,1,'2020-03-19 18:54:44','2020-03-19 18:54:44',0,301,NULL,NULL),(61,NULL,1,1,'2020-03-19 18:54:49','2020-03-19 18:54:49',0,302,NULL,NULL),(62,NULL,1,1,'2020-03-19 18:54:57','2020-03-19 18:54:57',0,303,NULL,NULL),(63,NULL,1,1,'2020-03-19 18:55:04','2020-03-19 18:55:04',0,304,NULL,NULL),(64,NULL,1,1,'2020-03-19 18:55:11','2020-03-19 18:55:11',0,305,NULL,NULL),(65,NULL,1,1,'2020-03-19 18:55:18','2020-03-19 18:55:18',0,306,NULL,NULL),(66,NULL,1,1,'2020-03-19 18:55:23','2020-03-19 18:55:23',0,307,NULL,NULL),(67,NULL,1,1,'2020-03-19 18:55:33','2020-03-19 18:55:33',0,308,NULL,NULL),(68,NULL,1,1,'2020-03-19 18:55:40','2020-03-19 18:55:40',0,309,NULL,NULL),(69,NULL,1,1,'2020-03-19 18:55:49','2020-03-19 18:55:49',0,310,NULL,NULL),(70,NULL,1,1,'2020-03-19 18:55:55','2020-03-19 18:55:55',0,311,NULL,NULL),(71,NULL,1,1,'2020-03-19 18:56:03','2020-03-19 18:56:03',0,312,NULL,NULL),(72,NULL,1,1,'2020-03-19 18:56:09','2020-03-19 18:56:09',0,313,NULL,NULL),(73,NULL,1,1,'2020-03-19 18:56:17','2020-03-19 18:56:17',0,314,NULL,NULL),(74,NULL,1,1,'2020-03-19 18:56:25','2020-03-19 18:56:25',0,315,NULL,NULL),(75,NULL,1,1,'2020-03-19 18:56:30','2020-03-19 18:56:30',0,316,NULL,NULL),(76,NULL,1,1,'2020-03-19 18:56:38','2020-03-19 18:56:38',0,317,NULL,NULL),(77,NULL,1,1,'2020-03-19 18:57:27','2020-03-19 18:57:27',0,318,NULL,NULL),(78,NULL,1,1,'2020-03-19 18:57:34','2020-03-19 18:57:34',0,319,NULL,NULL),(79,NULL,1,1,'2020-03-19 18:57:42','2020-03-19 18:57:42',0,320,NULL,NULL),(80,NULL,1,1,'2020-03-19 18:57:51','2020-03-19 18:57:51',0,321,NULL,NULL),(81,NULL,1,1,'2020-03-19 18:57:59','2020-03-19 18:57:59',0,322,NULL,NULL),(82,NULL,1,1,'2020-03-19 18:58:09','2020-03-19 18:58:21',0,323,NULL,NULL),(83,NULL,1,1,'2020-03-19 18:58:33','2020-03-19 18:58:33',0,324,NULL,NULL),(84,NULL,1,1,'2020-03-19 18:58:46','2020-03-19 18:58:46',0,325,NULL,NULL),(85,NULL,1,1,'2020-03-19 18:58:57','2020-03-19 18:58:57',0,326,NULL,NULL),(86,NULL,1,1,'2020-03-19 18:59:09','2020-03-19 18:59:09',0,327,NULL,NULL),(87,NULL,1,1,'2020-03-19 18:59:15','2020-03-19 18:59:15',0,328,NULL,NULL),(88,NULL,1,1,'2020-03-19 18:59:22','2020-03-19 18:59:22',0,329,NULL,NULL),(89,NULL,1,1,'2020-03-19 18:59:29','2020-03-19 18:59:29',0,330,NULL,NULL),(90,NULL,1,1,'2020-03-19 18:59:36','2020-03-19 18:59:36',0,331,NULL,NULL),(91,NULL,1,1,'2020-03-19 18:59:43','2020-03-19 18:59:43',0,332,NULL,NULL),(92,NULL,1,1,'2020-03-19 18:59:49','2020-03-19 18:59:49',0,333,NULL,NULL),(93,NULL,1,1,'2020-03-19 18:59:58','2020-03-19 18:59:58',0,334,NULL,NULL),(94,NULL,1,1,'2020-03-19 19:00:04','2020-03-19 19:00:04',0,335,NULL,NULL),(95,NULL,1,1,'2020-03-19 19:00:11','2020-03-19 19:00:11',0,336,NULL,NULL),(96,NULL,1,1,'2020-03-19 19:00:17','2020-03-19 19:00:17',0,337,NULL,NULL),(97,NULL,1,1,'2020-03-19 19:05:08','2020-03-19 19:05:08',0,470,NULL,NULL),(98,NULL,1,1,'2020-03-19 19:05:16','2020-03-19 19:05:16',0,474,NULL,NULL),(99,NULL,1,1,'2020-03-19 19:05:23','2020-03-19 19:05:23',0,475,NULL,NULL),(100,'Bench',1,5,'2020-03-19 19:05:36','2020-03-19 19:05:36',0,NULL,NULL,NULL),(101,NULL,1,1,'2020-03-19 19:05:49','2020-03-19 19:05:49',0,471,NULL,NULL),(102,NULL,1,1,'2020-03-19 19:06:51','2020-03-19 19:06:51',0,472,NULL,NULL),(103,NULL,1,1,'2020-03-19 19:07:00','2020-03-19 19:07:00',0,473,NULL,NULL),(104,NULL,1,1,'2020-03-19 19:07:10','2020-03-19 19:07:10',0,476,NULL,NULL),(105,NULL,1,1,'2020-03-19 19:07:18','2020-03-19 19:07:18',0,477,NULL,NULL),(106,NULL,1,1,'2020-03-19 19:07:24','2020-03-19 19:07:24',0,478,NULL,NULL),(107,NULL,1,1,'2020-03-19 19:07:30','2020-03-19 19:07:30',0,479,NULL,NULL),(108,NULL,1,1,'2020-03-19 19:07:37','2020-03-19 19:07:37',0,480,NULL,NULL),(109,NULL,1,1,'2020-03-19 19:07:49','2020-03-19 19:07:49',0,481,NULL,NULL),(110,NULL,1,1,'2020-03-19 19:07:59','2020-03-19 19:07:59',0,482,NULL,NULL),(111,NULL,1,1,'2020-03-19 19:08:08','2020-03-19 19:08:08',0,483,NULL,NULL),(112,NULL,1,1,'2020-03-19 19:08:15','2020-03-19 19:08:15',0,484,NULL,NULL),(113,NULL,1,1,'2020-03-19 19:08:21','2020-03-19 19:08:21',0,485,NULL,NULL),(114,NULL,1,1,'2020-03-19 19:08:27','2020-03-19 19:08:27',0,486,NULL,NULL),(115,NULL,1,1,'2020-03-19 19:08:33','2020-03-19 19:08:33',0,487,NULL,NULL),(116,NULL,1,1,'2020-03-19 19:08:41','2020-03-19 19:08:41',0,488,NULL,NULL),(117,NULL,1,1,'2020-03-19 19:08:49','2020-03-19 19:08:49',0,489,NULL,NULL),(118,NULL,1,1,'2020-03-19 19:08:55','2020-03-19 19:08:55',0,490,NULL,NULL),(119,NULL,1,1,'2020-03-19 19:09:01','2020-03-19 19:09:01',0,491,NULL,NULL),(120,NULL,1,1,'2020-03-19 19:09:08','2020-03-19 19:09:08',0,492,NULL,NULL),(121,NULL,1,1,'2020-03-19 19:09:17','2020-03-19 19:09:17',0,493,NULL,NULL),(122,NULL,1,1,'2020-03-19 19:09:23','2020-03-19 19:09:23',0,495,NULL,NULL),(123,NULL,1,1,'2020-03-19 19:09:31','2020-03-19 19:09:31',0,496,NULL,NULL),(124,NULL,1,1,'2020-03-19 19:09:37','2020-03-19 19:09:37',0,497,NULL,NULL),(125,NULL,1,1,'2020-03-19 19:09:47','2020-03-19 19:09:47',0,498,NULL,NULL),(126,NULL,1,1,'2020-03-19 19:09:54','2020-03-19 19:09:54',0,499,NULL,NULL),(127,NULL,1,1,'2020-03-19 19:10:02','2020-03-19 19:10:02',0,500,NULL,NULL),(128,NULL,1,1,'2020-03-19 19:10:09','2020-03-19 19:10:09',0,501,NULL,NULL),(129,NULL,1,1,'2020-03-19 19:10:15','2020-03-19 19:10:15',0,502,NULL,NULL),(130,NULL,1,1,'2020-03-19 19:10:22','2020-03-19 19:10:22',0,503,NULL,NULL),(131,NULL,1,1,'2020-03-19 19:10:28','2020-03-19 19:10:28',0,504,NULL,NULL),(132,NULL,1,1,'2020-03-19 19:10:34','2020-03-19 19:10:34',0,505,NULL,NULL),(133,NULL,1,1,'2020-03-19 19:10:40','2020-03-19 19:10:40',0,506,NULL,NULL),(134,NULL,1,1,'2020-03-19 19:10:57','2020-03-19 19:10:57',0,507,NULL,NULL),(135,NULL,1,1,'2020-03-19 19:11:03','2020-03-19 19:11:03',0,508,NULL,NULL),(136,NULL,1,1,'2020-03-19 19:11:12','2020-03-19 19:11:12',0,509,NULL,NULL),(137,NULL,1,1,'2020-03-19 19:11:18','2020-03-19 19:11:18',0,510,NULL,NULL),(138,NULL,1,1,'2020-03-19 19:11:26','2020-03-19 19:11:26',0,511,NULL,NULL),(139,NULL,1,1,'2020-03-19 19:11:32','2020-03-19 19:11:32',0,512,NULL,NULL),(140,NULL,1,1,'2020-03-19 19:11:37','2020-03-19 19:11:37',0,513,NULL,NULL),(141,NULL,1,1,'2020-03-19 19:11:44','2020-03-19 19:11:44',0,514,NULL,NULL),(142,NULL,1,1,'2020-03-19 19:11:51','2020-03-19 19:11:51',0,515,NULL,NULL),(143,NULL,1,1,'2020-03-19 19:11:57','2020-03-19 19:11:57',0,516,NULL,NULL),(144,NULL,1,1,'2020-03-19 19:12:03','2020-03-19 19:12:03',0,517,NULL,NULL),(145,NULL,1,1,'2020-03-19 19:12:09','2020-03-19 19:12:09',0,518,NULL,NULL),(146,NULL,1,1,'2020-03-19 19:12:16','2020-03-19 19:12:16',0,519,NULL,NULL),(147,NULL,1,1,'2020-03-19 19:12:22','2020-03-19 19:12:22',0,520,NULL,NULL),(148,NULL,1,1,'2020-03-19 19:12:29','2020-03-19 19:12:29',0,521,NULL,NULL),(149,NULL,1,1,'2020-03-19 19:12:35','2020-03-19 19:12:35',0,522,NULL,NULL),(150,NULL,1,1,'2020-03-19 19:12:41','2020-03-19 19:12:41',0,523,NULL,NULL),(151,NULL,1,1,'2020-03-19 19:12:48','2020-03-19 19:12:48',0,524,NULL,NULL),(152,NULL,1,1,'2020-03-19 19:12:54','2020-03-19 19:12:54',0,525,NULL,NULL),(153,NULL,1,1,'2020-03-19 19:13:01','2020-03-19 19:13:01',0,526,NULL,NULL),(154,NULL,1,1,'2020-03-19 19:13:08','2020-03-19 19:13:08',0,527,NULL,NULL),(155,NULL,1,1,'2020-03-19 19:13:13','2020-03-19 19:13:13',0,528,NULL,NULL),(156,NULL,1,1,'2020-03-19 19:13:22','2020-03-19 19:13:22',0,529,NULL,NULL),(157,NULL,1,1,'2020-03-19 19:13:27','2020-03-19 19:13:27',0,530,NULL,NULL),(158,NULL,1,1,'2020-03-19 19:13:34','2020-03-19 19:13:34',0,531,NULL,NULL),(159,NULL,1,1,'2020-03-19 19:13:39','2020-03-19 19:13:39',0,532,NULL,NULL),(160,NULL,1,1,'2020-03-19 19:13:46','2020-03-19 19:13:56',0,533,NULL,NULL),(161,NULL,1,1,'2020-03-19 19:14:06','2020-03-19 19:14:06',0,534,NULL,NULL),(162,NULL,1,1,'2020-03-19 19:14:13','2020-03-19 19:14:13',0,535,NULL,NULL),(163,NULL,1,1,'2020-03-19 19:14:22','2020-03-19 19:14:22',0,536,NULL,NULL),(164,NULL,1,1,'2020-03-19 19:14:29','2020-03-19 19:14:29',0,537,NULL,NULL),(165,NULL,1,1,'2020-03-19 19:14:35','2020-03-19 19:14:35',0,538,NULL,NULL),(166,NULL,1,1,'2020-03-19 19:14:41','2020-03-19 19:14:41',0,539,NULL,NULL),(167,NULL,1,1,'2020-03-19 19:14:49','2020-03-19 19:14:49',0,540,NULL,NULL),(168,NULL,1,1,'2020-03-19 19:14:56','2020-03-19 19:14:56',0,541,NULL,NULL),(169,NULL,1,1,'2020-03-19 19:15:02','2020-03-19 19:15:02',0,542,NULL,NULL),(170,NULL,1,1,'2020-03-19 19:15:08','2020-03-19 19:15:08',0,543,NULL,NULL),(171,NULL,1,1,'2020-03-19 19:15:15','2020-03-19 19:15:15',0,544,NULL,NULL),(172,NULL,1,1,'2020-03-19 19:15:21','2020-03-19 19:15:21',0,545,NULL,NULL),(173,NULL,1,1,'2020-03-19 19:15:28','2020-03-19 19:15:28',0,546,NULL,NULL),(174,NULL,1,1,'2020-03-19 19:15:34','2020-03-19 19:15:34',0,547,NULL,NULL),(175,NULL,1,1,'2020-03-19 19:15:40','2020-03-19 19:15:40',0,548,NULL,NULL),(176,NULL,1,1,'2020-03-19 19:15:47','2020-03-19 19:15:47',0,549,NULL,NULL),(177,NULL,1,1,'2020-03-19 19:15:56','2020-03-19 19:15:56',0,550,NULL,NULL),(178,NULL,1,1,'2020-03-19 19:16:08','2020-03-19 19:16:08',0,551,NULL,NULL),(179,NULL,1,1,'2020-03-19 19:16:15','2020-03-19 19:16:15',0,552,NULL,NULL),(180,NULL,1,1,'2020-03-19 19:16:22','2020-03-19 19:16:22',0,553,NULL,NULL),(181,NULL,1,1,'2020-03-19 19:16:31','2020-03-19 19:16:31',0,554,NULL,NULL),(182,NULL,1,1,'2020-03-19 19:16:40','2020-03-19 19:16:40',0,555,NULL,NULL),(183,NULL,1,1,'2020-03-19 19:16:47','2020-03-19 19:16:47',0,556,NULL,NULL),(184,NULL,1,1,'2020-03-19 19:16:53','2020-03-19 19:16:53',0,557,NULL,NULL),(185,NULL,1,1,'2020-03-19 19:16:59','2020-03-19 19:16:59',0,558,NULL,NULL),(186,NULL,1,1,'2020-03-19 19:17:47','2020-03-19 19:17:47',0,559,NULL,NULL),(187,NULL,1,1,'2020-03-19 19:17:56','2020-03-19 19:17:56',0,560,NULL,NULL),(188,NULL,1,1,'2020-03-19 19:18:04','2020-03-19 19:18:04',0,561,NULL,NULL),(189,NULL,1,1,'2020-03-19 19:18:11','2020-03-19 19:18:11',0,562,NULL,NULL),(190,NULL,1,1,'2020-03-19 19:18:18','2020-03-19 19:18:18',0,563,NULL,NULL),(191,NULL,1,1,'2020-03-19 19:18:25','2020-03-19 19:18:25',0,564,NULL,NULL),(192,NULL,1,1,'2020-03-19 19:18:32','2020-03-19 19:18:32',0,565,NULL,NULL),(193,NULL,1,1,'2020-03-19 19:18:39','2020-03-19 19:18:39',0,566,NULL,NULL),(194,NULL,1,1,'2020-03-19 19:18:47','2020-03-19 19:18:47',0,567,NULL,NULL),(195,NULL,1,1,'2020-03-19 19:19:24','2020-03-19 19:19:24',0,494,NULL,NULL),(196,NULL,1,1,'2020-03-19 19:20:22','2020-03-19 19:20:22',0,271,NULL,NULL),(200,'Bench',1,4,'2020-03-19 20:07:10','2020-03-19 20:07:10',0,NULL,NULL,NULL),(201,NULL,1,1,'2020-03-19 20:07:20','2020-03-19 20:07:20',0,1,NULL,NULL),(202,NULL,1,1,'2020-03-19 20:07:27','2020-03-19 20:07:27',0,2,NULL,NULL),(217,NULL,1,1,'2020-03-20 17:11:36','2020-03-20 17:11:36',0,3,NULL,NULL),(218,NULL,1,1,'2020-03-20 18:41:07','2020-03-20 18:41:07',0,4,NULL,NULL),(219,NULL,1,1,'2020-03-20 18:41:13','2020-03-20 18:41:13',0,5,NULL,NULL),(220,NULL,1,1,'2020-03-20 18:41:18','2020-03-20 18:41:18',0,6,NULL,NULL),(221,NULL,1,1,'2020-03-20 18:41:23','2020-03-20 18:41:36',0,7,NULL,NULL),(222,NULL,1,1,'2020-03-20 18:41:49','2020-03-20 18:41:49',0,8,NULL,NULL),(268,'deleted',-1,3,'2020-03-23 20:11:10','2020-03-23 20:11:23',-1,NULL,NULL,NULL),(269,NULL,1,1,'2020-03-23 20:11:12','2020-03-23 20:11:12',0,1,NULL,NULL),(270,NULL,1,1,'2020-03-23 20:11:12','2020-03-23 20:11:12',0,2,NULL,NULL),(271,'Bench',1,3,'2020-03-23 20:13:47','2020-03-23 20:13:47',0,NULL,NULL,NULL),(272,'Bench',1,3,'2020-03-23 20:13:49','2020-03-23 20:13:49',0,NULL,NULL,NULL),(273,'Bench',1,3,'2020-03-23 20:16:49','2020-03-23 20:16:49',0,NULL,NULL,NULL),(274,'Bench',1,3,'2020-03-23 20:16:51','2020-03-23 20:16:51',0,NULL,NULL,NULL),(275,'Bench',1,3,'2020-03-23 20:17:25','2020-03-23 20:17:25',0,NULL,NULL,NULL),(276,'Bench',1,3,'2020-03-23 20:17:26','2020-03-23 20:17:26',0,NULL,NULL,NULL),(277,'Bench',1,3,'2020-03-23 20:20:58','2020-03-23 20:20:58',0,NULL,NULL,NULL),(278,'Bench',1,3,'2020-03-23 20:20:59','2020-03-23 20:20:59',0,NULL,NULL,NULL),(279,'Bench',1,3,'2020-03-23 20:22:17','2020-03-23 20:22:17',0,NULL,NULL,NULL),(280,'Bench',1,3,'2020-03-23 20:22:18','2020-03-23 20:22:18',0,NULL,NULL,NULL),(281,'Bench',1,3,'2020-03-23 21:12:15','2020-03-23 21:12:15',0,NULL,NULL,NULL),(282,'Bench',1,3,'2020-03-23 21:12:16','2020-03-23 21:12:16',0,NULL,NULL,NULL),(283,'Bench',1,3,'2020-03-23 21:19:31','2020-03-23 21:19:31',0,NULL,NULL,NULL),(284,'Bench',1,3,'2020-03-23 21:19:32','2020-03-23 21:19:32',0,NULL,NULL,NULL),(285,'Bench',1,3,'2020-03-23 21:20:05','2020-03-23 21:20:05',0,NULL,NULL,NULL),(286,'Bench',1,3,'2020-03-23 21:20:06','2020-03-23 21:20:06',0,NULL,NULL,NULL),(331,'Bench',1,3,'2020-03-23 21:23:07','2020-03-23 21:23:07',0,NULL,NULL,NULL),(332,'Bench',1,3,'2020-03-23 21:23:08','2020-03-23 21:23:08',0,NULL,NULL,NULL),(333,'Bench',1,3,'2020-03-23 21:24:03','2020-03-23 21:24:03',0,NULL,NULL,NULL),(334,'Bench',1,3,'2020-03-23 21:24:04','2020-03-23 21:24:04',0,NULL,NULL,NULL),(335,'Bench',1,3,'2020-03-23 21:24:39','2020-03-23 21:24:39',0,NULL,NULL,NULL),(336,'Bench',1,3,'2020-03-23 21:24:40','2020-03-23 21:24:40',0,NULL,NULL,NULL),(337,'Bench',1,3,'2020-03-23 21:25:36','2020-03-23 21:25:36',0,NULL,NULL,NULL),(338,'Bench',1,3,'2020-03-23 21:25:37','2020-03-23 21:25:37',0,NULL,NULL,NULL),(339,'Bench',1,3,'2020-03-23 21:27:48','2020-03-23 21:27:48',0,NULL,NULL,NULL),(340,'Bench',1,3,'2020-03-23 21:27:49','2020-03-23 21:27:49',0,NULL,NULL,NULL),(341,'Bench',1,3,'2020-03-23 22:49:23','2020-03-23 22:49:23',0,NULL,NULL,NULL),(342,'Bench',1,3,'2020-03-23 22:49:25','2020-03-23 22:49:25',0,NULL,NULL,NULL),(343,'Bench',1,3,'2020-03-23 23:00:19','2020-03-23 23:00:19',0,NULL,NULL,NULL),(344,'Bench',1,3,'2020-03-23 23:00:21','2020-03-23 23:00:21',0,NULL,NULL,NULL),(345,'Bench',1,3,'2020-03-23 23:02:26','2020-03-23 23:02:26',0,NULL,NULL,NULL),(346,'Bench',1,3,'2020-03-23 23:02:27','2020-03-23 23:02:27',0,NULL,NULL,NULL),(347,'Bench',1,3,'2020-03-23 23:04:13','2020-03-23 23:04:13',0,NULL,NULL,NULL),(348,'Bench',1,3,'2020-03-23 23:04:14','2020-03-23 23:04:14',0,NULL,NULL,NULL),(349,'Bench',1,3,'2020-03-23 23:05:24','2020-03-23 23:05:24',0,NULL,NULL,NULL),(350,'Bench',1,3,'2020-03-23 23:05:25','2020-03-23 23:05:25',0,NULL,NULL,NULL),(351,'Bench',1,3,'2020-03-23 23:07:02','2020-03-23 23:07:02',0,NULL,NULL,NULL),(352,'Bench',1,3,'2020-03-23 23:07:05','2020-03-23 23:07:05',0,NULL,NULL,NULL),(353,'Bench',1,3,'2020-03-23 23:10:15','2020-03-23 23:10:15',0,NULL,NULL,NULL),(354,'Bench',1,3,'2020-03-23 23:10:16','2020-03-23 23:10:16',0,NULL,NULL,NULL),(355,'Bench',1,3,'2020-03-23 23:13:30','2020-03-23 23:13:30',0,NULL,NULL,NULL),(356,'Bench',1,3,'2020-03-23 23:13:31','2020-03-23 23:13:31',0,NULL,NULL,NULL),(357,'Bench',1,3,'2020-03-23 23:15:12','2020-03-23 23:15:12',0,NULL,NULL,NULL),(358,'Bench',1,3,'2020-03-23 23:15:15','2020-03-23 23:15:15',0,NULL,NULL,NULL),(359,'Bench',1,3,'2020-03-23 23:22:11','2020-03-23 23:22:11',0,NULL,NULL,NULL),(360,'Bench',1,3,'2020-03-23 23:22:13','2020-03-23 23:22:13',0,NULL,NULL,NULL),(361,'Bench',1,3,'2020-03-23 23:22:56','2020-03-23 23:22:56',0,NULL,NULL,NULL),(362,'Bench',1,3,'2020-03-23 23:22:58','2020-03-23 23:22:58',0,NULL,NULL,NULL),(363,'deleted',-1,3,'2020-03-23 23:24:16','2020-03-23 23:29:49',-1,NULL,NULL,NULL),(364,'Bench',1,3,'2020-03-23 23:24:56','2020-03-23 23:24:56',0,NULL,NULL,NULL),(365,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,481,NULL,NULL),(366,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,489,NULL,NULL),(367,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,498,NULL,NULL),(368,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,506,NULL,NULL),(369,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,514,NULL,NULL),(370,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,522,NULL,NULL),(371,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,530,NULL,NULL),(372,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,538,NULL,NULL),(373,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,546,NULL,NULL),(374,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,481,NULL,NULL),(375,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,481,NULL,NULL),(376,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,481,NULL,NULL),(377,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,482,NULL,NULL),(378,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,490,NULL,NULL),(379,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,499,NULL,NULL),(380,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,507,NULL,NULL),(381,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,515,NULL,NULL),(382,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,523,NULL,NULL),(383,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,531,NULL,NULL),(384,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,539,NULL,NULL),(385,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,547,NULL,NULL),(386,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,482,NULL,NULL),(387,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,482,NULL,NULL),(388,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,482,NULL,NULL),(389,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,483,NULL,NULL),(390,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,491,NULL,NULL),(391,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,500,NULL,NULL),(392,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,508,NULL,NULL),(393,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,516,NULL,NULL),(394,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,524,NULL,NULL),(395,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,532,NULL,NULL),(396,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,540,NULL,NULL),(397,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,548,NULL,NULL),(398,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,483,NULL,NULL),(399,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15',0,483,NULL,NULL),(400,NULL,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:16',0,483,NULL,NULL),(401,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,247,NULL,NULL),(402,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,260,NULL,NULL),(403,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,268,NULL,NULL),(404,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,276,NULL,NULL),(405,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,285,NULL,NULL),(406,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,293,NULL,NULL),(407,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,301,NULL,NULL),(408,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,309,NULL,NULL),(409,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,317,NULL,NULL),(410,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,247,NULL,NULL),(411,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,247,NULL,NULL),(412,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,247,NULL,NULL),(413,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,253,NULL,NULL),(414,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,261,NULL,NULL),(415,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,269,NULL,NULL),(416,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,277,NULL,NULL),(417,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,286,NULL,NULL),(418,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,294,NULL,NULL),(419,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,302,NULL,NULL),(420,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,310,NULL,NULL),(421,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,318,NULL,NULL),(422,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,253,NULL,NULL),(423,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,253,NULL,NULL),(424,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,253,NULL,NULL),(425,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,254,NULL,NULL),(426,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,262,NULL,NULL),(427,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,270,NULL,NULL),(428,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,278,NULL,NULL),(429,NULL,1,1,'2020-03-23 23:25:59','2020-03-23 23:25:59',0,287,NULL,NULL),(430,NULL,1,1,'2020-03-23 23:26:10','2020-03-23 23:26:10',0,1,NULL,NULL),(431,NULL,1,1,'2020-03-23 23:26:10','2020-03-23 23:26:10',0,2,NULL,NULL),(432,'deleted',-1,3,'2020-03-23 23:29:52','2020-03-23 23:32:36',-1,NULL,NULL,NULL),(433,'Bench',1,3,'2020-03-23 23:29:53','2020-03-23 23:29:53',0,NULL,NULL,NULL),(434,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,471,NULL,NULL),(435,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,481,NULL,NULL),(436,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,489,NULL,NULL),(437,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,498,NULL,NULL),(438,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,506,NULL,NULL),(439,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,514,NULL,NULL),(440,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,522,NULL,NULL),(441,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,530,NULL,NULL),(442,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,538,NULL,NULL),(443,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,471,NULL,NULL),(444,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,471,NULL,NULL),(445,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,471,NULL,NULL),(446,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,472,NULL,NULL),(447,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,482,NULL,NULL),(448,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,490,NULL,NULL),(449,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,499,NULL,NULL),(450,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,507,NULL,NULL),(451,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,515,NULL,NULL),(452,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,523,NULL,NULL),(453,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,531,NULL,NULL),(454,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,539,NULL,NULL),(455,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,472,NULL,NULL),(456,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,472,NULL,NULL),(457,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,472,NULL,NULL),(458,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,473,NULL,NULL),(459,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,483,NULL,NULL),(460,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,491,NULL,NULL),(461,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,500,NULL,NULL),(462,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,508,NULL,NULL),(463,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,516,NULL,NULL),(464,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,524,NULL,NULL),(465,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,532,NULL,NULL),(466,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,540,NULL,NULL),(467,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,473,NULL,NULL),(468,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,473,NULL,NULL),(469,NULL,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03',0,473,NULL,NULL),(470,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,245,NULL,NULL),(471,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,247,NULL,NULL),(472,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,260,NULL,NULL),(473,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,268,NULL,NULL),(474,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,276,NULL,NULL),(475,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,285,NULL,NULL),(476,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,293,NULL,NULL),(477,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,301,NULL,NULL),(478,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,309,NULL,NULL),(479,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,245,NULL,NULL),(480,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,245,NULL,NULL),(481,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,245,NULL,NULL),(482,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,248,NULL,NULL),(483,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,253,NULL,NULL),(484,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,261,NULL,NULL),(485,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,269,NULL,NULL),(486,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,277,NULL,NULL),(487,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,286,NULL,NULL),(488,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,294,NULL,NULL),(489,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,302,NULL,NULL),(490,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,310,NULL,NULL),(491,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,248,NULL,NULL),(492,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,248,NULL,NULL),(493,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,248,NULL,NULL),(494,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,249,NULL,NULL),(495,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,254,NULL,NULL),(496,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,262,NULL,NULL),(497,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,270,NULL,NULL),(498,NULL,1,1,'2020-03-23 23:32:14','2020-03-23 23:32:14',0,278,NULL,NULL),(499,NULL,1,1,'2020-03-23 23:32:19','2020-03-23 23:32:19',0,1,NULL,NULL),(500,NULL,1,1,'2020-03-23 23:32:19','2020-03-23 23:32:19',0,2,NULL,NULL),(501,'Bench',1,3,'2020-03-23 23:32:46','2020-03-23 23:32:46',0,NULL,NULL,NULL),(502,'Bench',1,3,'2020-03-23 23:32:49','2020-03-23 23:32:49',0,NULL,NULL,NULL),(503,NULL,1,1,'2020-03-23 23:32:57','2020-03-23 23:32:57',0,471,NULL,NULL),(504,NULL,1,1,'2020-03-23 23:32:57','2020-03-23 23:32:57',0,481,NULL,NULL),(505,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,489,NULL,NULL),(506,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,498,NULL,NULL),(507,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,506,NULL,NULL),(508,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,514,NULL,NULL),(509,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,522,NULL,NULL),(510,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,530,NULL,NULL),(511,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,538,NULL,NULL),(512,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,471,NULL,NULL),(513,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,471,NULL,NULL),(514,NULL,1,1,'2020-03-23 23:32:58','2020-03-23 23:32:58',0,471,NULL,NULL),(515,'Bench',1,3,'2020-03-23 23:34:38','2020-03-23 23:34:38',0,NULL,NULL,NULL),(516,'Bench',1,3,'2020-03-23 23:34:40','2020-03-23 23:34:40',0,NULL,NULL,NULL),(517,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,471,NULL,NULL),(518,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,481,NULL,NULL),(519,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,489,NULL,NULL),(520,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,498,NULL,NULL),(521,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,506,NULL,NULL),(522,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,514,NULL,NULL),(523,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,522,NULL,NULL),(524,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,530,NULL,NULL),(525,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,538,NULL,NULL),(526,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,471,NULL,NULL),(527,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,471,NULL,NULL),(528,NULL,1,1,'2020-03-23 23:34:57','2020-03-23 23:34:57',0,471,NULL,NULL),(529,'Bench',1,3,'2020-03-23 23:45:32','2020-03-23 23:45:32',0,NULL,NULL,NULL),(530,'Bench',1,3,'2020-03-23 23:45:34','2020-03-23 23:45:34',0,NULL,NULL,NULL),(531,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,471,NULL,NULL),(532,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,481,NULL,NULL),(533,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,489,NULL,NULL),(534,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,498,NULL,NULL),(535,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,506,NULL,NULL),(536,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,514,NULL,NULL),(537,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,522,NULL,NULL),(538,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,530,NULL,NULL),(539,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,538,NULL,NULL),(540,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,471,NULL,NULL),(541,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,471,NULL,NULL),(542,NULL,1,1,'2020-03-23 23:46:04','2020-03-23 23:46:04',0,471,NULL,NULL),(543,'Bench',1,3,'2020-03-23 23:47:05','2020-03-23 23:47:05',0,NULL,NULL,NULL),(544,'Bench',1,3,'2020-03-23 23:47:06','2020-03-23 23:47:06',0,NULL,NULL,NULL),(545,'Bench',1,3,'2020-03-23 23:49:19','2020-03-23 23:49:19',0,NULL,NULL,NULL),(546,'Bench',1,3,'2020-03-23 23:49:21','2020-03-23 23:49:21',0,NULL,NULL,NULL),(547,'deleted',-1,3,'2020-03-23 23:53:20','2020-03-23 23:56:30',-1,NULL,NULL,NULL),(548,'Bench',1,3,'2020-03-23 23:53:24','2020-03-23 23:53:24',0,NULL,NULL,NULL),(549,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,471,NULL,NULL),(550,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,481,NULL,NULL),(551,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,489,NULL,NULL),(552,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,498,NULL,NULL),(553,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,506,NULL,NULL),(554,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,514,NULL,NULL),(555,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,522,NULL,NULL),(556,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,530,NULL,NULL),(557,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,538,NULL,NULL),(558,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,546,NULL,NULL),(559,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,554,NULL,NULL),(560,NULL,1,1,'2020-03-23 23:53:52','2020-03-23 23:53:52',0,562,NULL,NULL),(561,NULL,1,1,'2020-03-23 23:53:58','2020-03-23 23:53:58',0,1,NULL,NULL),(562,NULL,1,1,'2020-03-23 23:53:58','2020-03-23 23:53:58',0,2,NULL,NULL),(563,'Bench',1,3,'2020-03-23 23:56:33','2020-03-23 23:56:33',0,NULL,NULL,NULL),(564,'Bench',1,3,'2020-03-23 23:56:35','2020-03-23 23:56:35',0,NULL,NULL,NULL),(565,'Bench',1,3,'2020-03-23 23:57:18','2020-03-23 23:57:18',0,NULL,NULL,NULL),(566,'Bench',1,3,'2020-03-23 23:57:20','2020-03-23 23:57:20',0,NULL,NULL,NULL),(567,'Bench',1,3,'2020-03-23 23:58:10','2020-03-23 23:58:10',0,NULL,NULL,NULL),(568,'Bench',1,3,'2020-03-23 23:58:13','2020-03-23 23:58:13',0,NULL,NULL,NULL),(569,'Bench',1,3,'2020-03-23 23:58:58','2020-03-23 23:58:58',0,NULL,NULL,NULL),(570,'Bench',1,3,'2020-03-23 23:58:59','2020-03-23 23:58:59',0,NULL,NULL,NULL),(571,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,471,NULL,NULL),(572,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,481,NULL,NULL),(573,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,489,NULL,NULL),(574,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,498,NULL,NULL),(575,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,506,NULL,NULL),(576,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,514,NULL,NULL),(577,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,522,NULL,NULL),(578,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,530,NULL,NULL),(579,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,538,NULL,NULL),(580,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,546,NULL,NULL),(581,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,554,NULL,NULL),(582,NULL,1,1,'2020-03-23 23:59:08','2020-03-23 23:59:08',0,562,NULL,NULL),(583,'Bench',1,3,'2020-03-23 23:59:46','2020-03-23 23:59:46',0,NULL,NULL,NULL),(584,'Bench',1,3,'2020-03-23 23:59:48','2020-03-23 23:59:48',0,NULL,NULL,NULL),(585,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,471,NULL,NULL),(586,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,481,NULL,NULL),(587,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,489,NULL,NULL),(588,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,498,NULL,NULL),(589,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,506,NULL,NULL),(590,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,514,NULL,NULL),(591,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,522,NULL,NULL),(592,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,530,NULL,NULL),(593,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,538,NULL,NULL),(594,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,546,NULL,NULL),(595,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,554,NULL,NULL),(596,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,562,NULL,NULL),(597,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,472,NULL,NULL),(598,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,482,NULL,NULL),(599,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,490,NULL,NULL),(600,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,499,NULL,NULL),(601,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,507,NULL,NULL),(602,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,515,NULL,NULL),(603,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,523,NULL,NULL),(604,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,531,NULL,NULL),(605,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,539,NULL,NULL),(606,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,547,NULL,NULL),(607,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,555,NULL,NULL),(608,NULL,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00',0,563,NULL,NULL),(609,'deleted',-1,3,'2020-03-24 00:01:14','2020-03-24 00:30:20',-1,NULL,NULL,NULL),(610,'Bench',1,3,'2020-03-24 00:01:15','2020-03-24 00:01:15',0,NULL,NULL,NULL),(611,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,471,NULL,NULL),(612,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,481,NULL,NULL),(613,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,489,NULL,NULL),(614,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,498,NULL,NULL),(615,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,506,NULL,NULL),(616,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,514,NULL,NULL),(617,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,522,NULL,NULL),(618,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,530,NULL,NULL),(619,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,538,NULL,NULL),(620,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,546,NULL,NULL),(621,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,554,NULL,NULL),(622,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,562,NULL,NULL),(623,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,472,NULL,NULL),(624,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,482,NULL,NULL),(625,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,490,NULL,NULL),(626,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,499,NULL,NULL),(627,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,507,NULL,NULL),(628,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,515,NULL,NULL),(629,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,523,NULL,NULL),(630,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,531,NULL,NULL),(631,NULL,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23',0,539,NULL,NULL),(632,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,547,NULL,NULL),(633,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,555,NULL,NULL),(634,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,563,NULL,NULL),(635,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,476,NULL,NULL),(636,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,484,NULL,NULL),(637,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,492,NULL,NULL),(638,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,501,NULL,NULL),(639,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,509,NULL,NULL),(640,NULL,1,1,'2020-03-24 00:01:24','2020-03-24 00:01:24',0,517,NULL,NULL),(641,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,249,NULL,NULL),(642,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,254,NULL,NULL),(643,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,262,NULL,NULL),(644,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,270,NULL,NULL),(645,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,278,NULL,NULL),(646,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,287,NULL,NULL),(647,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,295,NULL,NULL),(648,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,303,NULL,NULL),(649,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,311,NULL,NULL),(650,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,319,NULL,NULL),(651,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,327,NULL,NULL),(652,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,335,NULL,NULL),(653,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,247,NULL,NULL),(654,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,259,NULL,NULL),(655,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,267,NULL,NULL),(656,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,275,NULL,NULL),(657,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,283,NULL,NULL),(658,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,292,NULL,NULL),(659,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,300,NULL,NULL),(660,NULL,1,1,'2020-03-24 00:01:39','2020-03-24 00:01:39',0,308,NULL,NULL),(661,NULL,1,1,'2020-03-24 00:01:46','2020-03-24 00:01:46',0,1,NULL,NULL),(662,NULL,1,1,'2020-03-24 00:01:46','2020-03-24 00:01:46',0,2,NULL,NULL),(663,'Bench',1,3,'2020-03-24 00:30:23','2020-03-24 00:30:23',0,NULL,NULL,NULL),(664,'Bench',1,3,'2020-03-24 00:30:25','2020-03-24 00:30:25',0,NULL,NULL,NULL),(665,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,471,NULL,NULL),(666,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,481,NULL,NULL),(667,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,489,NULL,NULL),(668,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,498,NULL,NULL),(669,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,506,NULL,NULL),(670,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,514,NULL,NULL),(671,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,522,NULL,NULL),(672,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,530,NULL,NULL),(673,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,538,NULL,NULL),(674,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,546,NULL,NULL),(675,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,554,NULL,NULL),(676,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,562,NULL,NULL),(677,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,472,NULL,NULL),(678,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,482,NULL,NULL),(679,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,490,NULL,NULL),(680,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,499,NULL,NULL),(681,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,507,NULL,NULL),(682,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,515,NULL,NULL),(683,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,523,NULL,NULL),(684,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,531,NULL,NULL),(685,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,539,NULL,NULL),(686,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,547,NULL,NULL),(687,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,555,NULL,NULL),(688,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,563,NULL,NULL),(689,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,476,NULL,NULL),(690,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,484,NULL,NULL),(691,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,492,NULL,NULL),(692,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,501,NULL,NULL),(693,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,509,NULL,NULL),(694,NULL,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33',0,517,NULL,NULL),(695,'Bench',1,3,'2020-03-24 00:32:05','2020-03-24 00:32:05',0,NULL,NULL,NULL),(696,'Bench',1,3,'2020-03-24 00:32:06','2020-03-24 00:32:06',0,NULL,NULL,NULL),(697,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,471,NULL,NULL),(698,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,481,NULL,NULL),(699,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,489,NULL,NULL),(700,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,498,NULL,NULL),(701,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,506,NULL,NULL),(702,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,514,NULL,NULL),(703,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,522,NULL,NULL),(704,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,530,NULL,NULL),(705,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,538,NULL,NULL),(706,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,546,NULL,NULL),(707,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,554,NULL,NULL),(708,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,562,NULL,NULL),(709,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,472,NULL,NULL),(710,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,482,NULL,NULL),(711,NULL,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15',0,490,NULL,NULL),(712,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,499,NULL,NULL),(713,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,507,NULL,NULL),(714,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,515,NULL,NULL),(715,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,523,NULL,NULL),(716,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,531,NULL,NULL),(717,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,539,NULL,NULL),(718,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,547,NULL,NULL),(719,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,555,NULL,NULL),(720,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,563,NULL,NULL),(721,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,476,NULL,NULL),(722,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,484,NULL,NULL),(723,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,492,NULL,NULL),(724,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,501,NULL,NULL),(725,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,509,NULL,NULL),(726,NULL,1,1,'2020-03-24 00:32:16','2020-03-24 00:32:16',0,517,NULL,NULL),(727,'deleted',-1,3,'2020-03-24 00:32:58','2020-03-24 15:15:09',-1,NULL,NULL,NULL),(728,'Bench',1,3,'2020-03-24 00:32:59','2020-03-24 00:32:59',0,NULL,NULL,NULL),(729,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,471,NULL,NULL),(730,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,481,NULL,NULL),(731,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,489,NULL,NULL),(732,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,498,NULL,NULL),(733,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,506,NULL,NULL),(734,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,514,NULL,NULL),(735,NULL,1,1,'2020-03-24 00:33:11','2020-03-24 00:33:11',0,522,NULL,NULL),(736,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,530,NULL,NULL),(737,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,538,NULL,NULL),(738,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,546,NULL,NULL),(739,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,554,NULL,NULL),(740,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,562,NULL,NULL),(741,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,472,NULL,NULL),(742,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,482,NULL,NULL),(743,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,490,NULL,NULL),(744,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,499,NULL,NULL),(745,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,507,NULL,NULL),(746,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,515,NULL,NULL),(747,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,523,NULL,NULL),(748,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,531,NULL,NULL),(749,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,539,NULL,NULL),(750,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,547,NULL,NULL),(751,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,555,NULL,NULL),(752,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,563,NULL,NULL),(753,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,476,NULL,NULL),(754,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,484,NULL,NULL),(755,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,492,NULL,NULL),(756,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,501,NULL,NULL),(757,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,509,NULL,NULL),(758,NULL,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12',0,517,NULL,NULL),(759,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,249,NULL,NULL),(760,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,254,NULL,NULL),(761,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,262,NULL,NULL),(762,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,270,NULL,NULL),(763,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,278,NULL,NULL),(764,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,287,NULL,NULL),(765,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,295,NULL,NULL),(766,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,303,NULL,NULL),(767,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,311,NULL,NULL),(768,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,319,NULL,NULL),(769,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,327,NULL,NULL),(770,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,335,NULL,NULL),(771,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,247,NULL,NULL),(772,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,259,NULL,NULL),(773,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,267,NULL,NULL),(774,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,275,NULL,NULL),(775,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,283,NULL,NULL),(776,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,292,NULL,NULL),(777,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,300,NULL,NULL),(778,NULL,1,1,'2020-03-24 00:33:16','2020-03-24 00:33:16',0,308,NULL,NULL),(779,NULL,1,1,'2020-03-24 00:33:20','2020-03-24 00:33:20',0,1,NULL,NULL),(780,NULL,1,1,'2020-03-24 00:33:20','2020-03-24 00:33:20',0,2,NULL,NULL),(781,'Freezer',1,3,'2020-03-24 15:15:13','2020-03-24 15:22:25',0,NULL,NULL,NULL),(782,'Bench',1,3,'2020-03-24 15:15:15','2020-03-24 15:15:15',0,NULL,NULL,NULL),(783,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,471,NULL,NULL),(784,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,481,NULL,NULL),(785,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,489,NULL,NULL),(786,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,498,NULL,NULL),(787,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,506,NULL,NULL),(788,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,514,NULL,NULL),(789,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,522,NULL,NULL),(790,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,530,NULL,NULL),(791,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,538,NULL,NULL),(792,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,546,NULL,NULL),(793,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,554,NULL,NULL),(794,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,562,NULL,NULL),(795,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,472,NULL,NULL),(796,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,482,NULL,NULL),(797,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,490,NULL,NULL),(798,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,499,NULL,NULL),(799,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,507,NULL,NULL),(800,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,515,NULL,NULL),(801,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,523,NULL,NULL),(802,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,531,NULL,NULL),(803,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,539,NULL,NULL),(804,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,547,NULL,NULL),(805,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,555,NULL,NULL),(806,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,563,NULL,NULL),(807,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,476,NULL,NULL),(808,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,484,NULL,NULL),(809,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,492,NULL,NULL),(810,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,501,NULL,NULL),(811,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28',0,509,NULL,NULL),(812,NULL,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:29',0,517,NULL,NULL),(813,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,249,NULL,NULL),(814,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,254,NULL,NULL),(815,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,262,NULL,NULL),(816,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,270,NULL,NULL),(817,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,278,NULL,NULL),(818,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,287,NULL,NULL),(819,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,295,NULL,NULL),(820,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,303,NULL,NULL),(821,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,311,NULL,NULL),(822,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,319,NULL,NULL),(823,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,327,NULL,NULL),(824,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,335,NULL,NULL),(825,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,247,NULL,NULL),(826,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,259,NULL,NULL),(827,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,267,NULL,NULL),(828,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,275,NULL,NULL),(829,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,283,NULL,NULL),(830,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,292,NULL,NULL),(831,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,300,NULL,NULL),(832,NULL,1,1,'2020-03-24 15:15:34','2020-03-24 15:15:34',0,308,NULL,NULL),(833,NULL,1,1,'2020-03-24 15:15:39','2020-03-24 15:15:39',0,1,NULL,NULL),(834,NULL,1,1,'2020-03-24 15:15:39','2020-03-24 15:15:39',0,2,NULL,NULL),(835,'deleted',-1,3,'2020-03-24 15:23:58','2020-03-24 15:24:10',-1,NULL,NULL,NULL),(836,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,1,NULL,NULL),(837,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,2,NULL,NULL),(838,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,3,NULL,NULL),(839,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,4,NULL,NULL),(840,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,5,NULL,NULL),(841,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,6,NULL,NULL),(842,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,7,NULL,NULL),(843,NULL,1,1,'2020-03-24 15:24:00','2020-03-24 15:24:00',0,8,NULL,NULL),(844,'Freezer',1,3,'2020-03-24 16:06:11','2020-03-24 16:06:48',0,NULL,NULL,NULL),(845,'Bench',1,3,'2020-03-24 16:06:13','2020-03-24 16:06:13',0,NULL,NULL,NULL),(846,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,471,NULL,NULL),(847,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,481,NULL,NULL),(848,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,489,NULL,NULL),(849,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,498,NULL,NULL),(850,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,506,NULL,NULL),(851,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,514,NULL,NULL),(852,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,522,NULL,NULL),(853,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,530,NULL,NULL),(854,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,538,NULL,NULL),(855,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,546,NULL,NULL),(856,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,554,NULL,NULL),(857,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,562,NULL,NULL),(858,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,472,NULL,NULL),(859,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,482,NULL,NULL),(860,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,490,NULL,NULL),(861,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,499,NULL,NULL),(862,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,507,NULL,NULL),(863,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,515,NULL,NULL),(864,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,523,NULL,NULL),(865,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,531,NULL,NULL),(866,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,539,NULL,NULL),(867,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,547,NULL,NULL),(868,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,555,NULL,NULL),(869,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,563,NULL,NULL),(870,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,476,NULL,NULL),(871,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,484,NULL,NULL),(872,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,492,NULL,NULL),(873,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,501,NULL,NULL),(874,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,509,NULL,NULL),(875,NULL,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27',0,517,NULL,NULL),(876,NULL,1,1,'2020-03-24 16:06:31','2020-03-24 16:06:31',0,249,NULL,NULL),(877,NULL,1,1,'2020-03-24 16:06:31','2020-03-24 16:06:31',0,254,NULL,NULL),(878,NULL,1,1,'2020-03-24 16:06:31','2020-03-24 16:06:31',0,262,NULL,NULL),(879,NULL,1,1,'2020-03-24 16:06:31','2020-03-24 16:06:31',0,270,NULL,NULL),(880,NULL,1,1,'2020-03-24 16:06:31','2020-03-24 16:06:31',0,278,NULL,NULL),(881,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,287,NULL,NULL),(882,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,295,NULL,NULL),(883,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,303,NULL,NULL),(884,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,311,NULL,NULL),(885,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,319,NULL,NULL),(886,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,327,NULL,NULL),(887,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,335,NULL,NULL),(888,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,247,NULL,NULL),(889,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,259,NULL,NULL),(890,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,267,NULL,NULL),(891,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,275,NULL,NULL),(892,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,283,NULL,NULL),(893,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,292,NULL,NULL),(894,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,300,NULL,NULL),(895,NULL,1,1,'2020-03-24 16:06:32','2020-03-24 16:06:32',0,308,NULL,NULL),(896,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,1,NULL,NULL),(897,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,2,NULL,NULL),(898,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,3,NULL,NULL),(899,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,4,NULL,NULL),(900,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,5,NULL,NULL),(901,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,6,NULL,NULL),(902,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,7,NULL,NULL),(903,NULL,1,1,'2020-03-24 16:06:38','2020-03-24 16:06:38',0,8,NULL,NULL),(904,'deleted',-1,3,'2020-03-24 16:17:08','2020-03-24 16:17:16',-1,NULL,NULL,NULL),(905,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:09',0,1,NULL,NULL),(906,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:09',0,2,NULL,NULL),(907,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:09',0,3,NULL,NULL),(908,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:09',0,4,NULL,NULL),(909,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:09',0,5,NULL,NULL),(910,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:09',0,6,NULL,NULL),(911,NULL,1,1,'2020-03-24 16:17:09','2020-03-24 16:17:10',0,7,NULL,NULL),(912,NULL,1,1,'2020-03-24 16:17:10','2020-03-24 16:17:10',0,8,NULL,NULL),(913,'deleted',-1,3,'2020-03-24 16:17:27','2020-03-24 17:58:16',-1,NULL,NULL,NULL),(914,'Bench',1,3,'2020-03-24 16:17:29','2020-03-24 16:17:29',0,NULL,NULL,NULL),(915,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,471,NULL,NULL),(916,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,481,NULL,NULL),(917,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,489,NULL,NULL),(918,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,498,NULL,NULL),(919,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,506,NULL,NULL),(920,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,514,NULL,NULL),(921,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,522,NULL,NULL),(922,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,530,NULL,NULL),(923,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,538,NULL,NULL),(924,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,546,NULL,NULL),(925,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,554,NULL,NULL),(926,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,562,NULL,NULL),(927,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,472,NULL,NULL),(928,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,482,NULL,NULL),(929,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,490,NULL,NULL),(930,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,499,NULL,NULL),(931,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,507,NULL,NULL),(932,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,515,NULL,NULL),(933,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,523,NULL,NULL),(934,NULL,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37',0,531,NULL,NULL),(935,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,539,NULL,NULL),(936,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,547,NULL,NULL),(937,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,555,NULL,NULL),(938,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,563,NULL,NULL),(939,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,476,NULL,NULL),(940,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,484,NULL,NULL),(941,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,492,NULL,NULL),(942,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,501,NULL,NULL),(943,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,509,NULL,NULL),(944,NULL,1,1,'2020-03-24 16:17:38','2020-03-24 16:17:38',0,517,NULL,NULL),(945,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,249,NULL,NULL),(946,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,254,NULL,NULL),(947,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,262,NULL,NULL),(948,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,270,NULL,NULL),(949,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,278,NULL,NULL),(950,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,287,NULL,NULL),(951,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,295,NULL,NULL),(952,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,303,NULL,NULL),(953,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,311,NULL,NULL),(954,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,319,NULL,NULL),(955,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,327,NULL,NULL),(956,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,335,NULL,NULL),(957,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,247,NULL,NULL),(958,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,259,NULL,NULL),(959,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,267,NULL,NULL),(960,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,275,NULL,NULL),(961,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,283,NULL,NULL),(962,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,292,NULL,NULL),(963,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,300,NULL,NULL),(964,NULL,1,1,'2020-03-24 16:17:41','2020-03-24 16:17:41',0,308,NULL,NULL),(965,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,1,NULL,NULL),(966,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,2,NULL,NULL),(967,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,3,NULL,NULL),(968,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,4,NULL,NULL),(969,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,5,NULL,NULL),(970,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,6,NULL,NULL),(971,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,7,NULL,NULL),(972,NULL,1,1,'2020-03-24 16:17:48','2020-03-24 16:17:48',0,8,NULL,NULL),(973,'Bench',1,3,'2020-03-24 17:54:40','2020-03-24 17:54:40',0,NULL,NULL,NULL),(974,'deleted',-1,3,'2020-03-24 17:57:07','2020-03-24 17:57:18',-1,NULL,NULL,NULL),(975,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,1,NULL,NULL),(976,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,2,NULL,NULL),(977,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,3,NULL,NULL),(978,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,4,NULL,NULL),(979,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,5,NULL,NULL),(980,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,6,NULL,NULL),(981,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,7,NULL,NULL),(982,NULL,1,1,'2020-03-24 17:57:10','2020-03-24 17:57:10',0,8,NULL,NULL),(983,'Freezer',1,3,'2020-03-24 17:57:46','2020-03-24 17:58:19',0,NULL,NULL,NULL),(984,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,1,NULL,NULL),(985,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,2,NULL,NULL),(986,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,3,NULL,NULL),(987,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,4,NULL,NULL),(988,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,5,NULL,NULL),(989,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,6,NULL,NULL),(990,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,7,NULL,NULL),(991,NULL,1,1,'2020-03-24 17:58:12','2020-03-24 17:58:12',0,8,NULL,NULL),(992,'Freezer',1,3,'2020-03-24 18:21:26','2020-03-24 18:21:32',0,NULL,NULL,NULL),(993,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,1,NULL,NULL),(994,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,2,NULL,NULL),(995,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,3,NULL,NULL),(996,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,4,NULL,NULL),(997,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,5,NULL,NULL),(998,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,6,NULL,NULL),(999,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,7,NULL,NULL),(1000,NULL,1,1,'2020-03-24 18:21:27','2020-03-24 18:21:27',0,8,NULL,NULL),(1001,'deleted',-1,3,'2020-03-24 19:07:27','2020-03-24 19:07:42',-1,NULL,NULL,NULL),(1002,'Bench',1,6,'2020-03-24 19:07:31','2020-03-24 19:07:31',0,568,NULL,NULL),(1003,NULL,1,1,'2020-03-24 19:07:31','2020-03-24 19:07:31',0,1,NULL,NULL),(1004,NULL,1,1,'2020-03-24 19:07:31','2020-03-24 19:07:31',0,2,NULL,NULL),(1005,'deleted',-1,3,'2020-03-24 19:15:52','2020-03-24 19:16:03',-1,NULL,NULL,NULL),(1006,'Bench',1,6,'2020-03-24 19:15:54','2020-03-24 19:15:54',0,568,NULL,NULL),(1007,NULL,1,1,'2020-03-24 19:15:54','2020-03-24 19:15:54',0,1,NULL,NULL),(1008,NULL,1,1,'2020-03-24 19:15:54','2020-03-24 19:15:54',0,2,NULL,NULL),(1009,'deleted',-1,3,'2020-03-24 19:59:16','2020-03-24 19:59:27',-1,NULL,NULL,NULL),(1010,'Bench',1,6,'2020-03-24 19:59:18','2020-03-24 19:59:18',0,568,NULL,NULL),(1011,NULL,1,1,'2020-03-24 19:59:18','2020-03-24 19:59:18',0,1,NULL,NULL),(1012,NULL,1,1,'2020-03-24 19:59:18','2020-03-24 19:59:18',0,2,NULL,NULL),(1013,'deleted',-1,3,'2020-03-24 20:02:44','2020-03-24 20:02:56',-1,NULL,NULL,NULL),(1014,'Bench',1,6,'2020-03-24 20:02:46','2020-03-24 20:02:46',0,568,NULL,NULL),(1015,NULL,1,1,'2020-03-24 20:02:46','2020-03-24 20:02:46',0,1,NULL,NULL),(1016,NULL,1,1,'2020-03-24 20:02:46','2020-03-24 20:02:46',0,2,NULL,NULL);
/*!40000 ALTER TABLE `items` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `job_associations`
--

DROP TABLE IF EXISTS `job_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `job_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) DEFAULT NULL,
  `operation_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=101 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `job_associations`
--

LOCK TABLES `job_associations` WRITE;
/*!40000 ALTER TABLE `job_associations` DISABLE KEYS */;
INSERT INTO `job_associations` VALUES (4,4,5,'2020-03-19 20:20:52','2020-03-19 20:20:52'),(5,5,5,'2020-03-19 20:34:46','2020-03-19 20:34:46'),(6,6,5,'2020-03-19 20:36:19','2020-03-19 20:36:19'),(41,41,9,'2020-03-23 20:11:08','2020-03-23 20:11:08'),(42,42,6,'2020-03-23 20:12:00','2020-03-23 20:12:00'),(43,43,6,'2020-03-23 20:16:48','2020-03-23 20:16:48'),(44,44,6,'2020-03-23 20:17:23','2020-03-23 20:17:23'),(45,45,6,'2020-03-23 20:20:57','2020-03-23 20:20:57'),(46,46,6,'2020-03-23 20:22:15','2020-03-23 20:22:15'),(47,47,6,'2020-03-23 21:12:13','2020-03-23 21:12:13'),(48,48,6,'2020-03-23 21:19:30','2020-03-23 21:19:30'),(49,49,6,'2020-03-23 21:20:03','2020-03-23 21:20:03'),(53,53,6,'2020-03-23 21:23:06','2020-03-23 21:23:06'),(54,54,6,'2020-03-23 21:24:01','2020-03-23 21:24:01'),(55,55,6,'2020-03-23 21:24:38','2020-03-23 21:24:38'),(56,56,6,'2020-03-23 21:25:34','2020-03-23 21:25:34'),(57,57,6,'2020-03-23 21:27:47','2020-03-23 21:27:47'),(58,58,6,'2020-03-23 22:49:22','2020-03-23 22:49:22'),(59,59,6,'2020-03-23 23:00:17','2020-03-23 23:00:17'),(60,60,6,'2020-03-23 23:02:24','2020-03-23 23:02:24'),(61,61,6,'2020-03-23 23:04:11','2020-03-23 23:04:11'),(62,62,6,'2020-03-23 23:05:22','2020-03-23 23:05:22'),(63,63,6,'2020-03-23 23:07:01','2020-03-23 23:07:01'),(64,64,6,'2020-03-23 23:10:13','2020-03-23 23:10:13'),(65,65,6,'2020-03-23 23:13:28','2020-03-23 23:13:28'),(66,66,6,'2020-03-23 23:15:10','2020-03-23 23:15:10'),(67,67,6,'2020-03-23 23:22:10','2020-03-23 23:22:10'),(68,68,6,'2020-03-23 23:22:55','2020-03-23 23:22:55'),(69,69,6,'2020-03-23 23:24:15','2020-03-23 23:24:15'),(70,70,6,'2020-03-23 23:29:50','2020-03-23 23:29:50'),(71,71,6,'2020-03-23 23:32:38','2020-03-23 23:32:38'),(72,72,6,'2020-03-23 23:34:37','2020-03-23 23:34:37'),(73,73,6,'2020-03-23 23:45:31','2020-03-23 23:45:31'),(74,74,6,'2020-03-23 23:47:03','2020-03-23 23:47:03'),(75,75,6,'2020-03-23 23:49:16','2020-03-23 23:49:16'),(76,76,6,'2020-03-23 23:53:19','2020-03-23 23:53:19'),(77,77,6,'2020-03-23 23:56:31','2020-03-23 23:56:31'),(78,78,6,'2020-03-23 23:57:17','2020-03-23 23:57:17'),(79,79,6,'2020-03-23 23:58:08','2020-03-23 23:58:08'),(80,80,6,'2020-03-23 23:58:56','2020-03-23 23:58:56'),(81,81,6,'2020-03-23 23:59:44','2020-03-23 23:59:44'),(82,82,6,'2020-03-24 00:01:12','2020-03-24 00:01:12'),(83,83,6,'2020-03-24 00:30:22','2020-03-24 00:30:22'),(84,84,6,'2020-03-24 00:31:45','2020-03-24 00:31:45'),(85,85,6,'2020-03-24 00:32:56','2020-03-24 00:32:56'),(86,86,6,'2020-03-24 15:15:11','2020-03-24 15:15:11'),(87,87,42,'2020-03-24 15:23:56','2020-03-24 15:23:56'),(88,88,39,'2020-03-24 16:06:10','2020-03-24 16:06:10'),(89,89,40,'2020-03-24 16:07:14','2020-03-24 16:07:14'),(90,90,41,'2020-03-24 16:16:53','2020-03-24 16:16:53'),(91,91,85,'2020-03-24 16:17:06','2020-03-24 16:17:06'),(92,92,82,'2020-03-24 16:17:25','2020-03-24 16:17:25'),(93,93,83,'2020-03-24 17:54:38','2020-03-24 17:54:38'),(94,94,83,'2020-03-24 17:57:05','2020-03-24 17:57:05'),(95,95,84,'2020-03-24 17:57:44','2020-03-24 17:57:44'),(96,96,84,'2020-03-24 18:21:22','2020-03-24 18:21:22'),(97,97,103,'2020-03-24 19:07:25','2020-03-24 19:07:25'),(98,98,109,'2020-03-24 19:15:50','2020-03-24 19:15:50'),(99,99,115,'2020-03-24 19:59:13','2020-03-24 19:59:13'),(100,100,121,'2020-03-24 20:02:43','2020-03-24 20:02:43');
/*!40000 ALTER TABLE `job_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `jobs`
--

DROP TABLE IF EXISTS `jobs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `jobs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `arguments` text COLLATE utf8_unicode_ci,
  `state` longtext COLLATE utf8_unicode_ci,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `path` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `pc` int(11) DEFAULT NULL,
  `group_id` int(11) DEFAULT NULL,
  `submitted_by` int(11) DEFAULT NULL,
  `desired_start_time` datetime DEFAULT NULL,
  `latest_start_time` datetime DEFAULT NULL,
  `metacol_id` int(11) DEFAULT NULL,
  `successor_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=101 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `jobs`
--

LOCK TABLES `jobs` WRITE;
/*!40000 ALTER TABLE `jobs` DISABLE KEYS */;
INSERT INTO `jobs` VALUES (4,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":6},\"time\":\"2020-03-19T13:20:52.962-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: Plate Collection ID\"},{\"note\":\"Column 2: Well Location (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:21:04.675-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Oligos.csv\",\"id\":1}],\"timestamp\":1584649264.629}},{\"operation\":\"display\",\"content\":[{\"title\":\"For debug purposes only\"},{\"note\":\"uploaded file: [{\\\"id\\\"=>1, \\\"job_id\\\"=>4, \\\"upload_file_name\\\"=>\\\"Oligos.csv\\\", \\\"upload_content_type\\\"=>\\\"text/plain\\\", \\\"upload_file_size\\\"=>3294, \\\"upload_updated_at\\\"=>\\\"2020-03-19T13:21:02.000-07:00\\\", \\\"created_at\\\"=>\\\"2020-03-19T13:21:02.000-07:00\\\", \\\"updated_at\\\"=>\\\"2020-03-19T13:21:02.000-07:00\\\"}]\"}]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:33:36.538-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584650016.493}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1584650016.493}}]','2020-03-19 20:20:52','2020-03-19 20:33:36','operation.rb',-2,235,1,'2020-03-19 20:20:52','2020-03-19 21:20:52',NULL,NULL),(5,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":6},\"time\":\"2020-03-19T13:34:46.038-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: Plate Collection ID\"},{\"note\":\"Column 2: Well Location (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:35:29.493-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Oligos.csv\",\"id\":2}],\"timestamp\":1584650129.459}},{\"operation\":\"display\",\"content\":[{\"title\":\"For debug purposes only\"},{\"note\":\"uploaded file: [{\\\"id\\\"=>2, \\\"job_id\\\"=>5, \\\"upload_file_name\\\"=>\\\"Oligos.csv\\\", \\\"upload_content_type\\\"=>\\\"text/plain\\\", \\\"upload_file_size\\\"=>3294, \\\"upload_updated_at\\\"=>\\\"2020-03-19T13:35:27.000-07:00\\\", \\\"created_at\\\"=>\\\"2020-03-19T13:35:27.000-07:00\\\", \\\"updated_at\\\"=>\\\"2020-03-19T13:35:27.000-07:00\\\"}]\"}]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:35:36.898-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584650136.856}},{\"operation\":\"error\",\"message\":\"undefined method `Title\' for #<Krill::ShowBlock:0x0000559c242d9860>\",\"backtrace\":[\"/aquarium/lib/krill/show_block.rb:305:in `method_missing\'\",\"(eval):62:in `block (2 levels) in parse_csv\'\",\"/aquarium/lib/krill/show_block.rb:294:in `instance_eval\'\",\"/aquarium/lib/krill/show_block.rb:294:in `run\'\",\"/aquarium/lib/krill/base.rb:19:in `show\'\",\"(eval):61:in `block in parse_csv\'\",\"(eval):60:in `each\'\",\"(eval):60:in `parse_csv\'\",\"(eval):34:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:35:36.919-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-19 20:34:46','2020-03-19 20:35:36','operation.rb',-2,235,1,'2020-03-19 20:34:46','2020-03-19 21:34:46',NULL,NULL),(6,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":6},\"time\":\"2020-03-19T13:36:19.639-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: Plate Collection ID\"},{\"note\":\"Column 2: Well Location (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:36:27.148-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Oligos.csv\",\"id\":3}],\"timestamp\":1584650187.116}},{\"operation\":\"display\",\"content\":[{\"title\":\"For debug purposes only\"},{\"note\":\"uploaded file: [{\\\"id\\\"=>3, \\\"job_id\\\"=>6, \\\"upload_file_name\\\"=>\\\"Oligos.csv\\\", \\\"upload_content_type\\\"=>\\\"text/plain\\\", \\\"upload_file_size\\\"=>3294, \\\"upload_updated_at\\\"=>\\\"2020-03-19T13:36:26.000-07:00\\\", \\\"created_at\\\"=>\\\"2020-03-19T13:36:26.000-07:00\\\", \\\"updated_at\\\"=>\\\"2020-03-19T13:36:26.000-07:00\\\"}]\"}]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:36:28.308-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584650188.274}},{\"operation\":\"error\",\"message\":\"private method `open\' called for #<Array:0x0000559c244e3458>\",\"backtrace\":[\"(eval):64:in `block (2 levels) in parse_csv\'\",\"/aquarium/lib/krill/show_block.rb:294:in `instance_eval\'\",\"/aquarium/lib/krill/show_block.rb:294:in `run\'\",\"/aquarium/lib/krill/base.rb:19:in `show\'\",\"(eval):61:in `block in parse_csv\'\",\"(eval):60:in `each\'\",\"(eval):60:in `parse_csv\'\",\"(eval):34:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-19T13:36:28.333-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-19 20:36:19','2020-03-19 20:36:28','operation.rb',-2,235,1,'2020-03-19 20:36:19','2020-03-19 21:36:19',NULL,NULL),(41,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-23T13:11:08.665-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>268</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:11:12.170-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994272.148}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:11:12.882-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994272.859}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:268) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(268)\'>268</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:11:19.034-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994279.005}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:11:20.167-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994280.137}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"69\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"69\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:11:23.575-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994283.541}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[268,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:11:36.177-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994296.154}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1584994296.154}}]','2020-03-23 20:11:08','2020-03-23 20:11:36','operation.rb',-2,235,1,'2020-03-23 20:11:08','2020-03-23 21:11:08',NULL,NULL),(42,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T13:12:00.926-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>271</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:13:49.687-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994429.657}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>272</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:14:13.946-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994453.912}},{\"operation\":\"error\",\"message\":\"uninitialized constant ExecutionNamespace8fdLG3qxuLi3DfV8hFqzEET4OfkRsSzyKIxiIScdrw::Protocol::PLATE_ID\",\"backtrace\":[\"(eval):124:in `block in upload_and_csv\'\",\"/aquarium/lib/krill/show_block.rb:294:in `instance_eval\'\",\"/aquarium/lib/krill/show_block.rb:294:in `run\'\",\"/aquarium/lib/krill/base.rb:19:in `show\'\",\"(eval):120:in `upload_and_csv\'\",\"(eval):80:in `make_adapter_plate\'\",\"(eval):45:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:14:13.969-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 20:12:00','2020-03-23 20:14:13','operation.rb',-2,235,1,'2020-03-23 20:12:00','2020-03-23 21:12:00',NULL,NULL),(43,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T13:16:48.652-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>273</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:16:51.276-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994611.244}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>274</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:16:52.004-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994611.972}},{\"operation\":\"error\",\"message\":\"uninitialized constant ExecutionNamespaceNMdUc0_8e_iKYrUaZCl2nX93TjrzV5r99ko9OYIRy7Q::Protocol::PLATE_ID\",\"backtrace\":[\"(eval):124:in `block in upload_and_csv\'\",\"/aquarium/lib/krill/show_block.rb:294:in `instance_eval\'\",\"/aquarium/lib/krill/show_block.rb:294:in `run\'\",\"/aquarium/lib/krill/base.rb:19:in `show\'\",\"(eval):120:in `upload_and_csv\'\",\"(eval):80:in `make_adapter_plate\'\",\"(eval):45:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:16:52.026-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 20:16:48','2020-03-23 20:16:52','operation.rb',-2,235,1,'2020-03-23 20:16:48','2020-03-23 21:16:48',NULL,NULL),(44,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T13:17:23.733-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>275</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:17:26.916-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994646.874}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>276</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:17:27.598-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994647.555}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:19:57.980-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":4}],\"timestamp\":1584994797.939}},{\"operation\":\"error\",\"message\":\"uninitialized constant ExecutionNamespaceLzCVmxspAwktKpN4pSSFIuvV7E_240VkT55EWnM1CW4::Protocol::CSV\",\"backtrace\":[\"(eval):147:in `sample_from_csv\'\",\"(eval):84:in `make_adapter_plate\'\",\"(eval):48:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:19:58.003-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 20:17:23','2020-03-23 20:19:58','operation.rb',-2,235,1,'2020-03-23 20:17:23','2020-03-23 21:17:23',NULL,NULL),(45,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T13:20:57.505-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>277</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:20:59.886-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994859.877}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>278</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:21:00.526-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994860.518}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:21:06.004-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":5}],\"timestamp\":1584994865.989}},{\"operation\":\"error\",\"message\":\"uninitialized constant ExecutionNamespacedmmpLOy7VtT2WJoMMPP6OI7HsP_vOREMlyjNOmpQ8::Protocol::CSV\",\"backtrace\":[\"(eval):147:in `sample_from_csv\'\",\"(eval):84:in `make_adapter_plate\'\",\"(eval):48:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:21:06.026-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 20:20:57','2020-03-23 20:21:06','operation.rb',-2,235,1,'2020-03-23 20:20:57','2020-03-23 21:20:57',NULL,NULL),(46,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T13:22:15.505-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>279</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:22:18.424-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994938.395}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>280</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:22:19.038-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584994939.009}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:22:24.846-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":6}],\"timestamp\":1584994944.809}},{\"operation\":\"error\",\"message\":\"undefined method `close\' for #<Array:0x00005566e6310cc0>\\nDid you mean?  clone\",\"backtrace\":[\"/usr/local/lib/ruby/2.6.0/forwardable.rb:228:in `close\'\",\"/usr/local/lib/ruby/2.6.0/csv.rb:687:in `ensure in parse\'\",\"/usr/local/lib/ruby/2.6.0/csv.rb:687:in `parse\'\",\"(eval):150:in `sample_from_csv\'\",\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T13:22:24.869-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 20:22:15','2020-03-23 20:22:24','operation.rb',-2,235,1,'2020-03-23 20:22:15','2020-03-23 21:22:15',NULL,NULL),(47,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:12:13.981-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>281</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:12:16.252-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584997936.222}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>282</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:12:16.853-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584997936.823}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:12:23.447-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":7}],\"timestamp\":1584997943.408}},{\"operation\":\"error\",\"message\":\"undefined method `close\' for #<Array:0x00005566e67416c8>\\nDid you mean?  clone\",\"backtrace\":[\"/usr/local/lib/ruby/2.6.0/forwardable.rb:228:in `close\'\",\"/usr/local/lib/ruby/2.6.0/csv.rb:687:in `ensure in parse\'\",\"/usr/local/lib/ruby/2.6.0/csv.rb:687:in `parse\'\",\"(eval):150:in `sample_from_csv\'\",\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:12:23.471-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:12:13','2020-03-23 21:12:23','operation.rb',-2,235,1,'2020-03-23 21:12:13','2020-03-23 22:12:13',NULL,NULL),(48,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:19:30.443-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>283</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:19:32.919-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998372.903}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>284</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:19:33.467-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998373.451}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:19:38.940-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":8}],\"timestamp\":1584998378.918}},{\"operation\":\"error\",\"message\":\"undefined method `inpsect\' for #<ExecutionNamespacesmATLclgk5Fz7a6DqI1y4dtJT0LnBQlmWHh8j1a_K0::Protocol:0x00005566e696ce70>\\nDid you mean?  inspect\",\"backtrace\":[\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:19:38.963-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:19:30','2020-03-23 21:19:38','operation.rb',-2,235,1,'2020-03-23 21:19:30','2020-03-23 22:19:30',NULL,NULL),(49,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:20:03.648-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>285</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:20:06.385-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998406.365}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>286</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:20:06.891-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998406.872}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:20:11.925-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":9}],\"timestamp\":1584998411.9}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"Array\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:22:59.482-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:20:03','2020-03-23 21:22:59','operation.rb',-2,235,1,'2020-03-23 21:20:03','2020-03-23 22:20:03',NULL,NULL),(53,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:23:06.268-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>331</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:23:08.791-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998588.768}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>332</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:23:09.353-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998589.331}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:23:15.539-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":10}],\"timestamp\":1584998595.509}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"Array\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:23:39.068-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998619.047}},{\"operation\":\"error\",\"message\":\"undefined method `close\' for #<Array:0x00005566e5cea6c0>\\nDid you mean?  clone\",\"backtrace\":[\"/usr/local/lib/ruby/2.6.0/forwardable.rb:228:in `close\'\",\"/usr/local/lib/ruby/2.6.0/csv.rb:687:in `ensure in parse\'\",\"/usr/local/lib/ruby/2.6.0/csv.rb:687:in `parse\'\",\"(eval):151:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:23:39.091-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:23:06','2020-03-23 21:23:39','operation.rb',-2,235,1,'2020-03-23 21:23:06','2020-03-23 22:23:06',NULL,NULL),(54,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:24:01.708-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>333</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:04.875-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998644.857}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>334</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:05.476-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998645.458}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:11.318-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":11}],\"timestamp\":1584998651.293}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"Array\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:12.798-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998652.772}},{\"operation\":\"error\",\"message\":\"undefined local variable or method `csv\' for #<ExecutionNamespacenJIUAyGFCF89aN4ngE4Y2rDC68gI3WJKuLcATKm9dg::Protocol:0x00005566e601fca0>\\nDid you mean?  CSV\",\"backtrace\":[\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:12.821-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:24:01','2020-03-23 21:24:12','operation.rb',-2,235,1,'2020-03-23 21:24:01','2020-03-23 22:24:01',NULL,NULL),(55,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:24:38.116-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>335</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:40.960-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998680.936}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>336</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:41.435-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998681.409}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:46.319-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":12}],\"timestamp\":1584998686.289}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"Array\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:47.852-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998687.819}},{\"operation\":\"error\",\"message\":\"Headers incorrect\",\"backtrace\":[\"(eval):156:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `each_with_index\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:24:47.874-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:24:38','2020-03-23 21:24:47','operation.rb',-2,235,1,'2020-03-23 21:24:38','2020-03-23 22:24:38',NULL,NULL),(56,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:25:34.943-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>337</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:25:37.875-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998737.853}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>338</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:25:38.274-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998738.252}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:25:43.623-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":13}],\"timestamp\":1584998743.593}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 13, job_id: 56, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 21:25:43\\\\\\\", created_at: \\\\\\\"2020-03-23 21:25:43\\\\\\\", updated_at: \\\\\\\"2020-03-23 21:25:43\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:26:09.743-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998769.72}},{\"operation\":\"error\",\"message\":\"Headers incorrect\",\"backtrace\":[\"(eval):156:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `each_with_index\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:26:09.763-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:25:34','2020-03-23 21:26:09','operation.rb',-2,235,1,'2020-03-23 21:25:34','2020-03-23 22:25:34',NULL,NULL),(57,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T14:27:47.136-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>339</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:27:49.734-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998869.699}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>340</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:27:50.438-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1584998870.403}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:27:56.622-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":14}],\"timestamp\":1584998876.612}},{\"operation\":\"error\",\"message\":\"undefined method `file\' for #<Array:0x00005566e5933d88>\\nDid you mean?  fill\",\"backtrace\":[\"(eval):138:in `upload_and_csv\'\",\"(eval):86:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T14:27:56.649-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 21:27:47','2020-03-23 21:27:56','operation.rb',-2,235,1,'2020-03-23 21:27:47','2020-03-23 22:27:47',NULL,NULL),(58,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T15:49:22.568-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>341</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T15:49:25.398-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585003765.386}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>342</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T15:49:25.966-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585003765.955}},{\"operation\":\"display\",\"content\":[{\"title\":\"Upload CSV file of Adapters\"},{\"note\":\"Please upload a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T15:49:33.511-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":15}],\"timestamp\":1585003773.495}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 15, job_id: 58, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 22:49:32\\\\\\\", created_at: \\\\\\\"2020-03-23 22:49:32\\\\\\\", updated_at: \\\\\\\"2020-03-23 22:49:32\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T15:49:35.218-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585003775.196}},{\"operation\":\"error\",\"message\":\"undefined method `url\' for #<Array:0x00005566e5de0a98>\",\"backtrace\":[\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T15:49:35.239-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 22:49:22','2020-03-23 22:49:35','operation.rb',-2,235,1,'2020-03-23 22:49:22','2020-03-23 23:49:22',NULL,NULL),(59,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:00:17.796-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>343</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:00:21.095-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004421.056}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>344</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:00:22.194-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004422.153}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:00:27.687-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":16}],\"timestamp\":1585004427.675}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 16, job_id: 59, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:00:26\\\\\\\", created_at: \\\\\\\"2020-03-23 23:00:26\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:00:26\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:00:29.067-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004429.045}},{\"operation\":\"error\",\"message\":\"Headers incorrect\",\"backtrace\":[\"(eval):157:in `block in sample_from_csv\'\",\"(eval):153:in `each\'\",\"(eval):153:in `each_with_index\'\",\"(eval):153:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:00:29.128-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:00:17','2020-03-23 23:00:29','operation.rb',-2,235,1,'2020-03-23 23:00:17','2020-03-24 00:00:17',NULL,NULL),(60,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:02:24.969-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>345</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:02:27.705-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004547.692}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>346</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:02:28.423-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004548.41}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:02:36.170-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":17}],\"timestamp\":1585004556.149}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 17, job_id: 60, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:02:34\\\\\\\", created_at: \\\\\\\"2020-03-23 23:02:34\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:02:34\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:02:37.046-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004557.024}},{\"operation\":\"error\",\"message\":\"Headers incorrect\",\"backtrace\":[\"(eval):157:in `block in sample_from_csv\'\",\"(eval):153:in `each\'\",\"(eval):153:in `each_with_index\'\",\"(eval):153:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:02:37.097-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:02:24','2020-03-23 23:02:37','operation.rb',-2,235,1,'2020-03-23 23:02:24','2020-03-24 00:02:24',NULL,NULL),(61,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:04:11.920-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>347</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:04:14.731-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004654.701}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>348</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:04:15.428-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004655.395}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:04:21.052-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":18}],\"timestamp\":1585004661.014}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 18, job_id: 61, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:04:19\\\\\\\", created_at: \\\\\\\"2020-03-23 23:04:19\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:04:19\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:04:22.071-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004662.031}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"plate_id ﻿Plate ID, well_location Well Location\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:04:25.241-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004665.232}},{\"operation\":\"error\",\"message\":\"Headers incorrect\",\"backtrace\":[\"(eval):158:in `block in sample_from_csv\'\",\"(eval):153:in `each\'\",\"(eval):153:in `each_with_index\'\",\"(eval):153:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:04:25.261-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:04:11','2020-03-23 23:04:25','operation.rb',-2,235,1,'2020-03-23 23:04:11','2020-03-24 00:04:11',NULL,NULL),(62,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:05:22.678-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>349</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:05:25.691-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004725.682}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>350</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:05:26.891-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004726.882}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:05:33.545-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":19}],\"timestamp\":1585004733.527}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 19, job_id: 62, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:05:32\\\\\\\", created_at: \\\\\\\"2020-03-23 23:05:32\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:05:32\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:05:34.911-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004734.889}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"plate_id ﻿Plate ID, well_location Well Location\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:05:35.983-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004735.961}},{\"operation\":\"error\",\"message\":\"Headers incorrect\",\"backtrace\":[\"(eval):158:in `block in sample_from_csv\'\",\"(eval):153:in `each\'\",\"(eval):153:in `each_with_index\'\",\"(eval):153:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:05:36.005-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:05:22','2020-03-23 23:05:36','operation.rb',-2,235,1,'2020-03-23 23:05:22','2020-03-24 00:05:22',NULL,NULL),(63,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:07:01.324-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>351</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:07:05.058-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004825.037}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>352</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:07:06.140-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004826.117}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:07:12.016-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":20}],\"timestamp\":1585004831.986}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 20, job_id: 63, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:07:10\\\\\\\", created_at: \\\\\\\"2020-03-23 23:07:10\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:07:10\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:07:13.063-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004833.033}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"plate_id ﻿Plate ID, well_location Well Location\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:07:14.194-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585004834.163}},{\"operation\":\"error\",\"message\":\"Location outside collection dimensions\",\"backtrace\":[\"Collection_Management/SampleManagement:83:in `part_alpha_num\'\",\"(eval):162:in `block in sample_from_csv\'\",\"(eval):153:in `each\'\",\"(eval):153:in `each_with_index\'\",\"(eval):153:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:07:14.215-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:07:01','2020-03-23 23:07:14','operation.rb',-2,235,1,'2020-03-23 23:07:01','2020-03-24 00:07:01',NULL,NULL),(64,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:10:13.668-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>353</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:10:16.569-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005016.533}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>354</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:10:17.114-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005017.08}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:10:22.395-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":21}],\"timestamp\":1585005022.354}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 21, job_id: 64, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:10:21\\\\\\\", created_at: \\\\\\\"2020-03-23 23:10:21\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:10:21\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:10:24.435-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005024.427}},{\"operation\":\"error\",\"message\":\"undefined method `eacy\' for #<Array:0x00005566e6841870>\\nDid you mean?  each\",\"backtrace\":[\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:10:24.459-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:10:13','2020-03-23 23:10:24','operation.rb',-2,235,1,'2020-03-23 23:10:13','2020-03-24 00:10:13',NULL,NULL),(65,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:13:28.636-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>355</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:13:31.857-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005211.84}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>356</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:13:32.838-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005212.817}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:13:42.922-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":22}],\"timestamp\":1585005222.893}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 22, job_id: 65, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:13:41\\\\\\\", created_at: \\\\\\\"2020-03-23 23:13:41\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:13:41\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:13:44.004-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005223.973}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"Array\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:13:54.034-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005234.027}},{\"operation\":\"error\",\"message\":\"Location outside collection dimensions\",\"backtrace\":[\"Collection_Management/SampleManagement:83:in `part_alpha_num\'\",\"(eval):158:in `block (2 levels) in sample_from_csv\'\",\"(eval):155:in `each\'\",\"(eval):155:in `each_with_index\'\",\"(eval):155:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:13:54.055-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:13:28','2020-03-23 23:13:54','operation.rb',-2,235,1,'2020-03-23 23:13:28','2020-03-24 00:13:28',NULL,NULL),(66,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:15:10.791-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>357</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:15:15.234-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005315.198}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>358</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:15:16.177-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005316.143}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:15:23.843-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":23}],\"timestamp\":1585005323.834}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 23, job_id: 66, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 545, upload_updated_at: \\\\\\\"2020-03-23 23:15:21\\\\\\\", created_at: \\\\\\\"2020-03-23 23:15:21\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:15:21\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:15:24.830-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005324.82}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"P4\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:02.338-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005722.319}},{\"operation\":\"error\",\"message\":\"Location outside collection dimensions\",\"backtrace\":[\"Collection_Management/SampleManagement:83:in `part_alpha_num\'\",\"(eval):158:in `block (2 levels) in sample_from_csv\'\",\"(eval):154:in `each\'\",\"(eval):154:in `each_with_index\'\",\"(eval):154:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):88:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:02.358-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:15:10','2020-03-23 23:22:02','operation.rb',-2,235,1,'2020-03-23 23:15:10','2020-03-24 00:15:10',NULL,NULL),(67,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:22:10.231-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>359</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:13.154-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005733.124}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>360</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:13.797-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005733.765}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:29.135-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":24}],\"timestamp\":1585005749.12}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 24, job_id: 67, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 502, upload_updated_at: \\\\\\\"2020-03-23 23:22:27\\\\\\\", created_at: \\\\\\\"2020-03-23 23:22:27\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:22:27\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:31.118-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005751.1}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"A1\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:32.394-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005752.376}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"A2\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:33.310-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005753.275}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"A3\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:33.953-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005753.932}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"A4\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:34.793-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005754.77}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"A5\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:48.359-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:22:10','2020-03-23 23:22:48','operation.rb',-2,235,1,'2020-03-23 23:22:10','2020-03-24 00:22:10',NULL,NULL),(68,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:22:55.244-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>361</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:58.377-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005778.363}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>362</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:22:58.971-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005778.957}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:23:04.386-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":25}],\"timestamp\":1585005784.364}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[#\\\\u003cUpload id: 25, job_id: 68, upload_file_name: \\\\\\\"Book3.csv\\\\\\\", upload_content_type: \\\\\\\"text/plain\\\\\\\", upload_file_size: 502, upload_updated_at: \\\\\\\"2020-03-23 23:23:03\\\\\\\", created_at: \\\\\\\"2020-03-23 23:23:03\\\\\\\", updated_at: \\\\\\\"2020-03-23 23:23:03\\\\\\\"\\\\u003e]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:23:30.107-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005810.09}},{\"operation\":\"error\",\"message\":\"undefined local variable or method `total_adapter\' for #<ExecutionNamespaceDVmVgEA9g8D9kqY_4HRwLmobIxvjNUKktw1DFZT_foQ::Protocol:0x00005566e65ce098>\\nDid you mean?  total_adapters\",\"backtrace\":[\"(eval):113:in `validate_csv\'\",\"(eval):89:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:23:30.475-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:22:55','2020-03-23 23:23:30','operation.rb',-2,235,1,'2020-03-23 23:22:55','2020-03-24 00:22:55',NULL,NULL),(69,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:24:15.083-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>363</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:24:56.279-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005896.264}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>364</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:24:57.541-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005897.528}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:25:04.662-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":26}],\"timestamp\":1585005904.641}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:25:15.585-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005915.553}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:364) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(364)\'>364</a>):\"},{\"table\":[[{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:25:59.341-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005959.325}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:364) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(364)\'>364</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:26:10.529-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005970.5}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:363) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(363)\'>363</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:26:16.414-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005976.378}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:26:18.176-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005978.138}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 363\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:26:23.219-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005983.209}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[363,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:26:24.824-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585005984.813}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585005984.813}}]','2020-03-23 23:24:15','2020-03-23 23:26:24','operation.rb',-2,235,1,'2020-03-23 23:24:15','2020-03-24 00:24:15',NULL,NULL),(70,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:29:50.742-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>432</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:29:53.573-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006193.563}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>433</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:29:54.127-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006194.117}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:30:01.201-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":27}],\"timestamp\":1585006201.184}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:30:03.559-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006203.539}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:433) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(433)\'>433</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:14.097-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006334.063}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:433) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(433)\'>433</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:19.032-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006338.992}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:432) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(432)\'>432</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:23.261-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006343.252}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:24.446-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006344.434}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 432\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:27.539-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006347.524}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[432,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:29.334-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006349.317}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585006349.317}}]','2020-03-23 23:29:50','2020-03-23 23:32:29','operation.rb',-2,235,1,'2020-03-23 23:29:50','2020-03-24 00:29:50',NULL,NULL),(71,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:32:38.603-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>501</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:49.330-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006369.27}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>502</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:50.153-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006370.112}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:55.803-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":28}],\"timestamp\":1585006375.789}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:32:57.970-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006377.955}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:502) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(502)\'>502</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:34:25.467-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:32:38','2020-03-23 23:34:25','operation.rb',-2,235,1,'2020-03-23 23:32:38','2020-03-24 00:32:38',NULL,NULL),(72,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:34:37.115-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>515</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:34:40.402-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006480.373}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>516</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:34:41.126-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006481.096}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:34:47.271-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":29}],\"timestamp\":1585006487.235}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:34:54.009-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006493.999}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"12\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:34:57.080-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585006497.067}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:516) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(516)\'>516</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:24.536-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:34:37','2020-03-23 23:45:24','operation.rb',-2,235,1,'2020-03-23 23:34:37','2020-03-24 00:34:37',NULL,NULL),(73,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:45:31.297-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>529</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:34.211-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007134.188}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>530</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:34.854-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007134.83}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:41.609-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":30}],\"timestamp\":1585007141.577}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 0]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:43.528-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007143.463}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 1]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:44.445-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007144.411}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 2]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:45.142-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007145.107}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 3]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:46.201-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007146.164}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 4]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:46.954-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007146.917}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 5]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:47.681-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007147.643}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 6]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:48.434-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007148.395}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 7]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:49.064-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007149.023}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 8]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:45:49.878-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007149.836}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 0]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:46:02.039-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007162.019}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 0]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:46:02.694-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007162.674}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"[[0, 0]]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:46:03.267-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007163.246}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:46:03.887-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007163.865}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"12\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:46:04.657-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007164.633}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:530) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(530)\'>530</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:46:55.566-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:45:31','2020-03-23 23:46:55','operation.rb',-2,235,1,'2020-03-23 23:45:31','2020-03-24 00:45:31',NULL,NULL),(74,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:47:03.335-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>543</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:06.623-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007226.596}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>544</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:07.240-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007227.213}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:12.340-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":31}],\"timestamp\":1585007232.309}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 0]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A1\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:15.027-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007234.992}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 1]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A2\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:15.756-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007235.721}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 2]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A3\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:16.377-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007236.341}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 3]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A4\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:17.036-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007236.998}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 4]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A5\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:17.709-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007237.672}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 5]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A6\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:18.588-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007238.548}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 6]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A7\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:19.269-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007239.229}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 7]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A8\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:19.964-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007239.924}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 8]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A9\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:20.983-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007240.942}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 0]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A10\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:23.297-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007243.288}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 0]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A11\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:24.926-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007244.913}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 0]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A12\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:47:26.505-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007246.492}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:02.682-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:47:03','2020-03-23 23:49:02','operation.rb',-2,235,1,'2020-03-23 23:47:03','2020-03-24 00:47:03',NULL,NULL),(75,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:49:16.367-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>545</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:21.239-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007361.23}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>546</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:23.075-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007363.065}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:29.244-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":32}],\"timestamp\":1585007369.226}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A1\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:31.376-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007371.356}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A2\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:33.554-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007373.531}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A3\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:34.729-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007374.706}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A4\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:35.598-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007375.573}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A5\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:36.179-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007376.153}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A6\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:37.111-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007377.085}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A7\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:37.739-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007377.712}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A8\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:38.317-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007378.289}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A9\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:39.109-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007379.081}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A10\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:39.774-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007379.738}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A11\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:40.487-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007380.427}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A12\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:41.343-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007381.312}},{\"operation\":\"error\",\"message\":\"undefined method `containing_collection\' for nil:NilClass\",\"backtrace\":[\"(eval):163:in `block in sample_from_csv\'\",\"(eval):163:in `each\'\",\"(eval):163:in `group_by\'\",\"(eval):163:in `sample_from_csv\'\",\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:49:41.367-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:49:16','2020-03-23 23:49:41','operation.rb',-2,235,1,'2020-03-23 23:49:16','2020-03-24 00:49:16',NULL,NULL),(76,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:53:19.368-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>547</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:24.690-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007604.677}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>548</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:29.558-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007609.542}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:35.068-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":33}],\"timestamp\":1585007615.044}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 0]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A1\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:37.880-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007617.852}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 1]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A2\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:38.795-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007618.768}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 2]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A3\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:39.558-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007619.529}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 3]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A4\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:40.401-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007620.372}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 4]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A5\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:41.085-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007621.054}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 5]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A6\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:41.900-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007621.868}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 6]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A7\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:43.493-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007623.458}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 7]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A8\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:44.489-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007624.453}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 8]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A9\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:46.102-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007626.065}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 9]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A10\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:47.417-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007627.38}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 10]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A11\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:48.663-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007628.624}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"location: [[0, 11]], row: [\\\\\\\"100\\\\\\\", \\\\\\\"A12\\\\\\\"]\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:49.556-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007629.516}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:51.250-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007631.24}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"12\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:52.448-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007632.435}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:548) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(548)\'>548</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:53:58.065-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007638.048}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:547) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(547)\'>547</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:54:01.276-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007641.255}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:54:02.735-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007642.714}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 547\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:54:05.487-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007645.461}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[547,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:54:07.072-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007647.044}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585007647.044}}]','2020-03-23 23:53:19','2020-03-23 23:54:07','operation.rb',-2,235,1,'2020-03-23 23:53:19','2020-03-24 00:53:19',NULL,NULL),(77,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:56:31.986-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>563</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:56:35.662-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007795.637}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>564</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:56:36.361-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007796.335}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:56:44.981-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":34}],\"timestamp\":1585007804.945}},{\"operation\":\"error\",\"message\":\"Location outside collection dimensions\",\"backtrace\":[\"Collection_Management/SampleManagement:83:in `part_alpha_num\'\",\"(eval):157:in `block (2 levels) in sample_from_csv\'\",\"(eval):154:in `each\'\",\"(eval):154:in `each_with_index\'\",\"(eval):154:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:56:45.120-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:56:31','2020-03-23 23:56:45','operation.rb',-2,235,1,'2020-03-23 23:56:31','2020-03-24 00:56:31',NULL,NULL),(78,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:57:17.265-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>565</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:57:20.682-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007840.64}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>566</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:57:23.202-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007843.189}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:57:29.396-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":35}],\"timestamp\":1585007849.379}},{\"operation\":\"error\",\"message\":\"Location outside collection dimensions\",\"backtrace\":[\"Collection_Management/SampleManagement:83:in `part_alpha_num\'\",\"(eval):157:in `block (2 levels) in sample_from_csv\'\",\"(eval):154:in `each\'\",\"(eval):154:in `each_with_index\'\",\"(eval):154:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:57:29.543-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:57:17','2020-03-23 23:57:29','operation.rb',-2,235,1,'2020-03-23 23:57:17','2020-03-24 00:57:17',NULL,NULL),(79,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:58:08.775-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>567</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:58:13.509-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007893.475}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>568</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:58:14.128-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007894.092}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:58:20.668-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":36}],\"timestamp\":1585007900.66}},{\"operation\":\"error\",\"message\":\"Location outside collection dimensions\",\"backtrace\":[\"Collection_Management/SampleManagement:83:in `part_alpha_num\'\",\"(eval):157:in `block (2 levels) in sample_from_csv\'\",\"(eval):154:in `each\'\",\"(eval):154:in `each_with_index\'\",\"(eval):154:in `block in sample_from_csv\'\",\"(eval):152:in `each\'\",\"(eval):152:in `sample_from_csv\'\",\"(eval):87:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:58:20.810-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:58:08','2020-03-23 23:58:20','operation.rb',-2,235,1,'2020-03-23 23:58:08','2020-03-24 00:58:08',NULL,NULL),(80,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:58:56.069-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>569</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:58:59.538-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007939.519}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>570</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:00.189-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007940.169}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:05.084-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":37}],\"timestamp\":1585007945.06}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:07.371-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007947.344}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"12\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:08.507-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007948.479}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:570) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(570)\'>570</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:12.479-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:58:56','2020-03-23 23:59:12','operation.rb',-2,235,1,'2020-03-23 23:58:56','2020-03-24 00:58:56',NULL,NULL),(81,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T16:59:44.960-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>583</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:48.059-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007988.019}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>584</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:48.785-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007988.746}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:54.942-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":38}],\"timestamp\":1585007994.929}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T16:59:59.586-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585007999.568}},{\"operation\":\"display\",\"content\":[{\"title\":\"<span style=\\\"background-color:yellow\\\">INSPECTING  (String)</span>\"},{\"note\":\"\\\"24\\\"\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:00:00.455-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008000.435}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:584) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(584)\'>584</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:00:33.113-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-23 23:59:44','2020-03-24 00:00:33','operation.rb',-2,235,1,'2020-03-23 23:59:44','2020-03-24 00:59:44',NULL,NULL),(82,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T17:01:12.214-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>609</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:15.645-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008075.607}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>610</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:16.310-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008076.272}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:22.070-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":39}],\"timestamp\":1585008082.061}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:23.725-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008083.712}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:610) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(610)\'>610</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:39.024-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008098.995}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:610) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(610)\'>610</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:46.550-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008106.512}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:609) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(609)\'>609</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:50.814-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008110.805}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:52.319-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008112.309}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 609\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:01:55.374-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585008115.36}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[609,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:30:16.169-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-24 00:01:12','2020-03-24 00:30:16','operation.rb',-2,235,1,'2020-03-24 00:01:12','2020-03-24 01:01:12',NULL,NULL),(83,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T17:30:22.303-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>663</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:30:25.365-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009825.349}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>664</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:30:26.040-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009826.024}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:30:31.865-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":40}],\"timestamp\":1585009831.843}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:30:33.489-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009833.464}},{\"operation\":\"error\",\"message\":\"uninitialized constant ExecutionNamespaceZZvBFkZebiGoO46kaiHIrOY548jaIcTPefYXw2OIwj8::CollectionTransfer::INPUT_PLATE\",\"backtrace\":[\"Collection_Management/CollectionTransfer:48:in `transfer_to_working_plate\'\",\"(eval):94:in `block in make_adapter_plate\'\",\"(eval):91:in `each\'\",\"(eval):91:in `make_adapter_plate\'\",\"(eval):51:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:30:34.011-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-24 00:30:22','2020-03-24 00:30:34','operation.rb',-2,235,1,'2020-03-24 00:30:22','2020-03-24 01:30:22',NULL,NULL),(84,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T17:31:45.814-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>695</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:32:06.824-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009926.795}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>696</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:32:07.982-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009927.951}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:32:14.720-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":41}],\"timestamp\":1585009934.683}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:32:15.792-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009935.754}},{\"operation\":\"error\",\"message\":\"undefined method `assocaite\' for #<Item:0x00005566e6074700>\\nDid you mean?  associate\",\"backtrace\":[\"/usr/local/bundle/gems/activemodel-4.2.11.1/lib/active_model/attribute_methods.rb:433:in `method_missing\'\",\"Collection_Management/CollectionTransfer:155:in `block in associate_plate_to_plate\'\",\"Collection_Management/CollectionTransfer:154:in `each\'\",\"Collection_Management/CollectionTransfer:154:in `each_with_index\'\",\"Collection_Management/CollectionTransfer:154:in `associate_plate_to_plate\'\",\"Collection_Management/CollectionTransfer:48:in `transfer_to_working_plate\'\",\"(eval):94:in `block in make_adapter_plate\'\",\"(eval):91:in `each\'\",\"(eval):91:in `make_adapter_plate\'\",\"(eval):51:in `main\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:32:16.399-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-24 00:31:45','2020-03-24 00:32:16','operation.rb',-2,235,1,'2020-03-24 00:31:45','2020-03-24 01:31:45',NULL,NULL),(85,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-23T17:32:56.294-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>727</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:32:59.784-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009979.763}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>728</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:01.725-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009981.701}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:10.186-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":42}],\"timestamp\":1585009990.153}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:11.908-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009991.875}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:728) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(728)\'>728</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:16.706-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585009996.666}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:728) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(728)\'>728</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:20.634-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585010000.624}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:727) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(727)\'>727</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:24.764-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585010004.748}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:26.268-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585010006.251}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 727\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:29.922-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585010009.898}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[727,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-23T17:33:31.391-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585010011.367}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585010011.367}}]','2020-03-24 00:32:56','2020-03-24 00:33:31','operation.rb',-2,235,1,'2020-03-24 00:32:56','2020-03-24 01:32:56',NULL,NULL),(86,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-24T08:15:11.494-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>781</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:15:15.158-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585062915.131}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>782</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:15:15.731-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585062915.702}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:15:21.222-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":43}],\"timestamp\":1585062921.185}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:15:28.538-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585062928.529}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:782) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(782)\'>782</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:15:34.360-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585062934.332}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:782) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(782)\'>782</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:15:39.423-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585062939.4}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:781) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(781)\'>781</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:22:20.474-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063340.437}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:22:22.205-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063342.157}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 781\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:22:25.445-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063345.403}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[781,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:22:26.691-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063346.637}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585063346.637}}]','2020-03-24 15:15:11','2020-03-24 15:22:26','operation.rb',-2,235,1,'2020-03-24 15:15:11','2020-03-24 16:15:11',NULL,NULL),(87,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-24T08:23:56.674-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>835</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:24:00.017-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063440.004}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:24:00.666-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063440.655}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:835) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(835)\'>835</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:24:06.416-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063446.396}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:24:07.575-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063447.555}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"71\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"54\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"90\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"91\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"68\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"76\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"58\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"57\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:24:10.540-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063450.515}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[835,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T08:24:11.598-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585063451.573}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585063451.573}}]','2020-03-24 15:23:56','2020-03-24 15:24:11','operation.rb',-2,235,1,'2020-03-24 15:23:56','2020-03-24 16:23:56',NULL,NULL),(88,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-24T09:06:10.091-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>844</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:13.408-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585065973.374}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>845</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:14.014-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585065973.985}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:19.865-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":44}],\"timestamp\":1585065979.827}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:27.313-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585065987.301}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:845) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(845)\'>845</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:31.925-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585065991.908}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:845) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(845)\'>845</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:36.931-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585065996.905}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:38.401-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585065998.375}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:844) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(844)\'>844</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:44.119-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066004.087}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:45.724-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066005.691}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 844\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:48.937-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066008.899}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[844,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:06:52.625-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066012.584}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585066012.584}}]','2020-03-24 16:06:10','2020-03-24 16:06:52','operation.rb',-2,235,1,'2020-03-24 16:06:10','2020-03-24 17:06:10',NULL,NULL),(89,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":2},\"time\":\"2020-03-24T09:07:14.094-07:00\"},{\"operation\":\"error\",\"message\":\"Sample 3 has been included multiple times in this job\",\"backtrace\":[\"RNA_Seq/WorkflowValidation:27:in `validate_inputs\'\",\"(eval):29:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:07:16.043-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-24 16:07:14','2020-03-24 16:07:16','operation.rb',-2,235,1,'2020-03-24 16:07:14','2020-03-24 17:07:14',NULL,NULL),(90,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":3},\"time\":\"2020-03-24T09:16:53.502-07:00\"},{\"operation\":\"error\",\"message\":\"Sample 3 has been included multiple times in this job\",\"backtrace\":[\"RNA_Seq/WorkflowValidation:27:in `validate_inputs\'\",\"(eval):37:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:16:56.519-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-24 16:16:53','2020-03-24 16:16:56','operation.rb',-2,235,1,'2020-03-24 16:16:53','2020-03-24 17:16:53',NULL,NULL),(91,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-24T09:17:06.245-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>904</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:09.275-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066629.249}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:09.864-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066629.836}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:904) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(904)\'>904</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:13.036-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066633.006}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:13.773-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066633.741}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"75\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"88\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"63\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"81\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"70\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"97\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"94\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"59\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:16.491-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066636.457}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[904,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:17.541-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066637.506}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585066637.506}}]','2020-03-24 16:17:06','2020-03-24 16:17:17','operation.rb',-2,235,1,'2020-03-24 16:17:06','2020-03-24 17:17:06',NULL,NULL),(92,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":4},\"time\":\"2020-03-24T09:17:25.509-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>913</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:29.182-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066649.167}},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>914</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:30.019-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066650.005}},{\"operation\":\"display\",\"content\":[{\"title\":\"Make CSV file of Adapters\"},{\"note\":\"Please make a <b>CSV</B> file of all required adapters\"},{\"note\":\"Row 1 is Reserved for headers\"},{\"note\":\"Column 1: \'Plate ID\'\"},{\"note\":\"Column 2: \'Well Location\' (e.g. A1, B1)\"},{\"upload\":{\"var\":\"csv\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:36.533-07:00\",\"inputs\":{\"table_inputs\":[],\"csv\":[{\"name\":\"Book3.csv\",\"id\":45}],\"timestamp\":1585066656.509}},{\"operation\":\"display\",\"content\":[{\"title\":\"More Adapters than needed\"},{\"note\":\"The CSV uploaded adds more adapters than needed.\"},{\"note\":\"Click OKAY to continue with this job or Cancel to Cancel\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:37.721-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066657.697}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:100) to working \\n                                plate (ID:914) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 100):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(914)\'>914</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:41.623-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066661.595}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 12 ul from stock plate (ID:3) to working \\n                                plate (ID:914) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 3):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(914)\'>914</a>):\"},{\"table\":[[{\"content\":1,\"class\":\"td-empty-slot\"},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"C7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C9\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C10\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C11\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C12\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2, H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H6\",\"class\":\"td-filled-slot\",\"check\":true}],[{\"content\":\"H7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:46.350-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066666.316}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:48.505-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066668.467}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:913) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(913)\'>913</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"C1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"D1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"E1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"F1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"G1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"H1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:52.180-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066672.138}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:54.008-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066673.985}},{\"operation\":\"display\",\"content\":[{\"title\":\"Run RNA-Prep\"},{\"note\":\"Run typical RNA-Prep Protocol with plate 913\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:57.558-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066677.545}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[913,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T09:17:59.110-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585066679.095}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585066679.095}}]','2020-03-24 16:17:25','2020-03-24 16:17:59','operation.rb',-2,235,1,'2020-03-24 16:17:25','2020-03-24 17:17:25',NULL,NULL),(93,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":2},\"time\":\"2020-03-24T10:54:38.694-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>973</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:54:41.789-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072481.754}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":913,\"location\":\"Freezer\",\"name\":\"96 Well Sample Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:54:42.843-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072482.807}},{\"operation\":\"error\",\"message\":\"undefined local variable or method `working_plate\' for #<ExecutionNamespaceURUsBcxC19tTemoAVq1ioz4MJ9PTBd7C3shia4zMhWo::Protocol:0x00005566e480a0e8>\\nDid you mean?  workingt_plate\",\"backtrace\":[\"(eval):37:in `block in main\'\",\"(eval):35:in `each\'\",\"(eval):35:in `main\'\",\"/aquarium/lib/krill/protocol_sandbox.rb:65:in `execute\'\",\"/aquarium/lib/krill/threaded_manager.rb:40:in `block in start_thread\'\"]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:54:42.875-07:00\",\"inputs\":{}},{\"operation\":\"aborted\",\"rval\":{}}]','2020-03-24 17:54:38','2020-03-24 17:54:42','operation.rb',-2,235,1,'2020-03-24 17:54:38','2020-03-24 18:54:38',NULL,NULL),(94,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":2},\"time\":\"2020-03-24T10:57:05.560-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>974</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:57:09.214-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072629.182}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":913,\"location\":\"Freezer\",\"name\":\"96 Well Sample Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:57:10.186-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072630.151}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:913) to working \\n                                plate (ID:974) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 913):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(974)\'>974</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A2\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A3\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A4\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A5\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A6\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A7\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"A8\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:57:14.510-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072634.471}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[913,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:57:15.676-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072635.635}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will assume to pass\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"Pass\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:57:18.907-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072638.897}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[974,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:57:20.138-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072640.127}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585072640.127}}]','2020-03-24 17:57:05','2020-03-24 17:57:20','operation.rb',-2,235,1,'2020-03-24 17:57:05','2020-03-24 18:57:05',NULL,NULL),(95,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":3},\"time\":\"2020-03-24T10:57:44.449-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":913,\"location\":\"Freezer\",\"name\":\"96 Well Sample Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:58:12.813-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072692.777}},{\"operation\":\"display\",\"content\":[{\"title\":\"Rename Plate\"},{\"note\":\"Relabel plate 913 with 983\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:58:16.152-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072696.112}},{\"operation\":\"display\",\"content\":[{\"title\":\"Do the Normalization Pooling Steps\"},{\"note\":\"Run typical Normalization Pooling protocol with plate 983\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:58:19.024-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072699.014}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[983,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T10:58:19.886-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585072699.876}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585072699.876}}]','2020-03-24 17:57:44','2020-03-24 17:58:19','operation.rb',-2,235,1,'2020-03-24 17:57:44','2020-03-24 18:57:44',NULL,NULL),(96,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":3},\"time\":\"2020-03-24T11:21:22.695-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":913,\"location\":\"deleted\",\"name\":\"96 Well Sample Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T11:21:27.833-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585074087.812}},{\"operation\":\"display\",\"content\":[{\"title\":\"Rename Plate\"},{\"note\":\"Relabel plate 913 with 992\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T11:21:28.779-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585074088.757}},{\"operation\":\"display\",\"content\":[{\"title\":\"Do the Normalization Pooling Steps\"},{\"note\":\"Run typical Normalization Pooling protocol with plate 992\"},{\"table\":[[{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T11:21:32.173-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585074092.146}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[992,\"96 Well Sample Plate\",\"Freezer\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T11:21:33.097-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585074093.07}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585074093.07}}]','2020-03-24 18:21:22','2020-03-24 18:21:33','operation.rb',-2,235,1,'2020-03-24 18:21:22','2020-03-24 19:21:22',NULL,NULL),(97,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-24T12:07:24.996-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>1001</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:07:30.388-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585076850.36}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:07:31.796-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585076851.766}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:1001) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(1001)\'>1001</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:07:35.770-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585076855.731}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:07:36.835-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585076856.795}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"55\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"73\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:07:42.148-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585076862.094}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[1001,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:07:43.153-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585076863.142}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585076863.142}}]','2020-03-24 19:07:24','2020-03-24 19:07:43','operation.rb',-2,235,1,'2020-03-24 19:07:24','2020-03-24 20:07:24',NULL,NULL),(98,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-24T12:15:50.890-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>1005</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:15:54.105-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585077354.085}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:15:54.811-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585077354.788}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:1005) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(1005)\'>1005</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:15:58.902-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585077358.875}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:16:00.343-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585077360.315}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"94\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"96\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:16:03.854-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585077363.821}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[1005,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:16:05.343-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585077365.309}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585077365.309}}]','2020-03-24 19:15:50','2020-03-24 19:16:05','operation.rb',-2,235,1,'2020-03-24 19:15:50','2020-03-24 20:15:50',NULL,NULL),(99,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-24T12:59:13.763-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>1009</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:59:17.963-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585079957.944}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:59:18.673-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585079958.654}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:1009) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(1009)\'>1009</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:59:21.901-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585079961.878}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:59:22.979-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585079962.955}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"81\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"95\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:59:27.109-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585079967.08}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[1009,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T12:59:28.122-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585079968.092}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585079968.092}}]','2020-03-24 19:59:13','2020-03-24 19:59:28','operation.rb',-2,235,1,'2020-03-24 19:59:13','2020-03-24 20:59:13',NULL,NULL),(100,'1',NULL,'[{\"operation\":\"initialize\",\"arguments\":{\"operation_type_id\":5},\"time\":\"2020-03-24T13:02:43.278-07:00\"},{\"operation\":\"display\",\"content\":[{\"title\":\"Get and Label Working Plate\"},{\"note\":\"Get a <b>96 Well Sample Plate</b> and lable ID: <b>1013</b>\"}]},{\"operation\":\"next\",\"time\":\"2020-03-24T13:02:46.187-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585080166.172}},{\"operation\":\"display\",\"content\":[{\"title\":\"Gather the Following Additional Item(s)\"},{\"take\":{\"id\":200,\"location\":\"Bench\",\"name\":\"Total RNA 96 Well Plate\"}}]},{\"operation\":\"next\",\"time\":\"2020-03-24T13:02:46.933-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585080166.914}},{\"operation\":\"display\",\"content\":[{\"title\":\"Transfer from Stock Plate to Working Plate\"},{\"note\":\"Please transfer 20 ul from stock plate (ID:200) to working \\n                                plate (ID:1013) per tables below\"},{\"note\":\"Separator\"},{\"note\":\"Stock Plate (ID: 200):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":2,\"class\":\"td-empty-slot\"},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]},{\"note\":\"Working Plate (ID: <a href=\'#\' onclick=\'open_item_ui(1013)\'>1013</a>):\"},{\"table\":[[{\"content\":\"A1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"B1\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T13:02:50.358-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585080170.338}},{\"operation\":\"display\",\"content\":[{\"title\":\"Put Away the Following Items\"},{\"table\":[[\"ID\",\"Collection Type\",\"Location\"],[200,\"Total RNA 96 Well Plate\",\"Bench\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T13:02:52.971-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585080172.947}},{\"operation\":\"display\",\"content\":[{\"title\":\"Perform QC Measurements\"},{\"note\":\"Please Attach excel files\"},{\"note\":\"For testing purposes each sample will be given a random concentration from 50 to 100 ng/ul\"},{\"note\":\"This will eventually come from a CSV file\"},{\"table\":[[{\"content\":\"64\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":\"58\",\"class\":\"td-filled-slot\",\"check\":true},{\"content\":3,\"class\":\"td-empty-slot\"},{\"content\":4,\"class\":\"td-empty-slot\"},{\"content\":5,\"class\":\"td-empty-slot\"},{\"content\":6,\"class\":\"td-empty-slot\"},{\"content\":7,\"class\":\"td-empty-slot\"},{\"content\":8,\"class\":\"td-empty-slot\"},{\"content\":9,\"class\":\"td-empty-slot\"},{\"content\":10,\"class\":\"td-empty-slot\"},{\"content\":11,\"class\":\"td-empty-slot\"},{\"content\":12,\"class\":\"td-empty-slot\"}],[{\"content\":13,\"class\":\"td-empty-slot\"},{\"content\":14,\"class\":\"td-empty-slot\"},{\"content\":15,\"class\":\"td-empty-slot\"},{\"content\":16,\"class\":\"td-empty-slot\"},{\"content\":17,\"class\":\"td-empty-slot\"},{\"content\":18,\"class\":\"td-empty-slot\"},{\"content\":19,\"class\":\"td-empty-slot\"},{\"content\":20,\"class\":\"td-empty-slot\"},{\"content\":21,\"class\":\"td-empty-slot\"},{\"content\":22,\"class\":\"td-empty-slot\"},{\"content\":23,\"class\":\"td-empty-slot\"},{\"content\":24,\"class\":\"td-empty-slot\"}],[{\"content\":25,\"class\":\"td-empty-slot\"},{\"content\":26,\"class\":\"td-empty-slot\"},{\"content\":27,\"class\":\"td-empty-slot\"},{\"content\":28,\"class\":\"td-empty-slot\"},{\"content\":29,\"class\":\"td-empty-slot\"},{\"content\":30,\"class\":\"td-empty-slot\"},{\"content\":31,\"class\":\"td-empty-slot\"},{\"content\":32,\"class\":\"td-empty-slot\"},{\"content\":33,\"class\":\"td-empty-slot\"},{\"content\":34,\"class\":\"td-empty-slot\"},{\"content\":35,\"class\":\"td-empty-slot\"},{\"content\":36,\"class\":\"td-empty-slot\"}],[{\"content\":37,\"class\":\"td-empty-slot\"},{\"content\":38,\"class\":\"td-empty-slot\"},{\"content\":39,\"class\":\"td-empty-slot\"},{\"content\":40,\"class\":\"td-empty-slot\"},{\"content\":41,\"class\":\"td-empty-slot\"},{\"content\":42,\"class\":\"td-empty-slot\"},{\"content\":43,\"class\":\"td-empty-slot\"},{\"content\":44,\"class\":\"td-empty-slot\"},{\"content\":45,\"class\":\"td-empty-slot\"},{\"content\":46,\"class\":\"td-empty-slot\"},{\"content\":47,\"class\":\"td-empty-slot\"},{\"content\":48,\"class\":\"td-empty-slot\"}],[{\"content\":49,\"class\":\"td-empty-slot\"},{\"content\":50,\"class\":\"td-empty-slot\"},{\"content\":51,\"class\":\"td-empty-slot\"},{\"content\":52,\"class\":\"td-empty-slot\"},{\"content\":53,\"class\":\"td-empty-slot\"},{\"content\":54,\"class\":\"td-empty-slot\"},{\"content\":55,\"class\":\"td-empty-slot\"},{\"content\":56,\"class\":\"td-empty-slot\"},{\"content\":57,\"class\":\"td-empty-slot\"},{\"content\":58,\"class\":\"td-empty-slot\"},{\"content\":59,\"class\":\"td-empty-slot\"},{\"content\":60,\"class\":\"td-empty-slot\"}],[{\"content\":61,\"class\":\"td-empty-slot\"},{\"content\":62,\"class\":\"td-empty-slot\"},{\"content\":63,\"class\":\"td-empty-slot\"},{\"content\":64,\"class\":\"td-empty-slot\"},{\"content\":65,\"class\":\"td-empty-slot\"},{\"content\":66,\"class\":\"td-empty-slot\"},{\"content\":67,\"class\":\"td-empty-slot\"},{\"content\":68,\"class\":\"td-empty-slot\"},{\"content\":69,\"class\":\"td-empty-slot\"},{\"content\":70,\"class\":\"td-empty-slot\"},{\"content\":71,\"class\":\"td-empty-slot\"},{\"content\":72,\"class\":\"td-empty-slot\"}],[{\"content\":73,\"class\":\"td-empty-slot\"},{\"content\":74,\"class\":\"td-empty-slot\"},{\"content\":75,\"class\":\"td-empty-slot\"},{\"content\":76,\"class\":\"td-empty-slot\"},{\"content\":77,\"class\":\"td-empty-slot\"},{\"content\":78,\"class\":\"td-empty-slot\"},{\"content\":79,\"class\":\"td-empty-slot\"},{\"content\":80,\"class\":\"td-empty-slot\"},{\"content\":81,\"class\":\"td-empty-slot\"},{\"content\":82,\"class\":\"td-empty-slot\"},{\"content\":83,\"class\":\"td-empty-slot\"},{\"content\":84,\"class\":\"td-empty-slot\"}],[{\"content\":85,\"class\":\"td-empty-slot\"},{\"content\":86,\"class\":\"td-empty-slot\"},{\"content\":87,\"class\":\"td-empty-slot\"},{\"content\":88,\"class\":\"td-empty-slot\"},{\"content\":89,\"class\":\"td-empty-slot\"},{\"content\":90,\"class\":\"td-empty-slot\"},{\"content\":91,\"class\":\"td-empty-slot\"},{\"content\":92,\"class\":\"td-empty-slot\"},{\"content\":93,\"class\":\"td-empty-slot\"},{\"content\":94,\"class\":\"td-empty-slot\"},{\"content\":95,\"class\":\"td-empty-slot\"},{\"content\":96,\"class\":\"td-empty-slot\"}]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T13:02:56.153-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585080176.125}},{\"operation\":\"display\",\"content\":[{\"title\":\"Trash the following items\"},{\"table\":[[\"Item\",\"Waste Container\"],[1013,\"Biohazard Waste\"]]}]},{\"operation\":\"next\",\"time\":\"2020-03-24T13:03:15.356-07:00\",\"inputs\":{\"table_inputs\":[],\"timestamp\":1585080195.341}},{\"operation\":\"complete\",\"rval\":{\"table_inputs\":[],\"timestamp\":1585080195.341}}]','2020-03-24 20:02:43','2020-03-24 20:03:15','operation.rb',-2,235,1,'2020-03-24 20:02:43','2020-03-24 21:02:43',NULL,NULL);
/*!40000 ALTER TABLE `jobs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `libraries`
--

DROP TABLE IF EXISTS `libraries`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `libraries` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `category` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `libraries`
--

LOCK TABLES `libraries` WRITE;
/*!40000 ALTER TABLE `libraries` DISABLE KEYS */;
INSERT INTO `libraries` VALUES (1,'Debug','Standard Libs','2020-01-24 16:50:00','2020-01-24 16:50:00'),(2,'CollectionActions','Collection_Management','2020-03-19 17:30:41','2020-03-19 17:30:41'),(3,'CollectionDisplay','Collection_Management','2020-03-19 17:30:41','2020-03-19 17:30:41'),(4,'CollectionTransfer','Collection_Management','2020-03-19 17:30:41','2020-03-19 17:30:41'),(5,'SampleManagement','Collection_Management','2020-03-19 17:30:41','2020-03-19 17:30:41'),(6,'KeywordLib','RNA_Seq','2020-03-19 17:30:41','2020-03-19 17:30:41'),(7,'WorkflowValidation','RNA_Seq','2020-03-19 17:30:41','2020-03-19 17:30:41'),(8,'AssociationManagement','Standard Libs','2020-03-19 17:30:41','2020-03-19 17:30:41'),(9,'CommonInputOutputNames','Standard Libs','2020-03-19 17:30:41','2020-03-19 17:30:41'),(10,'PlanParams','Standard Libs','2020-03-19 17:30:41','2020-03-19 17:30:41'),(11,'Units','Standard Libs','2020-03-19 17:30:41','2020-03-19 17:30:41'),(12,'CsvDebugLib','RNA_Seq','2020-03-19 20:47:48','2020-03-19 20:57:38'),(13,'ControlBlock','Control Blocks','2020-03-24 15:41:58','2020-03-24 15:41:58');
/*!40000 ALTER TABLE `libraries` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `locators`
--

DROP TABLE IF EXISTS `locators`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `locators` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `wizard_id` int(11) DEFAULT NULL,
  `item_id` int(11) DEFAULT NULL,
  `number` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `locators`
--

LOCK TABLES `locators` WRITE;
/*!40000 ALTER TABLE `locators` DISABLE KEYS */;
/*!40000 ALTER TABLE `locators` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `logs`
--

DROP TABLE IF EXISTS `logs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `logs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) DEFAULT NULL,
  `user_id` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `entry_type` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `data` text COLLATE utf8_unicode_ci,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `logs`
--

LOCK TABLES `logs` WRITE;
/*!40000 ALTER TABLE `logs` DISABLE KEYS */;
/*!40000 ALTER TABLE `logs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `memberships`
--

DROP TABLE IF EXISTS `memberships`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `memberships` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `group_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=543 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `memberships`
--

LOCK TABLES `memberships` WRITE;
/*!40000 ALTER TABLE `memberships` DISABLE KEYS */;
INSERT INTO `memberships` VALUES (541,1,1,'2017-10-02 16:21:25','2017-10-02 16:21:25'),(542,1,235,'2017-10-02 17:50:59','2017-10-02 17:50:59');
/*!40000 ALTER TABLE `memberships` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `object_types`
--

DROP TABLE IF EXISTS `object_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `object_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `description` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `min` int(11) DEFAULT NULL,
  `max` int(11) DEFAULT NULL,
  `handler` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `safety` text COLLATE utf8_unicode_ci,
  `cleanup` text COLLATE utf8_unicode_ci,
  `data` text COLLATE utf8_unicode_ci,
  `vendor` text COLLATE utf8_unicode_ci,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `unit` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `cost` float DEFAULT NULL,
  `release_method` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `release_description` text COLLATE utf8_unicode_ci,
  `sample_type_id` int(11) DEFAULT NULL,
  `image` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `prefix` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `rows` int(11) DEFAULT NULL,
  `columns` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=21 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `object_types`
--

LOCK TABLES `object_types` WRITE;
/*!40000 ALTER TABLE `object_types` DISABLE KEYS */;
INSERT INTO `object_types` VALUES (1,'__Part','Part of a collection',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2018-12-21 17:59:09','2018-12-21 17:59:09','part',0.01,'return','',NULL,'','',NULL,NULL),(2,'Orphan','Part of a collection',0,1,'part','No safety information','No cleanup information','No data','No vendor information','2018-12-21 17:59:09','2018-12-21 17:59:09','part',0.01,'return','',NULL,'','',NULL,NULL),(3,'96 Well Sample Plate','96 well sample plate',0,1000,'collection','No safety information','No cleanup information','No data','No vendor information','2020-03-19 17:30:41','2020-03-19 17:32:04','plate',0.01,'return','',NULL,'','',8,12),(4,'Total RNA 96 Well Plate','96 Well plate of total RNA from customer',0,1000000,'collection','No safety information','No cleanup information','No data','No vendor information','2020-03-19 17:30:41','2020-03-19 17:32:08','plate',0.01,'return','',1,'','M80C',8,12),(5,'96 Well Oligonucleotide','A 96 well plate of stock oligonucleotides',0,1,'collection','No safety information','No cleanup information','No data','No vendor information','2020-03-19 18:35:54','2020-03-19 18:39:40','oligonucleotide',0.01,'return','',2,'','',8,12),(6,'Fragment Stock','Fragment stock in 1.5 mL tube, usually stored in M20 fridge.',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Fragment',50,'return','',3,NULL,'M20',NULL,NULL),(7,'1 ng/µL Fragment Stock','A diluted fragment stock to use as a PCR template',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Fragment',0.01,'return','',3,NULL,'M20',NULL,NULL),(8,'Gibson Reaction Result','A plasmid that was made from Gibson reaction and stayed in the Gibson reaction tube. One can use this to do transform and extract the plasmid.',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',10,'return','',4,NULL,'M20',NULL,NULL),(9,'Plasmid Stock','A 1.5 mL tube containing purified plasmid DNA',0,1,'sample_container','No safety information','No cleanup information','concentration:','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',2,'return','',4,NULL,'M20',NULL,NULL),(10,'1 ng/µL Plasmid Stock','Diluted stock for use as a template in PCR',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',0.01,'query','If this is an aliquot for the \"Transformation Efficiency Project\", dispose of it. Otherwise, return it.',4,NULL,'M20',NULL,NULL),(11,'Plasmid Glycerol Stock','Glycerol Stock of E. coli (usually DH5alpha) containing plasmid DNA stock',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',5,'return','',4,NULL,'M80',NULL,NULL),(12,'Checked E coli Plate of Plasmid','It\'s a checked plate',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','plate',0.01,'return','',4,NULL,'',NULL,NULL),(13,'E coli Plate of Plasmid','A plate containing E. coli transformed with a plasmid',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',0.01,'return','',4,NULL,'DFP',NULL,NULL),(14,'TB Overnight of Plasmid','An overnight of E. coli transformed with a plasmid in TB + antibiotic',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',0.01,'return','',4,NULL,'DFO',NULL,NULL),(15,'Transformed E. coli Aliquot','An aliquot containing transformed E. coli - usually in a 1.5 mL tube',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Plasmid',0.01,'dispose','',4,NULL,'',NULL,NULL),(16,'Primer Aliquot','Primers at low concentration (10uM) for every day use',0,1,'sample_container','No safety information','No cleanup information','{ \"measure\": { \"type\": \"concentration\", \"unit\": \"micromolar\" } }','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Primer',0.01,'return','',5,NULL,'M20',NULL,NULL),(17,'Primer Stock','rehydrated primer in tube from IDT at 100uM',0,1,'sample_container','No safety information','No cleanup information','{ \"measure\": { \"type\": \"concentration\", \"unit\": \"micromolar\" } }','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Primer',0.01,'return','',5,NULL,'M20',NULL,NULL),(18,'Yeast Glycerol Stock','A 1.8mL culture of half saturated yeast overnight and half 50% glycerol stored in the -80C freezer',0,1,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Yeast Strain',5,'return','',7,NULL,'M80',NULL,NULL),(19,'Yeast Overnight Suspension','Yeast Overnight Suspension',0,1000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Yeast Strain',1,'query','',7,NULL,'DFO',NULL,NULL),(20,'Yeast Plate','Yeast Plate',0,100000,'sample_container','No safety information','No cleanup information','No data','No vendor information','2020-03-24 15:41:54','2020-03-24 15:41:54','Yeast Strain',1,'return','',7,NULL,'DFP',NULL,NULL);
/*!40000 ALTER TABLE `object_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `operation_types`
--

DROP TABLE IF EXISTS `operation_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `operation_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `category` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `deployed` tinyint(1) DEFAULT NULL,
  `on_the_fly` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `index_operation_types_on_category_and_name` (`category`,`name`)
) ENGINE=InnoDB AUTO_INCREMENT=25 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `operation_types`
--

LOCK TABLES `operation_types` WRITE;
/*!40000 ALTER TABLE `operation_types` DISABLE KEYS */;
INSERT INTO `operation_types` VALUES (1,'Direct Purchase','Misc.',1,1,'2020-01-24 16:50:00','2020-01-24 16:50:00'),(2,'C_DNA_QC','RNA_Seq',1,0,'2020-03-19 17:30:41','2020-03-19 19:30:24'),(3,'Normalization Pooling','RNA_Seq',1,0,'2020-03-19 17:30:41','2020-03-19 19:30:27'),(4,'RNA_Prep','RNA_Seq',1,0,'2020-03-19 17:30:41','2020-03-19 19:30:32'),(5,'RNA_QC','RNA_Seq',1,0,'2020-03-19 17:30:41','2020-03-19 19:30:36'),(6,'Make Adapter Plate','RNA_Seq',0,NULL,'2020-03-19 19:32:57','2020-03-24 15:14:46'),(7,'Blank Block','Control Blocks',0,0,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(8,'Canceled','Control Blocks',0,0,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(9,'Delay','Control Blocks',0,0,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(10,'Mark For Discard','Control Blocks',0,0,'2020-03-24 15:41:54','2020-03-24 15:41:54'),(11,'Pass','Control Blocks',0,0,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(12,'Pick Any','Control Blocks',0,0,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(13,'Receive from Operation','Control Blocks',0,0,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(14,'Send Email','Control Blocks',0,0,'2020-03-24 15:41:55','2020-03-24 15:41:55'),(15,'Wait For All','Control Blocks',0,0,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(16,'Wait for User Input','Control Blocks',0,0,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(17,'[ADV USERS ONLY] Associate to Item','Control Blocks',0,0,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(18,'[ADV USERS ONLY] Case Block','Control Blocks',0,0,'2020-03-24 15:41:56','2020-03-24 15:41:56'),(19,'[ADV USERS ONLY] Listen to Channel','Control Blocks',0,0,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(20,'[ADV USERS ONLY] Respond to Key-Value','Control Blocks',0,0,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(21,'[ADV USERS ONLY] Response Block','Control Blocks',0,0,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(22,'[ADV USERS ONLY] Send to Channel','Control Blocks',0,0,'2020-03-24 15:41:57','2020-03-24 15:41:57'),(23,'Listen To Channel','Control Blocks',1,NULL,'2020-03-24 15:49:42','2020-03-24 15:51:44'),(24,'Send to Channel','Control Blocks',1,NULL,'2020-03-24 15:59:46','2020-03-24 15:59:51');
/*!40000 ALTER TABLE `operation_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `operations`
--

DROP TABLE IF EXISTS `operations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `operations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `operation_type_id` int(11) DEFAULT NULL,
  `status` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `x` float DEFAULT NULL,
  `y` float DEFAULT NULL,
  `parent_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_operations_on_operation_type_id` (`operation_type_id`),
  KEY `index_operations_on_user_id` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=125 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `operations`
--

LOCK TABLES `operations` WRITE;
/*!40000 ALTER TABLE `operations` DISABLE KEYS */;
INSERT INTO `operations` VALUES (5,6,'error',1,'2020-03-19 20:07:00','2020-03-19 20:36:28',168,352,0),(6,4,'done',1,'2020-03-19 20:07:00','2020-03-24 16:07:02',176,224,0),(7,2,'waiting',1,'2020-03-19 20:17:57','2020-03-19 20:20:35',280,136,0),(8,3,'waiting',1,'2020-03-19 20:17:57','2020-03-19 20:20:35',80,136,0),(9,5,'done',1,'2020-03-19 20:17:57','2020-03-23 20:11:36',400,224,0),(39,4,'done',1,'2020-03-20 16:58:17','2020-03-24 16:06:52',104,240,0),(40,2,'error',1,'2020-03-20 16:58:17','2020-03-24 16:07:16',280,56,0),(41,3,'error',1,'2020-03-20 16:58:17','2020-03-24 16:16:56',80,56,0),(42,5,'done',1,'2020-03-20 16:58:17','2020-03-24 15:24:11',328,240,0),(82,4,'done',1,'2020-03-24 16:08:07','2020-03-24 16:17:59',104,240,0),(83,2,'done',1,'2020-03-24 16:08:07','2020-03-24 17:57:20',368,72,0),(84,3,'done',1,'2020-03-24 16:08:07','2020-03-24 18:21:33',104,56,0),(85,5,'done',1,'2020-03-24 16:08:07','2020-03-24 16:17:17',272,240,0),(100,2,'pending',1,'2020-03-24 18:32:04','2020-03-24 19:02:17',280,136,0),(101,3,'pending',1,'2020-03-24 18:32:04','2020-03-24 19:02:17',80,136,0),(103,5,'done',1,'2020-03-24 18:32:57','2020-03-24 19:07:43',304,448,0),(104,4,'waiting',1,'2020-03-24 18:32:57','2020-03-24 19:02:17',80,200,0),(105,24,'done',1,'2020-03-24 18:32:57','2020-03-24 19:08:21',312,384,0),(106,23,'delayed',1,'2020-03-24 18:32:57','2020-03-24 19:09:18',88,296,0),(107,2,'waiting',1,'2020-03-24 19:14:18','2020-03-24 19:15:29',280,136,0),(108,3,'waiting',1,'2020-03-24 19:14:18','2020-03-24 19:15:29',80,136,0),(109,5,'done',1,'2020-03-24 19:14:18','2020-03-24 19:16:05',304,448,0),(110,4,'waiting',1,'2020-03-24 19:14:18','2020-03-24 19:15:29',80,200,0),(111,24,'done',1,'2020-03-24 19:14:18','2020-03-24 19:16:27',312,384,0),(112,23,'delayed',1,'2020-03-24 19:14:18','2020-03-24 19:15:29',88,296,0),(113,2,'waiting',1,'2020-03-24 19:58:28','2020-03-24 19:58:35',280,136,0),(114,3,'waiting',1,'2020-03-24 19:58:28','2020-03-24 19:58:35',80,136,0),(115,5,'done',1,'2020-03-24 19:58:29','2020-03-24 19:59:28',304,448,0),(116,4,'waiting',1,'2020-03-24 19:58:29','2020-03-24 19:58:35',80,200,0),(117,24,'done',1,'2020-03-24 19:58:29','2020-03-24 19:59:44',312,384,0),(118,23,'delayed',1,'2020-03-24 19:58:29','2020-03-24 19:58:35',88,296,0),(119,2,'waiting',1,'2020-03-24 20:01:50','2020-03-24 20:02:35',280,136,0),(120,3,'waiting',1,'2020-03-24 20:01:50','2020-03-24 20:02:35',80,136,0),(121,5,'done',1,'2020-03-24 20:01:50','2020-03-24 20:03:15',304,448,0),(122,4,'waiting',1,'2020-03-24 20:01:50','2020-03-24 20:02:35',80,200,0),(123,24,'done',1,'2020-03-24 20:01:50','2020-03-24 20:03:54',312,384,0),(124,23,'done',1,'2020-03-24 20:01:50','2020-03-24 20:10:28',88,296,0);
/*!40000 ALTER TABLE `operations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `parameters`
--

DROP TABLE IF EXISTS `parameters`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `parameters` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `key` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `value` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` text COLLATE utf8_unicode_ci,
  `user_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=21 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `parameters`
--

LOCK TABLES `parameters` WRITE;
/*!40000 ALTER TABLE `parameters` DISABLE KEYS */;
INSERT INTO `parameters` VALUES (1,'email','joe@nasa.org','2018-10-31 22:44:56','2018-10-31 22:44:56',NULL,1),(2,'phone','8675309','2018-10-31 22:44:56','2018-10-31 22:44:56',NULL,1),(3,'biofab',NULL,'2018-10-31 22:44:56','2018-10-31 22:44:56',NULL,1),(4,'aquarium',NULL,'2018-10-31 22:44:56','2018-10-31 22:44:56',NULL,1),(5,'Make new samples private',NULL,'2018-10-31 22:44:56','2018-10-31 22:44:56',NULL,1),(6,'Lab Name',NULL,'2018-10-31 22:44:57','2018-10-31 22:44:57',NULL,1),(7,'email','joe@nasa.org','2018-10-31 22:45:00','2018-10-31 22:45:00',NULL,1),(8,'phone','8675309','2018-10-31 22:45:00','2018-10-31 22:45:00',NULL,1),(9,'biofab','true','2018-10-31 22:45:00','2018-10-31 22:45:00',NULL,1),(10,'aquarium','true','2018-10-31 22:45:00','2018-10-31 22:45:02',NULL,1),(11,'Make new samples private',NULL,'2018-10-31 22:45:00','2018-10-31 22:45:00',NULL,1),(12,'Lab Name',NULL,'2018-10-31 22:45:00','2018-10-31 22:45:00',NULL,1),(19,'labor rate','0.0','2020-03-19 20:20:33','2020-03-19 20:20:33','Edit me',NULL),(20,'markup rate','0.0','2020-03-19 20:20:33','2020-03-19 20:20:33','Edit me',NULL);
/*!40000 ALTER TABLE `parameters` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `part_associations`
--

DROP TABLE IF EXISTS `part_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `part_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `part_id` int(11) DEFAULT NULL,
  `collection_id` int(11) DEFAULT NULL,
  `row` int(11) DEFAULT NULL,
  `column` int(11) DEFAULT NULL,
  `created_at` datetime DEFAULT NULL,
  `updated_at` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `index_part_associations_on_collection_id_and_row_and_column` (`collection_id`,`row`,`column`)
) ENGINE=InnoDB AUTO_INCREMENT=866 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `part_associations`
--

LOCK TABLES `part_associations` WRITE;
/*!40000 ALTER TABLE `part_associations` DISABLE KEYS */;
INSERT INTO `part_associations` VALUES (1,4,3,0,0,'2020-03-19 18:40:13','2020-03-19 18:40:13'),(2,5,3,1,0,'2020-03-19 18:40:23','2020-03-19 18:40:23'),(3,6,3,2,0,'2020-03-19 18:40:35','2020-03-19 18:40:35'),(4,7,3,3,0,'2020-03-19 18:40:43','2020-03-19 18:40:43'),(5,8,3,4,0,'2020-03-19 18:40:52','2020-03-19 18:40:52'),(6,9,3,5,0,'2020-03-19 18:40:58','2020-03-19 18:40:58'),(7,10,3,6,0,'2020-03-19 18:41:05','2020-03-19 18:41:05'),(8,11,3,7,0,'2020-03-19 18:41:17','2020-03-19 18:41:17'),(9,12,3,0,1,'2020-03-19 18:41:23','2020-03-19 18:41:23'),(10,13,3,1,1,'2020-03-19 18:41:33','2020-03-19 18:41:33'),(11,14,3,2,1,'2020-03-19 18:41:41','2020-03-19 18:41:41'),(12,15,3,3,1,'2020-03-19 18:41:46','2020-03-19 18:41:46'),(13,16,3,4,1,'2020-03-19 18:41:53','2020-03-19 18:41:53'),(14,17,3,5,1,'2020-03-19 18:42:05','2020-03-19 18:42:05'),(15,18,3,6,1,'2020-03-19 18:42:11','2020-03-19 18:42:11'),(16,19,3,7,1,'2020-03-19 18:42:16','2020-03-19 18:42:16'),(17,20,3,0,2,'2020-03-19 18:42:22','2020-03-19 18:42:22'),(18,21,3,1,2,'2020-03-19 18:42:40','2020-03-19 18:42:40'),(19,22,3,2,2,'2020-03-19 18:42:48','2020-03-19 18:42:48'),(20,23,3,3,2,'2020-03-19 18:42:57','2020-03-19 18:42:57'),(21,24,3,4,2,'2020-03-19 18:43:03','2020-03-19 18:43:03'),(22,25,3,5,2,'2020-03-19 18:43:10','2020-03-19 18:43:10'),(23,26,3,6,2,'2020-03-19 18:43:20','2020-03-19 18:43:20'),(24,27,3,7,2,'2020-03-19 18:43:29','2020-03-19 18:43:29'),(25,28,3,0,3,'2020-03-19 18:43:37','2020-03-19 18:43:37'),(26,29,3,1,3,'2020-03-19 18:43:44','2020-03-19 18:43:44'),(27,30,3,2,3,'2020-03-19 18:43:57','2020-03-19 18:43:57'),(28,31,3,3,3,'2020-03-19 18:45:26','2020-03-19 18:45:26'),(29,32,3,4,3,'2020-03-19 18:45:35','2020-03-19 18:45:35'),(30,33,3,5,3,'2020-03-19 18:45:57','2020-03-19 18:45:57'),(31,34,3,6,3,'2020-03-19 18:46:06','2020-03-19 18:46:06'),(32,35,3,7,3,'2020-03-19 18:46:14','2020-03-19 18:46:14'),(33,36,3,0,4,'2020-03-19 18:46:22','2020-03-19 18:46:22'),(34,37,3,1,4,'2020-03-19 18:46:30','2020-03-19 18:46:30'),(35,38,3,2,4,'2020-03-19 18:46:38','2020-03-19 18:46:38'),(36,39,3,3,4,'2020-03-19 18:46:48','2020-03-19 18:46:48'),(37,40,3,4,4,'2020-03-19 18:46:53','2020-03-19 18:46:53'),(38,41,3,5,4,'2020-03-19 18:47:03','2020-03-19 18:47:03'),(39,42,3,6,4,'2020-03-19 18:47:12','2020-03-19 18:47:12'),(40,43,3,7,4,'2020-03-19 18:47:21','2020-03-19 18:47:21'),(41,44,3,0,5,'2020-03-19 18:47:28','2020-03-19 18:47:28'),(42,45,3,1,5,'2020-03-19 18:47:48','2020-03-19 18:47:48'),(43,46,3,2,5,'2020-03-19 18:48:02','2020-03-19 18:48:02'),(44,47,3,3,5,'2020-03-19 18:48:10','2020-03-19 18:48:10'),(45,48,3,4,5,'2020-03-19 18:48:19','2020-03-19 18:48:19'),(46,49,3,5,5,'2020-03-19 18:48:26','2020-03-19 18:48:26'),(47,50,3,6,5,'2020-03-19 18:48:33','2020-03-19 18:48:33'),(48,51,3,7,5,'2020-03-19 18:48:44','2020-03-19 18:48:44'),(49,52,3,0,6,'2020-03-19 18:49:36','2020-03-19 18:49:36'),(50,53,3,1,6,'2020-03-19 18:49:45','2020-03-19 18:49:45'),(51,54,3,2,6,'2020-03-19 18:49:51','2020-03-19 18:49:51'),(52,55,3,3,6,'2020-03-19 18:49:57','2020-03-19 18:49:57'),(53,56,3,4,6,'2020-03-19 18:51:12','2020-03-19 18:51:12'),(54,57,3,5,6,'2020-03-19 18:51:24','2020-03-19 18:51:24'),(55,58,3,6,6,'2020-03-19 18:53:34','2020-03-19 18:53:34'),(56,59,3,7,6,'2020-03-19 18:53:41','2020-03-19 18:53:41'),(57,60,3,0,7,'2020-03-19 18:54:44','2020-03-19 18:54:44'),(58,61,3,1,7,'2020-03-19 18:54:49','2020-03-19 18:54:49'),(59,62,3,2,7,'2020-03-19 18:54:57','2020-03-19 18:54:57'),(60,63,3,3,7,'2020-03-19 18:55:04','2020-03-19 18:55:04'),(61,64,3,4,7,'2020-03-19 18:55:11','2020-03-19 18:55:11'),(62,65,3,5,7,'2020-03-19 18:55:18','2020-03-19 18:55:18'),(63,66,3,6,7,'2020-03-19 18:55:23','2020-03-19 18:55:23'),(64,67,3,7,7,'2020-03-19 18:55:33','2020-03-19 18:55:33'),(65,68,3,0,8,'2020-03-19 18:55:40','2020-03-19 18:55:40'),(66,69,3,1,8,'2020-03-19 18:55:49','2020-03-19 18:55:49'),(67,70,3,2,8,'2020-03-19 18:55:55','2020-03-19 18:55:55'),(68,71,3,3,8,'2020-03-19 18:56:03','2020-03-19 18:56:03'),(69,72,3,4,8,'2020-03-19 18:56:09','2020-03-19 18:56:09'),(70,73,3,5,8,'2020-03-19 18:56:17','2020-03-19 18:56:17'),(71,74,3,6,8,'2020-03-19 18:56:25','2020-03-19 18:56:25'),(72,75,3,7,8,'2020-03-19 18:56:30','2020-03-19 18:56:30'),(73,76,3,0,9,'2020-03-19 18:56:38','2020-03-19 18:56:38'),(74,77,3,1,9,'2020-03-19 18:57:27','2020-03-19 18:57:27'),(75,78,3,2,9,'2020-03-19 18:57:34','2020-03-19 18:57:34'),(76,79,3,3,9,'2020-03-19 18:57:42','2020-03-19 18:57:42'),(77,80,3,4,9,'2020-03-19 18:57:51','2020-03-19 18:57:51'),(78,81,3,5,9,'2020-03-19 18:57:59','2020-03-19 18:57:59'),(79,82,3,6,9,'2020-03-19 18:58:09','2020-03-19 18:58:09'),(80,83,3,7,9,'2020-03-19 18:58:33','2020-03-19 18:58:33'),(81,84,3,0,10,'2020-03-19 18:58:46','2020-03-19 18:58:46'),(82,85,3,1,10,'2020-03-19 18:58:57','2020-03-19 18:58:57'),(83,86,3,2,10,'2020-03-19 18:59:09','2020-03-19 18:59:09'),(84,87,3,3,10,'2020-03-19 18:59:15','2020-03-19 18:59:15'),(85,88,3,4,10,'2020-03-19 18:59:22','2020-03-19 18:59:22'),(86,89,3,5,10,'2020-03-19 18:59:29','2020-03-19 18:59:29'),(87,90,3,6,10,'2020-03-19 18:59:36','2020-03-19 18:59:36'),(88,91,3,7,10,'2020-03-19 18:59:43','2020-03-19 18:59:43'),(89,92,3,0,11,'2020-03-19 18:59:49','2020-03-19 18:59:49'),(90,93,3,1,11,'2020-03-19 18:59:58','2020-03-19 18:59:58'),(91,94,3,2,11,'2020-03-19 19:00:04','2020-03-19 19:00:04'),(92,95,3,3,11,'2020-03-19 19:00:11','2020-03-19 19:00:11'),(93,96,3,4,11,'2020-03-19 19:00:17','2020-03-19 19:00:17'),(94,97,3,5,11,'2020-03-19 19:05:08','2020-03-19 19:05:08'),(95,98,3,6,11,'2020-03-19 19:05:16','2020-03-19 19:05:16'),(96,99,3,7,11,'2020-03-19 19:05:23','2020-03-19 19:05:23'),(97,101,100,0,0,'2020-03-19 19:05:49','2020-03-19 19:05:49'),(98,102,100,1,0,'2020-03-19 19:06:51','2020-03-19 19:06:51'),(99,103,100,2,0,'2020-03-19 19:07:00','2020-03-19 19:07:00'),(100,104,100,3,0,'2020-03-19 19:07:10','2020-03-19 19:07:10'),(101,105,100,4,0,'2020-03-19 19:07:18','2020-03-19 19:07:18'),(102,106,100,5,0,'2020-03-19 19:07:24','2020-03-19 19:07:24'),(103,107,100,6,0,'2020-03-19 19:07:30','2020-03-19 19:07:30'),(104,108,100,7,0,'2020-03-19 19:07:37','2020-03-19 19:07:37'),(105,109,100,0,1,'2020-03-19 19:07:49','2020-03-19 19:07:49'),(106,110,100,1,1,'2020-03-19 19:07:59','2020-03-19 19:07:59'),(107,111,100,2,1,'2020-03-19 19:08:08','2020-03-19 19:08:08'),(108,112,100,3,1,'2020-03-19 19:08:15','2020-03-19 19:08:15'),(109,113,100,4,1,'2020-03-19 19:08:21','2020-03-19 19:08:21'),(110,114,100,5,1,'2020-03-19 19:08:27','2020-03-19 19:08:27'),(111,115,100,6,1,'2020-03-19 19:08:33','2020-03-19 19:08:33'),(112,116,100,7,1,'2020-03-19 19:08:41','2020-03-19 19:08:41'),(113,117,100,0,2,'2020-03-19 19:08:49','2020-03-19 19:08:49'),(114,118,100,1,2,'2020-03-19 19:08:55','2020-03-19 19:08:55'),(115,119,100,2,2,'2020-03-19 19:09:01','2020-03-19 19:09:01'),(116,120,100,3,2,'2020-03-19 19:09:08','2020-03-19 19:09:08'),(117,121,100,4,2,'2020-03-19 19:09:17','2020-03-19 19:09:17'),(118,122,100,5,2,'2020-03-19 19:09:23','2020-03-19 19:09:23'),(119,123,100,6,2,'2020-03-19 19:09:31','2020-03-19 19:09:31'),(120,124,100,7,2,'2020-03-19 19:09:37','2020-03-19 19:09:37'),(121,125,100,0,3,'2020-03-19 19:09:47','2020-03-19 19:09:47'),(122,126,100,1,3,'2020-03-19 19:09:54','2020-03-19 19:09:54'),(123,127,100,2,3,'2020-03-19 19:10:02','2020-03-19 19:10:02'),(124,128,100,3,3,'2020-03-19 19:10:09','2020-03-19 19:10:09'),(125,129,100,4,3,'2020-03-19 19:10:15','2020-03-19 19:10:15'),(126,130,100,5,3,'2020-03-19 19:10:22','2020-03-19 19:10:22'),(127,131,100,6,3,'2020-03-19 19:10:28','2020-03-19 19:10:28'),(128,132,100,7,3,'2020-03-19 19:10:34','2020-03-19 19:10:34'),(129,133,100,0,4,'2020-03-19 19:10:40','2020-03-19 19:10:40'),(130,134,100,1,4,'2020-03-19 19:10:57','2020-03-19 19:10:57'),(131,135,100,2,4,'2020-03-19 19:11:03','2020-03-19 19:11:03'),(132,136,100,3,4,'2020-03-19 19:11:12','2020-03-19 19:11:12'),(133,137,100,4,4,'2020-03-19 19:11:18','2020-03-19 19:11:18'),(134,138,100,5,4,'2020-03-19 19:11:26','2020-03-19 19:11:26'),(135,139,100,6,4,'2020-03-19 19:11:32','2020-03-19 19:11:32'),(136,140,100,7,4,'2020-03-19 19:11:37','2020-03-19 19:11:37'),(137,141,100,0,5,'2020-03-19 19:11:44','2020-03-19 19:11:44'),(138,142,100,1,5,'2020-03-19 19:11:51','2020-03-19 19:11:51'),(139,143,100,2,5,'2020-03-19 19:11:57','2020-03-19 19:11:57'),(140,144,100,3,5,'2020-03-19 19:12:03','2020-03-19 19:12:03'),(141,145,100,4,5,'2020-03-19 19:12:09','2020-03-19 19:12:09'),(142,146,100,5,5,'2020-03-19 19:12:16','2020-03-19 19:12:16'),(143,147,100,6,5,'2020-03-19 19:12:22','2020-03-19 19:12:22'),(144,148,100,7,5,'2020-03-19 19:12:29','2020-03-19 19:12:29'),(145,149,100,0,6,'2020-03-19 19:12:35','2020-03-19 19:12:35'),(146,150,100,1,6,'2020-03-19 19:12:41','2020-03-19 19:12:41'),(147,151,100,2,6,'2020-03-19 19:12:48','2020-03-19 19:12:48'),(148,152,100,3,6,'2020-03-19 19:12:54','2020-03-19 19:12:54'),(149,153,100,4,6,'2020-03-19 19:13:01','2020-03-19 19:13:01'),(150,154,100,5,6,'2020-03-19 19:13:08','2020-03-19 19:13:08'),(151,155,100,6,6,'2020-03-19 19:13:13','2020-03-19 19:13:13'),(152,156,100,7,6,'2020-03-19 19:13:22','2020-03-19 19:13:22'),(153,157,100,0,7,'2020-03-19 19:13:27','2020-03-19 19:13:27'),(154,158,100,1,7,'2020-03-19 19:13:34','2020-03-19 19:13:34'),(155,159,100,2,7,'2020-03-19 19:13:39','2020-03-19 19:13:39'),(156,160,100,3,7,'2020-03-19 19:13:46','2020-03-19 19:13:46'),(157,161,100,4,7,'2020-03-19 19:14:06','2020-03-19 19:14:06'),(158,162,100,5,7,'2020-03-19 19:14:13','2020-03-19 19:14:13'),(159,163,100,6,7,'2020-03-19 19:14:22','2020-03-19 19:14:22'),(160,164,100,7,7,'2020-03-19 19:14:29','2020-03-19 19:14:29'),(161,165,100,0,8,'2020-03-19 19:14:35','2020-03-19 19:14:35'),(162,166,100,1,8,'2020-03-19 19:14:41','2020-03-19 19:14:41'),(163,167,100,2,8,'2020-03-19 19:14:49','2020-03-19 19:14:49'),(164,168,100,3,8,'2020-03-19 19:14:56','2020-03-19 19:14:56'),(165,169,100,4,8,'2020-03-19 19:15:02','2020-03-19 19:15:02'),(166,170,100,5,8,'2020-03-19 19:15:08','2020-03-19 19:15:08'),(167,171,100,6,8,'2020-03-19 19:15:15','2020-03-19 19:15:15'),(168,172,100,7,8,'2020-03-19 19:15:21','2020-03-19 19:15:21'),(169,173,100,0,9,'2020-03-19 19:15:28','2020-03-19 19:15:28'),(170,174,100,1,9,'2020-03-19 19:15:34','2020-03-19 19:15:34'),(171,175,100,2,9,'2020-03-19 19:15:40','2020-03-19 19:15:40'),(172,176,100,3,9,'2020-03-19 19:15:47','2020-03-19 19:15:47'),(173,177,100,4,9,'2020-03-19 19:15:56','2020-03-19 19:15:56'),(174,178,100,5,9,'2020-03-19 19:16:08','2020-03-19 19:16:08'),(175,179,100,6,9,'2020-03-19 19:16:15','2020-03-19 19:16:15'),(176,180,100,7,9,'2020-03-19 19:16:22','2020-03-19 19:16:22'),(177,181,100,0,10,'2020-03-19 19:16:31','2020-03-19 19:16:31'),(178,182,100,1,10,'2020-03-19 19:16:40','2020-03-19 19:16:40'),(179,183,100,2,10,'2020-03-19 19:16:47','2020-03-19 19:16:47'),(180,184,100,3,10,'2020-03-19 19:16:53','2020-03-19 19:16:53'),(181,185,100,4,10,'2020-03-19 19:16:59','2020-03-19 19:16:59'),(182,186,100,5,10,'2020-03-19 19:17:47','2020-03-19 19:17:47'),(183,187,100,6,10,'2020-03-19 19:17:56','2020-03-19 19:17:56'),(184,188,100,7,10,'2020-03-19 19:18:04','2020-03-19 19:18:04'),(185,189,100,0,11,'2020-03-19 19:18:11','2020-03-19 19:18:11'),(186,190,100,1,11,'2020-03-19 19:18:18','2020-03-19 19:18:18'),(187,191,100,2,11,'2020-03-19 19:18:25','2020-03-19 19:18:25'),(188,192,100,3,11,'2020-03-19 19:18:32','2020-03-19 19:18:32'),(189,193,100,4,11,'2020-03-19 19:18:39','2020-03-19 19:18:39'),(190,194,100,5,11,'2020-03-19 19:18:47','2020-03-19 19:18:47'),(191,195,100,6,11,'2020-03-19 19:19:24','2020-03-19 19:19:24'),(192,196,100,7,11,'2020-03-19 19:20:22','2020-03-19 19:20:22'),(193,201,200,0,0,'2020-03-19 20:07:20','2020-03-19 20:07:20'),(194,202,200,1,0,'2020-03-19 20:07:27','2020-03-19 20:07:27'),(195,217,200,2,0,'2020-03-20 17:11:36','2020-03-20 17:11:36'),(196,218,200,3,0,'2020-03-20 18:41:07','2020-03-20 18:41:07'),(197,219,200,4,0,'2020-03-20 18:41:13','2020-03-20 18:41:13'),(198,220,200,5,0,'2020-03-20 18:41:18','2020-03-20 18:41:18'),(199,221,200,6,0,'2020-03-20 18:41:23','2020-03-20 18:41:23'),(200,222,200,7,0,'2020-03-20 18:41:49','2020-03-20 18:41:49'),(222,269,268,0,0,'2020-03-23 20:11:12','2020-03-23 20:11:12'),(223,270,268,0,1,'2020-03-23 20:11:12','2020-03-23 20:11:12'),(266,365,364,0,0,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(267,366,364,0,1,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(268,367,364,0,2,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(269,368,364,0,3,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(270,369,364,0,4,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(271,370,364,0,5,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(272,371,364,0,6,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(273,372,364,0,7,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(274,373,364,0,8,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(275,374,364,0,9,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(276,375,364,0,10,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(277,376,364,0,11,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(278,377,364,1,0,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(279,378,364,1,1,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(280,379,364,1,2,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(281,380,364,1,3,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(282,381,364,1,4,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(283,382,364,1,5,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(284,383,364,1,6,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(285,384,364,1,7,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(286,385,364,1,8,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(287,386,364,1,9,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(288,387,364,1,10,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(289,388,364,1,11,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(290,389,364,2,0,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(291,390,364,2,1,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(292,391,364,2,2,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(293,392,364,2,3,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(294,393,364,2,4,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(295,394,364,2,5,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(296,395,364,2,6,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(297,396,364,2,7,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(298,397,364,2,8,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(299,398,364,2,9,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(300,399,364,2,10,'2020-03-23 23:25:15','2020-03-23 23:25:15'),(301,400,364,2,11,'2020-03-23 23:25:16','2020-03-23 23:25:16'),(302,401,364,3,0,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(303,402,364,3,1,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(304,403,364,3,2,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(305,404,364,3,3,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(306,405,364,3,4,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(307,406,364,3,5,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(308,407,364,3,6,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(309,408,364,3,7,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(310,409,364,3,8,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(311,410,364,3,9,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(312,411,364,3,10,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(313,412,364,3,11,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(314,413,364,4,0,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(315,414,364,4,1,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(316,415,364,4,2,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(317,416,364,4,3,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(318,417,364,4,4,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(319,418,364,4,5,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(320,419,364,4,6,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(321,420,364,4,7,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(322,421,364,4,8,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(323,422,364,4,9,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(324,423,364,4,10,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(325,424,364,4,11,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(326,425,364,5,0,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(327,426,364,5,1,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(328,427,364,5,2,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(329,428,364,5,3,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(330,429,364,5,4,'2020-03-23 23:25:59','2020-03-23 23:25:59'),(331,430,363,0,0,'2020-03-23 23:26:10','2020-03-23 23:26:10'),(332,431,363,0,1,'2020-03-23 23:26:10','2020-03-23 23:26:10'),(333,434,433,0,0,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(334,435,433,0,1,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(335,436,433,0,2,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(336,437,433,0,3,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(337,438,433,0,4,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(338,439,433,0,5,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(339,440,433,0,6,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(340,441,433,0,7,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(341,442,433,0,8,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(342,443,433,0,9,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(343,444,433,0,10,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(344,445,433,0,11,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(345,446,433,1,0,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(346,447,433,1,1,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(347,448,433,1,2,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(348,449,433,1,3,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(349,450,433,1,4,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(350,451,433,1,5,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(351,452,433,1,6,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(352,453,433,1,7,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(353,454,433,1,8,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(354,455,433,1,9,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(355,456,433,1,10,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(356,457,433,1,11,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(357,458,433,2,0,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(358,459,433,2,1,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(359,460,433,2,2,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(360,461,433,2,3,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(361,462,433,2,4,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(362,463,433,2,5,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(363,464,433,2,6,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(364,465,433,2,7,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(365,466,433,2,8,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(366,467,433,2,9,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(367,468,433,2,10,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(368,469,433,2,11,'2020-03-23 23:30:03','2020-03-23 23:30:03'),(369,470,433,3,0,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(370,471,433,3,1,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(371,472,433,3,2,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(372,473,433,3,3,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(373,474,433,3,4,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(374,475,433,3,5,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(375,476,433,3,6,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(376,477,433,3,7,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(377,478,433,3,8,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(378,479,433,3,9,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(379,480,433,3,10,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(380,481,433,3,11,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(381,482,433,4,0,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(382,483,433,4,1,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(383,484,433,4,2,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(384,485,433,4,3,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(385,486,433,4,4,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(386,487,433,4,5,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(387,488,433,4,6,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(388,489,433,4,7,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(389,490,433,4,8,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(390,491,433,4,9,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(391,492,433,4,10,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(392,493,433,4,11,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(393,494,433,5,0,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(394,495,433,5,1,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(395,496,433,5,2,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(396,497,433,5,3,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(397,498,433,5,4,'2020-03-23 23:32:14','2020-03-23 23:32:14'),(398,499,432,0,0,'2020-03-23 23:32:19','2020-03-23 23:32:19'),(399,500,432,0,1,'2020-03-23 23:32:19','2020-03-23 23:32:19'),(400,503,502,0,0,'2020-03-23 23:32:57','2020-03-23 23:32:57'),(401,504,502,0,1,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(402,505,502,0,2,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(403,506,502,0,3,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(404,507,502,0,4,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(405,508,502,0,5,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(406,509,502,0,6,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(407,510,502,0,7,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(408,511,502,0,8,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(409,512,502,0,9,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(410,513,502,0,10,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(411,514,502,0,11,'2020-03-23 23:32:58','2020-03-23 23:32:58'),(412,517,516,0,0,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(413,518,516,0,1,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(414,519,516,0,2,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(415,520,516,0,3,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(416,521,516,0,4,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(417,522,516,0,5,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(418,523,516,0,6,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(419,524,516,0,7,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(420,525,516,0,8,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(421,526,516,0,9,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(422,527,516,0,10,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(423,528,516,0,11,'2020-03-23 23:34:57','2020-03-23 23:34:57'),(424,531,530,0,0,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(425,532,530,0,1,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(426,533,530,0,2,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(427,534,530,0,3,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(428,535,530,0,4,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(429,536,530,0,5,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(430,537,530,0,6,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(431,538,530,0,7,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(432,539,530,0,8,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(433,540,530,0,9,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(434,541,530,0,10,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(435,542,530,0,11,'2020-03-23 23:46:04','2020-03-23 23:46:04'),(436,549,548,0,0,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(437,550,548,0,1,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(438,551,548,0,2,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(439,552,548,0,3,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(440,553,548,0,4,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(441,554,548,0,5,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(442,555,548,0,6,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(443,556,548,0,7,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(444,557,548,0,8,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(445,558,548,0,9,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(446,559,548,0,10,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(447,560,548,0,11,'2020-03-23 23:53:52','2020-03-23 23:53:52'),(448,561,547,0,0,'2020-03-23 23:53:58','2020-03-23 23:53:58'),(449,562,547,0,1,'2020-03-23 23:53:58','2020-03-23 23:53:58'),(450,571,570,0,0,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(451,572,570,0,1,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(452,573,570,0,2,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(453,574,570,0,3,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(454,575,570,0,4,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(455,576,570,0,5,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(456,577,570,0,6,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(457,578,570,0,7,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(458,579,570,0,8,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(459,580,570,0,9,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(460,581,570,0,10,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(461,582,570,0,11,'2020-03-23 23:59:08','2020-03-23 23:59:08'),(462,585,584,0,0,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(463,586,584,0,1,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(464,587,584,0,2,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(465,588,584,0,3,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(466,589,584,0,4,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(467,590,584,0,5,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(468,591,584,0,6,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(469,592,584,0,7,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(470,593,584,0,8,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(471,594,584,0,9,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(472,595,584,0,10,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(473,596,584,0,11,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(474,597,584,1,0,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(475,598,584,1,1,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(476,599,584,1,2,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(477,600,584,1,3,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(478,601,584,1,4,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(479,602,584,1,5,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(480,603,584,1,6,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(481,604,584,1,7,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(482,605,584,1,8,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(483,606,584,1,9,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(484,607,584,1,10,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(485,608,584,1,11,'2020-03-24 00:00:00','2020-03-24 00:00:00'),(486,611,610,0,0,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(487,612,610,0,1,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(488,613,610,0,2,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(489,614,610,0,3,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(490,615,610,0,4,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(491,616,610,0,5,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(492,617,610,0,6,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(493,618,610,0,7,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(494,619,610,0,8,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(495,620,610,0,9,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(496,621,610,0,10,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(497,622,610,0,11,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(498,623,610,1,0,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(499,624,610,1,1,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(500,625,610,1,2,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(501,626,610,1,3,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(502,627,610,1,4,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(503,628,610,1,5,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(504,629,610,1,6,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(505,630,610,1,7,'2020-03-24 00:01:23','2020-03-24 00:01:23'),(506,631,610,1,8,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(507,632,610,1,9,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(508,633,610,1,10,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(509,634,610,1,11,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(510,635,610,2,0,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(511,636,610,2,1,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(512,637,610,2,2,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(513,638,610,2,3,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(514,639,610,2,4,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(515,640,610,2,5,'2020-03-24 00:01:24','2020-03-24 00:01:24'),(516,641,610,2,6,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(517,642,610,2,7,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(518,643,610,2,8,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(519,644,610,2,9,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(520,645,610,2,10,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(521,646,610,2,11,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(522,647,610,3,0,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(523,648,610,3,1,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(524,649,610,3,2,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(525,650,610,3,3,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(526,651,610,3,4,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(527,652,610,3,5,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(528,653,610,3,6,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(529,654,610,3,7,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(530,655,610,3,8,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(531,656,610,3,9,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(532,657,610,3,10,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(533,658,610,3,11,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(534,659,610,4,0,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(535,660,610,4,1,'2020-03-24 00:01:39','2020-03-24 00:01:39'),(536,661,609,0,0,'2020-03-24 00:01:46','2020-03-24 00:01:46'),(537,662,609,0,1,'2020-03-24 00:01:46','2020-03-24 00:01:46'),(538,665,664,0,0,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(539,666,664,0,1,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(540,667,664,0,2,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(541,668,664,0,3,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(542,669,664,0,4,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(543,670,664,0,5,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(544,671,664,0,6,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(545,672,664,0,7,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(546,673,664,0,8,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(547,674,664,0,9,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(548,675,664,0,10,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(549,676,664,0,11,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(550,677,664,1,0,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(551,678,664,1,1,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(552,679,664,1,2,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(553,680,664,1,3,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(554,681,664,1,4,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(555,682,664,1,5,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(556,683,664,1,6,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(557,684,664,1,7,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(558,685,664,1,8,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(559,686,664,1,9,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(560,687,664,1,10,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(561,688,664,1,11,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(562,689,664,2,0,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(563,690,664,2,1,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(564,691,664,2,2,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(565,692,664,2,3,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(566,693,664,2,4,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(567,694,664,2,5,'2020-03-24 00:30:33','2020-03-24 00:30:33'),(568,697,696,0,0,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(569,698,696,0,1,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(570,699,696,0,2,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(571,700,696,0,3,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(572,701,696,0,4,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(573,702,696,0,5,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(574,703,696,0,6,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(575,704,696,0,7,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(576,705,696,0,8,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(577,706,696,0,9,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(578,707,696,0,10,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(579,708,696,0,11,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(580,709,696,1,0,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(581,710,696,1,1,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(582,711,696,1,2,'2020-03-24 00:32:15','2020-03-24 00:32:15'),(583,712,696,1,3,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(584,713,696,1,4,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(585,714,696,1,5,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(586,715,696,1,6,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(587,716,696,1,7,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(588,717,696,1,8,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(589,718,696,1,9,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(590,719,696,1,10,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(591,720,696,1,11,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(592,721,696,2,0,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(593,722,696,2,1,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(594,723,696,2,2,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(595,724,696,2,3,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(596,725,696,2,4,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(597,726,696,2,5,'2020-03-24 00:32:16','2020-03-24 00:32:16'),(598,729,728,0,0,'2020-03-24 00:33:11','2020-03-24 00:33:11'),(599,730,728,0,1,'2020-03-24 00:33:11','2020-03-24 00:33:11'),(600,731,728,0,2,'2020-03-24 00:33:11','2020-03-24 00:33:11'),(601,732,728,0,3,'2020-03-24 00:33:11','2020-03-24 00:33:11'),(602,733,728,0,4,'2020-03-24 00:33:11','2020-03-24 00:33:11'),(603,734,728,0,5,'2020-03-24 00:33:11','2020-03-24 00:33:11'),(604,735,728,0,6,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(605,736,728,0,7,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(606,737,728,0,8,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(607,738,728,0,9,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(608,739,728,0,10,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(609,740,728,0,11,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(610,741,728,1,0,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(611,742,728,1,1,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(612,743,728,1,2,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(613,744,728,1,3,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(614,745,728,1,4,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(615,746,728,1,5,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(616,747,728,1,6,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(617,748,728,1,7,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(618,749,728,1,8,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(619,750,728,1,9,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(620,751,728,1,10,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(621,752,728,1,11,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(622,753,728,2,0,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(623,754,728,2,1,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(624,755,728,2,2,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(625,756,728,2,3,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(626,757,728,2,4,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(627,758,728,2,5,'2020-03-24 00:33:12','2020-03-24 00:33:12'),(628,759,728,2,6,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(629,760,728,2,7,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(630,761,728,2,8,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(631,762,728,2,9,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(632,763,728,2,10,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(633,764,728,2,11,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(634,765,728,3,0,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(635,766,728,3,1,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(636,767,728,3,2,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(637,768,728,3,3,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(638,769,728,3,4,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(639,770,728,3,5,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(640,771,728,3,6,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(641,772,728,3,7,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(642,773,728,3,8,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(643,774,728,3,9,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(644,775,728,3,10,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(645,776,728,3,11,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(646,777,728,4,0,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(647,778,728,4,1,'2020-03-24 00:33:16','2020-03-24 00:33:16'),(648,779,727,0,0,'2020-03-24 00:33:20','2020-03-24 00:33:20'),(649,780,727,0,1,'2020-03-24 00:33:20','2020-03-24 00:33:20'),(650,783,782,0,0,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(651,784,782,0,1,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(652,785,782,0,2,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(653,786,782,0,3,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(654,787,782,0,4,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(655,788,782,0,5,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(656,789,782,0,6,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(657,790,782,0,7,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(658,791,782,0,8,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(659,792,782,0,9,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(660,793,782,0,10,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(661,794,782,0,11,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(662,795,782,1,0,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(663,796,782,1,1,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(664,797,782,1,2,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(665,798,782,1,3,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(666,799,782,1,4,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(667,800,782,1,5,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(668,801,782,1,6,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(669,802,782,1,7,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(670,803,782,1,8,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(671,804,782,1,9,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(672,805,782,1,10,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(673,806,782,1,11,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(674,807,782,2,0,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(675,808,782,2,1,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(676,809,782,2,2,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(677,810,782,2,3,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(678,811,782,2,4,'2020-03-24 15:15:28','2020-03-24 15:15:28'),(679,812,782,2,5,'2020-03-24 15:15:29','2020-03-24 15:15:29'),(680,813,782,2,6,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(681,814,782,2,7,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(682,815,782,2,8,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(683,816,782,2,9,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(684,817,782,2,10,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(685,818,782,2,11,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(686,819,782,3,0,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(687,820,782,3,1,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(688,821,782,3,2,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(689,822,782,3,3,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(690,823,782,3,4,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(691,824,782,3,5,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(692,825,782,3,6,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(693,826,782,3,7,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(694,827,782,3,8,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(695,828,782,3,9,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(696,829,782,3,10,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(697,830,782,3,11,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(698,831,782,4,0,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(699,832,782,4,1,'2020-03-24 15:15:34','2020-03-24 15:15:34'),(700,833,781,0,0,'2020-03-24 15:15:39','2020-03-24 15:15:39'),(701,834,781,0,1,'2020-03-24 15:15:39','2020-03-24 15:15:39'),(702,836,835,0,0,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(703,837,835,0,1,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(704,838,835,0,2,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(705,839,835,0,3,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(706,840,835,0,4,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(707,841,835,0,5,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(708,842,835,0,6,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(709,843,835,0,7,'2020-03-24 15:24:00','2020-03-24 15:24:00'),(710,846,845,0,0,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(711,847,845,0,1,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(712,848,845,0,2,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(713,849,845,0,3,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(714,850,845,0,4,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(715,851,845,0,5,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(716,852,845,0,6,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(717,853,845,0,7,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(718,854,845,0,8,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(719,855,845,0,9,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(720,856,845,0,10,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(721,857,845,0,11,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(722,858,845,1,0,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(723,859,845,1,1,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(724,860,845,1,2,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(725,861,845,1,3,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(726,862,845,1,4,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(727,863,845,1,5,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(728,864,845,1,6,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(729,865,845,1,7,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(730,866,845,1,8,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(731,867,845,1,9,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(732,868,845,1,10,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(733,869,845,1,11,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(734,870,845,2,0,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(735,871,845,2,1,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(736,872,845,2,2,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(737,873,845,2,3,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(738,874,845,2,4,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(739,875,845,2,5,'2020-03-24 16:06:27','2020-03-24 16:06:27'),(740,876,845,2,6,'2020-03-24 16:06:31','2020-03-24 16:06:31'),(741,877,845,2,7,'2020-03-24 16:06:31','2020-03-24 16:06:31'),(742,878,845,2,8,'2020-03-24 16:06:31','2020-03-24 16:06:31'),(743,879,845,2,9,'2020-03-24 16:06:31','2020-03-24 16:06:31'),(744,880,845,2,10,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(745,881,845,2,11,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(746,882,845,3,0,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(747,883,845,3,1,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(748,884,845,3,2,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(749,885,845,3,3,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(750,886,845,3,4,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(751,887,845,3,5,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(752,888,845,3,6,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(753,889,845,3,7,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(754,890,845,3,8,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(755,891,845,3,9,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(756,892,845,3,10,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(757,893,845,3,11,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(758,894,845,4,0,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(759,895,845,4,1,'2020-03-24 16:06:32','2020-03-24 16:06:32'),(760,896,844,0,0,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(761,897,844,0,1,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(762,898,844,0,2,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(763,899,844,0,3,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(764,900,844,0,4,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(765,901,844,0,5,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(766,902,844,0,6,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(767,903,844,0,7,'2020-03-24 16:06:38','2020-03-24 16:06:38'),(768,905,904,0,0,'2020-03-24 16:17:09','2020-03-24 16:17:09'),(769,906,904,0,1,'2020-03-24 16:17:09','2020-03-24 16:17:09'),(770,907,904,0,2,'2020-03-24 16:17:09','2020-03-24 16:17:09'),(771,908,904,0,3,'2020-03-24 16:17:09','2020-03-24 16:17:09'),(772,909,904,0,4,'2020-03-24 16:17:09','2020-03-24 16:17:09'),(773,910,904,0,5,'2020-03-24 16:17:09','2020-03-24 16:17:09'),(774,911,904,0,6,'2020-03-24 16:17:10','2020-03-24 16:17:10'),(775,912,904,0,7,'2020-03-24 16:17:10','2020-03-24 16:17:10'),(776,915,914,0,0,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(777,916,914,0,1,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(778,917,914,0,2,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(779,918,914,0,3,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(780,919,914,0,4,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(781,920,914,0,5,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(782,921,914,0,6,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(783,922,914,0,7,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(784,923,914,0,8,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(785,924,914,0,9,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(786,925,914,0,10,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(787,926,914,0,11,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(788,927,914,1,0,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(789,928,914,1,1,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(790,929,914,1,2,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(791,930,914,1,3,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(792,931,914,1,4,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(793,932,914,1,5,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(794,933,914,1,6,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(795,934,914,1,7,'2020-03-24 16:17:37','2020-03-24 16:17:37'),(796,935,914,1,8,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(797,936,914,1,9,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(798,937,914,1,10,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(799,938,914,1,11,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(800,939,914,2,0,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(801,940,914,2,1,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(802,941,914,2,2,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(803,942,914,2,3,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(804,943,914,2,4,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(805,944,914,2,5,'2020-03-24 16:17:38','2020-03-24 16:17:38'),(806,945,914,2,6,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(807,946,914,2,7,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(808,947,914,2,8,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(809,948,914,2,9,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(810,949,914,2,10,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(811,950,914,2,11,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(812,951,914,3,0,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(813,952,914,3,1,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(814,953,914,3,2,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(815,954,914,3,3,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(816,955,914,3,4,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(817,956,914,3,5,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(818,957,914,3,6,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(819,958,914,3,7,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(820,959,914,3,8,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(821,960,914,3,9,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(822,961,914,3,10,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(823,962,914,3,11,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(824,963,914,4,0,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(825,964,914,4,1,'2020-03-24 16:17:41','2020-03-24 16:17:41'),(826,965,913,0,0,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(827,966,913,0,1,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(828,967,913,0,2,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(829,968,913,0,3,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(830,969,913,0,4,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(831,970,913,0,5,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(832,971,913,0,6,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(833,972,913,0,7,'2020-03-24 16:17:48','2020-03-24 16:17:48'),(834,975,974,0,0,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(835,976,974,0,1,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(836,977,974,0,2,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(837,978,974,0,3,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(838,979,974,0,4,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(839,980,974,0,5,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(840,981,974,0,6,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(841,982,974,0,7,'2020-03-24 17:57:10','2020-03-24 17:57:10'),(842,984,983,0,0,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(843,985,983,0,1,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(844,986,983,0,2,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(845,987,983,0,3,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(846,988,983,0,4,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(847,989,983,0,5,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(848,990,983,0,6,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(849,991,983,0,7,'2020-03-24 17:58:12','2020-03-24 17:58:12'),(850,993,992,0,0,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(851,994,992,0,1,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(852,995,992,0,2,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(853,996,992,0,3,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(854,997,992,0,4,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(855,998,992,0,5,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(856,999,992,0,6,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(857,1000,992,0,7,'2020-03-24 18:21:27','2020-03-24 18:21:27'),(858,1003,1001,0,0,'2020-03-24 19:07:31','2020-03-24 19:07:31'),(859,1004,1001,0,1,'2020-03-24 19:07:31','2020-03-24 19:07:31'),(860,1007,1005,0,0,'2020-03-24 19:15:54','2020-03-24 19:15:54'),(861,1008,1005,0,1,'2020-03-24 19:15:54','2020-03-24 19:15:54'),(862,1011,1009,0,0,'2020-03-24 19:59:18','2020-03-24 19:59:18'),(863,1012,1009,0,1,'2020-03-24 19:59:18','2020-03-24 19:59:18'),(864,1015,1013,0,0,'2020-03-24 20:02:46','2020-03-24 20:02:46'),(865,1016,1013,0,1,'2020-03-24 20:02:47','2020-03-24 20:02:47');
/*!40000 ALTER TABLE `part_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `plan_associations`
--

DROP TABLE IF EXISTS `plan_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `plan_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `plan_id` int(11) DEFAULT NULL,
  `operation_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_plan_associations_on_operation_id` (`operation_id`),
  KEY `index_plan_associations_on_plan_id` (`plan_id`)
) ENGINE=InnoDB AUTO_INCREMENT=121 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `plan_associations`
--

LOCK TABLES `plan_associations` WRITE;
/*!40000 ALTER TABLE `plan_associations` DISABLE KEYS */;
INSERT INTO `plan_associations` VALUES (4,4,5,'2020-03-19 20:07:00','2020-03-19 20:07:00'),(5,4,6,'2020-03-19 20:07:00','2020-03-19 20:07:00'),(6,4,7,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(7,4,8,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(8,4,9,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(37,32,39,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(38,32,40,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(39,32,41,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(40,32,42,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(78,70,82,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(79,70,83,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(80,70,84,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(81,70,85,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(82,71,86,'2020-03-24 18:28:27','2020-03-24 18:28:27'),(83,71,87,'2020-03-24 18:28:27','2020-03-24 18:28:27'),(84,71,88,'2020-03-24 18:28:27','2020-03-24 18:28:27'),(85,71,89,'2020-03-24 18:28:27','2020-03-24 18:28:27'),(86,71,90,'2020-03-24 18:29:17','2020-03-24 18:29:17'),(87,71,91,'2020-03-24 18:29:17','2020-03-24 18:29:17'),(88,72,92,'2020-03-24 18:31:12','2020-03-24 18:31:12'),(89,72,93,'2020-03-24 18:31:12','2020-03-24 18:31:12'),(90,72,94,'2020-03-24 18:31:12','2020-03-24 18:31:12'),(91,72,95,'2020-03-24 18:31:12','2020-03-24 18:31:12'),(92,72,96,'2020-03-24 18:31:12','2020-03-24 18:31:12'),(93,72,97,'2020-03-24 18:31:12','2020-03-24 18:31:12'),(96,73,100,'2020-03-24 18:32:04','2020-03-24 18:32:04'),(97,73,101,'2020-03-24 18:32:04','2020-03-24 18:32:04'),(99,73,103,'2020-03-24 18:32:57','2020-03-24 18:32:57'),(100,73,104,'2020-03-24 18:32:57','2020-03-24 18:32:57'),(101,73,105,'2020-03-24 18:32:57','2020-03-24 18:32:57'),(102,73,106,'2020-03-24 18:32:57','2020-03-24 18:32:57'),(103,74,107,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(104,74,108,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(105,74,109,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(106,74,110,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(107,74,111,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(108,74,112,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(109,75,113,'2020-03-24 19:58:28','2020-03-24 19:58:28'),(110,75,114,'2020-03-24 19:58:28','2020-03-24 19:58:28'),(111,75,115,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(112,75,116,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(113,75,117,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(114,75,118,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(115,76,119,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(116,76,120,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(117,76,121,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(118,76,122,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(119,76,123,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(120,76,124,'2020-03-24 20:01:50','2020-03-24 20:01:50');
/*!40000 ALTER TABLE `plan_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `plans`
--

DROP TABLE IF EXISTS `plans`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `plans` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `status` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `cost_limit` float DEFAULT NULL,
  `folder` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `layout` text COLLATE utf8_unicode_ci,
  PRIMARY KEY (`id`),
  KEY `index_plans_on_user_id` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=77 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `plans`
--

LOCK TABLES `plans` WRITE;
/*!40000 ALTER TABLE `plans` DISABLE KEYS */;
INSERT INTO `plans` VALUES (4,1,'2020-03-19 20:07:00','2020-03-19 20:20:35',1,'Make Adapter Plate',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}'),(32,1,'2020-03-20 16:58:17','2020-03-24 15:23:51',1,'Make Adapter Plate (copy)',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}'),(70,1,'2020-03-24 16:08:07','2020-03-24 16:16:36',1,'Make Adapter Plate (copy) (copy)',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}'),(73,1,'2020-03-24 18:32:04','2020-03-24 19:02:17',1,'Make Adapter Plate (copy)',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}'),(74,1,'2020-03-24 19:14:18','2020-03-24 19:15:29',1,'Make Adapter Plate (copy) (copy)',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}'),(75,1,'2020-03-24 19:58:28','2020-03-24 19:58:35',1,'Make Adapter Plate (copy) (copy) (copy)',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}'),(76,1,'2020-03-24 20:01:50','2020-03-24 20:02:35',1,'Make Adapter Plate (copy) (copy) (copy)',NULL,NULL,NULL,'{\"id\":0,\"parent_id\":-1,\"name\":\"Untitled Module 0\",\"x\":160,\"y\":160,\"width\":160,\"height\":60,\"model\":{\"model\":\"Module\"},\"input\":null,\"output\":null,\"documentation\":\"No documentation yet for this module.\",\"children\":null,\"wires\":null,\"text_boxes\":null}');
/*!40000 ALTER TABLE `plans` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `sample_types`
--

DROP TABLE IF EXISTS `sample_types`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `sample_types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `description` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `sample_types`
--

LOCK TABLES `sample_types` WRITE;
/*!40000 ALTER TABLE `sample_types` DISABLE KEYS */;
INSERT INTO `sample_types` VALUES (1,'RNA Sample','An individual unique sample of RNA','2020-03-19 17:30:41','2020-03-19 17:30:41'),(2,'oligonucleotide','oligonucleotide adapter','2020-03-19 18:05:56','2020-03-19 18:05:56'),(3,'Fragment','A linear double stranded piece of DNA from PCR or Restriction Digest','2020-03-24 15:41:53','2020-03-24 15:41:53'),(4,'Plasmid','A circular piece of double stranded DNA','2020-03-24 15:41:53','2020-03-24 15:41:53'),(5,'Primer','A short double stranded piece of DNA for PCR and sequencing','2020-03-24 15:41:53','2020-03-24 15:41:53'),(6,'E coli strain','A strain of E coli distinguished from others by genomic (not plasmid) modifications.','2020-03-24 15:41:53','2020-03-24 15:41:53'),(7,'Yeast Strain','A strain of yeast distinguished from others by genomic or plasmid modifications','2020-03-24 15:41:53','2020-03-24 15:41:53'),(8,'DNA Library','A sample that contains a pool of DNA molecules with many unique sequences','2020-03-24 15:41:53','2020-03-24 15:41:53'),(9,'Oligo Pool','Pool or library of ssDNA oligos. May contain one or more sublibraries. In array fields, the n-th position corresponds to n-th sublibrary. \"forward priming site\" and \"reverse priming site\" are read as primer sequences.','2020-03-24 15:41:53','2020-03-24 15:41:53');
/*!40000 ALTER TABLE `sample_types` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `samples`
--

DROP TABLE IF EXISTS `samples`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `samples` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `sample_type_id` int(11) DEFAULT NULL,
  `project` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `user_id` int(11) DEFAULT NULL,
  `description` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `data` text COLLATE utf8_unicode_ci,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=569 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `samples`
--

LOCK TABLES `samples` WRITE;
/*!40000 ALTER TABLE `samples` DISABLE KEYS */;
INSERT INTO `samples` VALUES (1,'1-S1',1,'1','2020-03-19 17:58:24','2020-03-19 17:58:24',1,'1-S1',NULL),(2,'1-S2',1,'1','2020-03-19 17:58:24','2020-03-19 17:58:24',1,'1-S2',NULL),(3,'1-S3',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S3',NULL),(4,'1-S4',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S4',NULL),(5,'1-S5',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S5',NULL),(6,'1-S6',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S6',NULL),(7,'1-S7',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S7',NULL),(8,'1-S8',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S8',NULL),(9,'1-S9',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S9',NULL),(10,'1-S10',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S10',NULL),(11,'1-S11',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S11',NULL),(12,'1-S12',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S12',NULL),(13,'1-S13',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S13',NULL),(14,'1-S14',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S14',NULL),(15,'1-S15',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S15',NULL),(16,'1-S16',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S16',NULL),(17,'1-S17',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S17',NULL),(18,'1-S18',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S18',NULL),(19,'1-S19',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S19',NULL),(20,'1-S20',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S20',NULL),(21,'1-S21',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S21',NULL),(22,'1-S22',1,'1','2020-03-19 17:58:25','2020-03-19 17:58:25',1,'1-S22',NULL),(23,'1-S23',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S23',NULL),(24,'1-S24',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S24',NULL),(25,'1-S25',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S25',NULL),(26,'1-S26',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S26',NULL),(27,'1-S27',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S27',NULL),(28,'1-S28',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S28',NULL),(29,'1-S29',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S29',NULL),(30,'1-S30',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S30',NULL),(31,'1-S31',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S31',NULL),(32,'1-S32',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S32',NULL),(33,'1-S33',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S33',NULL),(34,'1-S34',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S34',NULL),(35,'1-S35',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S35',NULL),(36,'1-S36',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S36',NULL),(37,'1-S37',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S37',NULL),(38,'1-S38',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S38',NULL),(39,'1-S39',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S39',NULL),(40,'1-S40',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S40',NULL),(41,'1-S41',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S41',NULL),(42,'1-S42',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S42',NULL),(43,'1-S43',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S43',NULL),(44,'1-S44',1,'1','2020-03-19 17:58:26','2020-03-19 17:58:26',1,'1-S44',NULL),(45,'1-S45',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S45',NULL),(46,'1-S46',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S46',NULL),(47,'1-S47',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S47',NULL),(48,'1-S48',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S48',NULL),(49,'1-S49',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S49',NULL),(50,'1-S50',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S50',NULL),(51,'1-S51',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S51',NULL),(52,'1-S52',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S52',NULL),(53,'1-S53',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S53',NULL),(54,'1-S54',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S54',NULL),(55,'1-S55',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S55',NULL),(56,'1-S56',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S56',NULL),(57,'1-S57',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S57',NULL),(58,'1-S58',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S58',NULL),(59,'1-S59',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S59',NULL),(60,'1-S60',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S60',NULL),(61,'1-S61',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S61',NULL),(62,'1-S62',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S62',NULL),(63,'1-S63',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S63',NULL),(64,'1-S64',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S64',NULL),(65,'1-S65',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S65',NULL),(66,'1-S66',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S66',NULL),(67,'1-S67',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S67',NULL),(68,'1-S68',1,'1','2020-03-19 17:58:27','2020-03-19 17:58:27',1,'1-S68',NULL),(69,'1-S69',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S69',NULL),(70,'1-S70',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S70',NULL),(71,'1-S71',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S71',NULL),(72,'1-S72',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S72',NULL),(73,'1-S73',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S73',NULL),(74,'1-S74',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S74',NULL),(75,'1-S75',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S75',NULL),(76,'1-S76',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S76',NULL),(77,'1-S77',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S77',NULL),(78,'1-S78',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S78',NULL),(79,'1-S79',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S79',NULL),(80,'1-S80',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S80',NULL),(81,'1-S81',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S81',NULL),(82,'1-S82',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S82',NULL),(83,'1-S83',1,'1','2020-03-19 17:58:28','2020-03-19 17:58:28',1,'1-S83',NULL),(245,'A1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'A1',NULL),(246,'G1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'G1',NULL),(247,'H1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'H1',NULL),(248,'B1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'B1',NULL),(249,'C1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'C1',NULL),(250,'D1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'D1',NULL),(251,'E1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'E1',NULL),(252,'F1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'F1',NULL),(253,'I1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'I1',NULL),(254,'J1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'J1',NULL),(255,'K1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'K1',NULL),(256,'L1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'L1',NULL),(257,'M1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'M1',NULL),(258,'N1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'N1',NULL),(259,'O1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'O1',NULL),(260,'P1',2,'Adapters','2020-03-19 18:34:25','2020-03-19 18:34:25',1,'P1',NULL),(261,'Q1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Q1',NULL),(262,'R1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'R1',NULL),(263,'S1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'S1',NULL),(264,'T1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'T1',NULL),(265,'U1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'U1',NULL),(266,'V1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'V1',NULL),(267,'W1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'W1',NULL),(268,'X1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'X1',NULL),(269,'Y1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Y1',NULL),(270,'Z1',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Z1',NULL),(271,'A2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'A2',NULL),(272,'B2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'B2',NULL),(273,'C2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'C2',NULL),(274,'D2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'D2',NULL),(275,'E2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'E2',NULL),(276,'F2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'F2',NULL),(277,'G2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'G2',NULL),(278,'H2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'H2',NULL),(279,'I2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'I2',NULL),(280,'J2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'J2',NULL),(281,'K2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'K2',NULL),(282,'L2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'L2',NULL),(283,'M2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'M2',NULL),(284,'N2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'N2',NULL),(285,'O2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'O2',NULL),(286,'P2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'P2',NULL),(287,'Q2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Q2',NULL),(288,'R2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'R2',NULL),(289,'S2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'S2',NULL),(290,'T2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'T2',NULL),(291,'U2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'U2',NULL),(292,'V2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'V2',NULL),(293,'W2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'W2',NULL),(294,'X2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'X2',NULL),(295,'Y2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Y2',NULL),(296,'Z2',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Z2',NULL),(297,'A3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'A3',NULL),(298,'B3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'B3',NULL),(299,'C3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'C3',NULL),(300,'D3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'D3',NULL),(301,'E3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'E3',NULL),(302,'F3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'F3',NULL),(303,'G3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'G3',NULL),(304,'H3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'H3',NULL),(305,'I3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'I3',NULL),(306,'J3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'J3',NULL),(307,'K3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'K3',NULL),(308,'L3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'L3',NULL),(309,'M3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'M3',NULL),(310,'N3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'N3',NULL),(311,'O3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'O3',NULL),(312,'P3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'P3',NULL),(313,'Q3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Q3',NULL),(314,'R3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'R3',NULL),(315,'S3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'S3',NULL),(316,'T3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'T3',NULL),(317,'U3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'U3',NULL),(318,'V3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'V3',NULL),(319,'W3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'W3',NULL),(320,'X3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'X3',NULL),(321,'Y3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Y3',NULL),(322,'Z3',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'Z3',NULL),(323,'A4',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'A4',NULL),(324,'B4',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'B4',NULL),(325,'C4',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'C4',NULL),(326,'D4',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'D4',NULL),(327,'E4',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'E4',NULL),(328,'F4',2,'Adapters','2020-03-19 18:34:26','2020-03-19 18:34:26',1,'F4',NULL),(329,'G4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'G4',NULL),(330,'H4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'H4',NULL),(331,'I4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'I4',NULL),(332,'J4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'J4',NULL),(333,'K4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'K4',NULL),(334,'L4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'L4',NULL),(335,'M4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'M4',NULL),(336,'N4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'N4',NULL),(337,'O4',2,'Adapters','2020-03-19 18:34:27','2020-03-19 18:34:27',1,'O4',NULL),(470,'P4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'P4',NULL),(471,'S4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'S4',NULL),(472,'T4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'T4',NULL),(473,'U4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'U4',NULL),(474,'Q4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'Q4',NULL),(475,'R4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'R4',NULL),(476,'V4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'V4',NULL),(477,'W4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'W4',NULL),(478,'X4',2,'Adapters','2020-03-19 19:04:34','2020-03-19 19:04:34',1,'X4',NULL),(479,'Y4',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Y4',NULL),(480,'Z4',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Z4',NULL),(481,'A5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'A5',NULL),(482,'B5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'B5',NULL),(483,'C5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'C5',NULL),(484,'D5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'D5',NULL),(485,'E5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'E5',NULL),(486,'F5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'F5',NULL),(487,'G5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'G5',NULL),(488,'H5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'H5',NULL),(489,'I5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'I5',NULL),(490,'J5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'J5',NULL),(491,'K5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'K5',NULL),(492,'L5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'L5',NULL),(493,'M5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'M5',NULL),(494,'N5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'N5',NULL),(495,'O5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'O5',NULL),(496,'P5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'P5',NULL),(497,'Q5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Q5',NULL),(498,'R5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'R5',NULL),(499,'S5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'S5',NULL),(500,'T5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'T5',NULL),(501,'U5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'U5',NULL),(502,'V5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'V5',NULL),(503,'W5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'W5',NULL),(504,'X5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'X5',NULL),(505,'Y5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Y5',NULL),(506,'Z5',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Z5',NULL),(507,'A6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'A6',NULL),(508,'B6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'B6',NULL),(509,'C6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'C6',NULL),(510,'D6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'D6',NULL),(511,'E6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'E6',NULL),(512,'F6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'F6',NULL),(513,'G6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'G6',NULL),(514,'H6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'H6',NULL),(515,'I6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'I6',NULL),(516,'J6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'J6',NULL),(517,'K6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'K6',NULL),(518,'L6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'L6',NULL),(519,'M6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'M6',NULL),(520,'N6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'N6',NULL),(521,'O6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'O6',NULL),(522,'P6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'P6',NULL),(523,'Q6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Q6',NULL),(524,'R6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'R6',NULL),(525,'S6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'S6',NULL),(526,'T6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'T6',NULL),(527,'U6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'U6',NULL),(528,'V6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'V6',NULL),(529,'W6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'W6',NULL),(530,'X6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'X6',NULL),(531,'Y6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Y6',NULL),(532,'Z6',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Z6',NULL),(533,'A7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'A7',NULL),(534,'B7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'B7',NULL),(535,'C7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'C7',NULL),(536,'D7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'D7',NULL),(537,'E7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'E7',NULL),(538,'F7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'F7',NULL),(539,'G7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'G7',NULL),(540,'H7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'H7',NULL),(541,'I7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'I7',NULL),(542,'J7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'J7',NULL),(543,'K7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'K7',NULL),(544,'L7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'L7',NULL),(545,'M7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'M7',NULL),(546,'N7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'N7',NULL),(547,'O7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'O7',NULL),(548,'P7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'P7',NULL),(549,'Q7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Q7',NULL),(550,'R7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'R7',NULL),(551,'S7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'S7',NULL),(552,'T7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'T7',NULL),(553,'U7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'U7',NULL),(554,'V7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'V7',NULL),(555,'W7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'W7',NULL),(556,'X7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'X7',NULL),(557,'Y7',2,'Adapters','2020-03-19 19:04:35','2020-03-19 19:04:35',1,'Y7',NULL),(558,'Z7',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'Z7',NULL),(559,'A8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'A8',NULL),(560,'B8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'B8',NULL),(561,'C8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'C8',NULL),(562,'D8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'D8',NULL),(563,'E8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'E8',NULL),(564,'F8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'F8',NULL),(565,'G8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'G8',NULL),(566,'H8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'H8',NULL),(567,'I8',2,'Adapters','2020-03-19 19:04:36','2020-03-19 19:04:36',1,'I8',NULL),(568,'Test Plasmid',4,'Test','2020-03-24 18:57:02','2020-03-24 18:57:02',1,'asd\'fk',NULL);
/*!40000 ALTER TABLE `samples` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `schema_migrations`
--

DROP TABLE IF EXISTS `schema_migrations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `schema_migrations` (
  `version` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  UNIQUE KEY `unique_schema_migrations` (`version`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `schema_migrations`
--

LOCK TABLES `schema_migrations` WRITE;
/*!40000 ALTER TABLE `schema_migrations` DISABLE KEYS */;
INSERT INTO `schema_migrations` VALUES ('20131029153603'),('20131029153634'),('20131111143554'),('20131111143621'),('20131113172448'),('20131113181345'),('20131119164152'),('20131119164208'),('20131122032927'),('20131223192901'),('20140131235419'),('20140404201838'),('20140404201900'),('20140404204258'),('20140408224245'),('20140428213241'),('20140507230919'),('20140508203643'),('20140513225335'),('20140616190537'),('20140714220057'),('20140907220135'),('20150124195318'),('20150124201744'),('20150129213358'),('20150129221830'),('20150212051010'),('20150212051027'),('20150213173621'),('20150222153442'),('20150326202149'),('20150405154727'),('20150515160553'),('20150515160619'),('20150719221125'),('20150719221226'),('20150719221253'),('20150719223053'),('20150720044538'),('20150828232337'),('20150923014954'),('20150923015030'),('20150923184243'),('20150924044044'),('20150926162327'),('20151027164741'),('20151029034310'),('20151118210640'),('20151203054202'),('20160128203950'),('20160128205317'),('20160128205943'),('20160129021809'),('20160129164244'),('20160129165100'),('20160330023703'),('20160330033810'),('20160330185947'),('20160330190634'),('20160411130601'),('20160411131711'),('20160412010529'),('20160427043024'),('20160427043546'),('20160429232330'),('20160429232408'),('20160429232434'),('20160430000308'),('20160430152749'),('20160514044605'),('20160526204339'),('20160607162741'),('20160615161649'),('20160720211005'),('20161113203042'),('20161219172133'),('20170330173426'),('20170421231924'),('20170426225719'),('20170504211619'),('20170504212208'),('20170604165355'),('20170627173019'),('20170725190809'),('20170729024546'),('20170806145525'),('20170813203843'),('20171103151518'),('20180509200425'),('20180529204642'),('20180809012224'),('20181221174622');
/*!40000 ALTER TABLE `schema_migrations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `timings`
--

DROP TABLE IF EXISTS `timings`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `timings` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `parent_id` int(11) DEFAULT NULL,
  `parent_class` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `days` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `start` int(11) DEFAULT NULL,
  `stop` int(11) DEFAULT NULL,
  `active` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `timings`
--

LOCK TABLES `timings` WRITE;
/*!40000 ALTER TABLE `timings` DISABLE KEYS */;
/*!40000 ALTER TABLE `timings` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `uploads`
--

DROP TABLE IF EXISTS `uploads`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `uploads` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) DEFAULT NULL,
  `upload_file_name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `upload_content_type` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `upload_file_size` int(11) DEFAULT NULL,
  `upload_updated_at` datetime DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=46 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `uploads`
--

LOCK TABLES `uploads` WRITE;
/*!40000 ALTER TABLE `uploads` DISABLE KEYS */;
INSERT INTO `uploads` VALUES (1,4,'Oligos.csv','text/plain',3294,'2020-03-19 20:21:02','2020-03-19 20:21:02','2020-03-19 20:21:02'),(2,5,'Oligos.csv','text/plain',3294,'2020-03-19 20:35:27','2020-03-19 20:35:27','2020-03-19 20:35:27'),(3,6,'Oligos.csv','text/plain',3294,'2020-03-19 20:36:26','2020-03-19 20:36:26','2020-03-19 20:36:26'),(4,44,'Book3.csv','text/plain',545,'2020-03-23 20:19:56','2020-03-23 20:19:56','2020-03-23 20:19:56'),(5,45,'Book3.csv','text/plain',545,'2020-03-23 20:21:04','2020-03-23 20:21:04','2020-03-23 20:21:04'),(6,46,'Book3.csv','text/plain',545,'2020-03-23 20:22:23','2020-03-23 20:22:23','2020-03-23 20:22:23'),(7,47,'Book3.csv','text/plain',545,'2020-03-23 21:12:22','2020-03-23 21:12:22','2020-03-23 21:12:22'),(8,48,'Book3.csv','text/plain',545,'2020-03-23 21:19:38','2020-03-23 21:19:38','2020-03-23 21:19:38'),(9,49,'Book3.csv','text/plain',545,'2020-03-23 21:20:11','2020-03-23 21:20:11','2020-03-23 21:20:11'),(10,53,'Book3.csv','text/plain',545,'2020-03-23 21:23:14','2020-03-23 21:23:14','2020-03-23 21:23:14'),(11,54,'Book3.csv','text/plain',545,'2020-03-23 21:24:10','2020-03-23 21:24:10','2020-03-23 21:24:10'),(12,55,'Book3.csv','text/plain',545,'2020-03-23 21:24:46','2020-03-23 21:24:46','2020-03-23 21:24:46'),(13,56,'Book3.csv','text/plain',545,'2020-03-23 21:25:43','2020-03-23 21:25:43','2020-03-23 21:25:43'),(14,57,'Book3.csv','text/plain',545,'2020-03-23 21:27:55','2020-03-23 21:27:55','2020-03-23 21:27:55'),(15,58,'Book3.csv','text/plain',545,'2020-03-23 22:49:32','2020-03-23 22:49:32','2020-03-23 22:49:32'),(16,59,'Book3.csv','text/plain',545,'2020-03-23 23:00:26','2020-03-23 23:00:26','2020-03-23 23:00:26'),(17,60,'Book3.csv','text/plain',545,'2020-03-23 23:02:34','2020-03-23 23:02:34','2020-03-23 23:02:34'),(18,61,'Book3.csv','text/plain',545,'2020-03-23 23:04:19','2020-03-23 23:04:19','2020-03-23 23:04:19'),(19,62,'Book3.csv','text/plain',545,'2020-03-23 23:05:32','2020-03-23 23:05:32','2020-03-23 23:05:32'),(20,63,'Book3.csv','text/plain',545,'2020-03-23 23:07:10','2020-03-23 23:07:10','2020-03-23 23:07:10'),(21,64,'Book3.csv','text/plain',545,'2020-03-23 23:10:21','2020-03-23 23:10:21','2020-03-23 23:10:21'),(22,65,'Book3.csv','text/plain',545,'2020-03-23 23:13:41','2020-03-23 23:13:41','2020-03-23 23:13:41'),(23,66,'Book3.csv','text/plain',545,'2020-03-23 23:15:21','2020-03-23 23:15:21','2020-03-23 23:15:21'),(24,67,'Book3.csv','text/plain',502,'2020-03-23 23:22:27','2020-03-23 23:22:27','2020-03-23 23:22:27'),(25,68,'Book3.csv','text/plain',502,'2020-03-23 23:23:03','2020-03-23 23:23:03','2020-03-23 23:23:03'),(26,69,'Book3.csv','text/plain',502,'2020-03-23 23:25:02','2020-03-23 23:25:02','2020-03-23 23:25:02'),(27,70,'Book3.csv','text/plain',502,'2020-03-23 23:29:59','2020-03-23 23:29:59','2020-03-23 23:29:59'),(28,71,'Book3.csv','text/plain',124,'2020-03-23 23:32:55','2020-03-23 23:32:55','2020-03-23 23:32:55'),(29,72,'Book3.csv','text/plain',124,'2020-03-23 23:34:45','2020-03-23 23:34:45','2020-03-23 23:34:45'),(30,73,'Book3.csv','text/plain',124,'2020-03-23 23:45:40','2020-03-23 23:45:40','2020-03-23 23:45:40'),(31,74,'Book3.csv','text/plain',124,'2020-03-23 23:47:11','2020-03-23 23:47:11','2020-03-23 23:47:11'),(32,75,'Book3.csv','text/plain',124,'2020-03-23 23:49:28','2020-03-23 23:49:28','2020-03-23 23:49:28'),(33,76,'Book3.csv','text/plain',124,'2020-03-23 23:53:34','2020-03-23 23:53:34','2020-03-23 23:53:34'),(34,77,'Book3.csv','text/plain',473,'2020-03-23 23:56:40','2020-03-23 23:56:40','2020-03-23 23:56:40'),(35,78,'Book3.csv','text/plain',473,'2020-03-23 23:57:28','2020-03-23 23:57:28','2020-03-23 23:57:28'),(36,79,'Book3.csv','text/plain',395,'2020-03-23 23:58:19','2020-03-23 23:58:19','2020-03-23 23:58:19'),(37,80,'Book3.csv','text/plain',124,'2020-03-23 23:59:04','2020-03-23 23:59:04','2020-03-23 23:59:04'),(38,81,'Book3.csv','text/plain',223,'2020-03-23 23:59:53','2020-03-23 23:59:53','2020-03-23 23:59:53'),(39,82,'Book3.csv','text/plain',394,'2020-03-24 00:01:20','2020-03-24 00:01:20','2020-03-24 00:01:20'),(40,83,'Book3.csv','text/plain',394,'2020-03-24 00:30:30','2020-03-24 00:30:30','2020-03-24 00:30:30'),(41,84,'Book3.csv','text/plain',394,'2020-03-24 00:32:13','2020-03-24 00:32:13','2020-03-24 00:32:13'),(42,85,'Book3.csv','text/plain',394,'2020-03-24 00:33:08','2020-03-24 00:33:08','2020-03-24 00:33:08'),(43,86,'Book3.csv','text/plain',394,'2020-03-24 15:15:20','2020-03-24 15:15:20','2020-03-24 15:15:20'),(44,88,'Book3.csv','text/plain',394,'2020-03-24 16:06:18','2020-03-24 16:06:18','2020-03-24 16:06:18'),(45,92,'Book3.csv','text/plain',394,'2020-03-24 16:17:35','2020-03-24 16:17:35','2020-03-24 16:17:35');
/*!40000 ALTER TABLE `uploads` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `user_budget_associations`
--

DROP TABLE IF EXISTS `user_budget_associations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `user_budget_associations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `budget_id` int(11) DEFAULT NULL,
  `quota` float DEFAULT NULL,
  `disabled` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `user_budget_associations`
--

LOCK TABLES `user_budget_associations` WRITE;
/*!40000 ALTER TABLE `user_budget_associations` DISABLE KEYS */;
INSERT INTO `user_budget_associations` VALUES (1,1,1,1000,0,'2018-07-17 22:10:10','2018-07-17 22:10:10');
/*!40000 ALTER TABLE `user_budget_associations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `users`
--

DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `users` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `login` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `password_digest` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `remember_token` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `admin` tinyint(1) DEFAULT '0',
  `key` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `index_users_on_login` (`login`),
  KEY `index_users_on_remember_token` (`remember_token`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `users`
--

LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` VALUES (1,'Joe Neptune','neptune','2013-06-16 17:26:54','2017-10-19 04:59:18','$2a$10$HxgxLX5/ITcYpII1InAL1.jUYAiHk/rMftHniPJVvauy43VDoo8yW','TYmoWfyV42AL7dSoYcgmug',1,'VHzz9IW3xnNx8O3cA_P0rKsUWmTVH_Qz9mHKqgE-hNI');
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `wires`
--

DROP TABLE IF EXISTS `wires`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `wires` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `from_id` int(11) DEFAULT NULL,
  `to_id` int(11) DEFAULT NULL,
  `active` tinyint(1) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=104 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `wires`
--

LOCK TABLES `wires` WRITE;
/*!40000 ALTER TABLE `wires` DISABLE KEYS */;
INSERT INTO `wires` VALUES (1,1720,1723,1,'2020-03-19 20:07:00','2020-03-19 20:07:00'),(2,1725,1727,1,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(3,1722,1728,1,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(4,1725,1730,1,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(5,1722,1726,1,'2020-03-19 20:17:57','2020-03-19 20:17:57'),(7,1767,1769,NULL,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(8,1764,1770,NULL,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(9,1767,1772,NULL,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(10,1764,1768,NULL,'2020-03-20 16:58:17','2020-03-20 16:58:17'),(11,1806,1782,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(12,1767,1788,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(13,1807,1789,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(14,1808,1790,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(15,1809,1791,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(16,1810,1792,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(17,1811,1793,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(18,1807,1783,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(19,1808,1784,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(20,1809,1785,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(21,1810,1786,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(22,1811,1787,1,'2020-03-20 18:46:06','2020-03-20 18:46:06'),(23,1854,1868,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(26,1852,1867,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(27,1861,1869,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(34,1862,1870,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(35,1863,1871,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(36,1864,1872,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(37,1865,1873,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(38,1866,1874,NULL,'2020-03-24 16:08:07','2020-03-24 16:08:07'),(39,1852,1875,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(40,1854,1877,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(41,1861,1879,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(42,1862,1880,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(43,1863,1881,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(44,1864,1882,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(45,1865,1883,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(46,1866,1884,1,'2020-03-24 16:10:54','2020-03-24 16:10:54'),(84,2024,2028,1,'2020-03-24 18:32:57','2020-03-24 18:32:57'),(85,2034,2027,1,'2020-03-24 18:59:25','2020-03-24 18:59:25'),(86,2055,2062,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(87,2068,2059,NULL,'2020-03-24 19:14:18','2020-03-24 19:14:18'),(88,2058,2050,1,'2020-03-24 19:14:38','2020-03-24 19:14:38'),(89,2060,2052,1,'2020-03-24 19:14:38','2020-03-24 19:14:38'),(90,2060,2049,1,'2020-03-24 19:14:38','2020-03-24 19:14:38'),(91,2058,2048,1,'2020-03-24 19:14:38','2020-03-24 19:14:38'),(92,2076,2083,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(93,2089,2080,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(94,2079,2071,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(95,2081,2073,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(96,2081,2070,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(97,2079,2069,NULL,'2020-03-24 19:58:29','2020-03-24 19:58:29'),(98,2097,2104,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(99,2110,2101,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(100,2100,2092,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(101,2102,2094,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(102,2102,2091,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50'),(103,2100,2090,NULL,'2020-03-24 20:01:50','2020-03-24 20:01:50');
/*!40000 ALTER TABLE `wires` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `wizards`
--

DROP TABLE IF EXISTS `wizards`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `wizards` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `specification` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `description` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `wizards`
--

LOCK TABLES `wizards` WRITE;
/*!40000 ALTER TABLE `wizards` DISABLE KEYS */;
/*!40000 ALTER TABLE `wizards` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `workers`
--

DROP TABLE IF EXISTS `workers`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `workers` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `message` varchar(255) DEFAULT NULL,
  `status` varchar(255) DEFAULT NULL,
  `created_at` datetime DEFAULT NULL,
  `updated_at` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=53 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `workers`
--

LOCK TABLES `workers` WRITE;
/*!40000 ALTER TABLE `workers` DISABLE KEYS */;
INSERT INTO `workers` VALUES (1,'publisher',NULL,'running','2018-11-16 16:09:14','2018-11-16 16:09:14'),(2,'publisher',NULL,'done','2018-11-16 16:10:31','2018-11-16 16:11:22'),(3,'publisher',NULL,'done','2018-11-16 16:11:16','2018-11-16 16:12:03'),(4,'publisher',NULL,'done','2018-11-16 16:15:00','2018-11-16 16:15:39'),(5,'publisher',NULL,'done','2018-11-16 16:16:19','2018-11-16 16:17:11'),(6,'publisher',NULL,'done','2018-11-16 16:19:23','2018-11-16 16:19:56'),(7,'publisher',NULL,'done','2018-11-16 17:45:28','2018-11-16 17:45:45'),(8,'publisher',NULL,'done','2018-11-16 17:48:08','2018-11-16 17:48:18'),(9,'publisher',NULL,'done','2018-11-16 18:43:18','2018-11-16 18:43:39'),(10,'publisher',NULL,'done','2018-11-16 18:46:03','2018-11-16 18:46:17'),(11,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON','error','2018-11-16 18:48:41','2018-11-16 18:48:47'),(12,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON','error','2018-11-16 18:54:15','2018-11-16 18:54:21'),(13,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON','error','2018-11-16 18:55:55','2018-11-16 18:56:00'),(14,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON','error','2018-11-16 19:01:31','2018-11-16 19:01:35'),(15,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON','error','2018-11-16 19:02:46','2018-11-16 19:02:51'),(16,'publisher',NULL,'running','2018-11-16 19:08:07','2018-11-16 19:08:07'),(17,'publisher',NULL,'running','2018-11-16 19:14:15','2018-11-16 19:14:15'),(18,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON: (erb):21:in `make_index\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 19:21:57','2018-11-16 19:22:02'),(19,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON: (erb):21:in `make_index\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 19:24:08','2018-11-16 19:24:14'),(20,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON: (erb):21:in `make_index\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 19:27:22','2018-11-16 19:27:28'),(21,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON: (erb):21:in `make_index\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 19:30:01','2018-11-16 19:30:07'),(22,'publisher','undefined method `join\' for nil:NilClass\nDid you mean?  JSON: (erb):21:in `make_index\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 19:33:00','2018-11-16 19:33:05'),(23,'publisher',NULL,'done','2018-11-16 19:34:25','2018-11-16 19:34:39'),(24,'publisher',NULL,'done','2018-11-16 19:35:54','2018-11-16 19:36:09'),(25,'publisher','undefined method `each\' for nil:NilClass: (erb):20:in `make_about_md\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 20:41:04','2018-11-16 20:41:09'),(26,'publisher','undefined method `each\' for nil:NilClass: (erb):20:in `make_about_md\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 20:45:28','2018-11-16 20:45:33'),(27,'publisher','undefined method `each\' for nil:NilClass: (erb):13:in `make_about_md\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `block in result\'','error','2018-11-16 20:47:12','2018-11-16 20:47:16'),(28,'publisher',NULL,'done','2018-11-16 20:48:39','2018-11-16 20:48:55'),(29,'publisher',NULL,'done','2018-11-16 20:53:35','2018-11-16 20:53:50'),(30,'publisher',NULL,'done','2018-11-16 20:54:37','2018-11-16 20:54:51'),(31,'publisher',NULL,'done','2018-11-16 20:55:41','2018-11-16 20:55:56'),(32,'publisher',NULL,'done','2018-11-16 21:58:44','2018-11-16 21:58:58'),(33,'publisher',NULL,'running','2018-11-16 22:02:27','2018-11-16 22:02:27'),(34,'publisher','undefined local variable or method `zipname\' for #<Aquadoc::Render:0x00007ffe86a82230>: (erb):5:in `make_about_md\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb.rb:861:in `eval\', /Users/ericklavins/.rvm/rubies/ruby-2.3.7/lib/ruby/2.3.0/erb','error','2018-11-16 22:07:51','2018-11-16 22:07:56'),(35,'publisher',NULL,'done','2018-11-16 22:09:37','2018-11-16 22:09:48'),(36,'publisher',NULL,'done','2018-11-16 22:12:31','2018-11-16 22:12:51'),(37,'publisher',NULL,'done','2018-11-16 22:17:24','2018-11-16 22:17:51'),(38,'publisher',NULL,'done','2018-11-16 22:22:22','2018-11-16 22:22:33'),(39,'publisher',NULL,'done','2018-11-27 23:09:12','2018-11-27 23:10:09'),(40,'publisher',NULL,'done','2018-11-27 23:28:01','2018-11-27 23:28:36'),(41,'publisher',NULL,'done','2018-11-27 23:30:47','2018-11-27 23:31:14'),(42,'publisher',NULL,'done','2018-11-27 23:34:57','2018-11-27 23:35:13'),(43,'publisher',NULL,'done','2018-11-27 23:36:23','2018-11-27 23:36:51'),(44,'publisher',NULL,'done','2018-11-27 23:41:27','2018-11-27 23:42:18'),(45,'publisher',NULL,'done','2018-12-12 18:29:44','2018-12-12 18:31:08'),(46,'publisher',NULL,'done','2018-12-17 21:35:41','2018-12-17 21:36:01'),(47,'publisher',NULL,'done','2018-12-17 21:45:33','2018-12-17 21:45:52'),(48,'publisher',NULL,'done','2018-12-17 22:15:09','2018-12-17 22:15:29'),(49,'publisher',NULL,'done','2018-12-17 22:30:15','2018-12-17 22:30:33'),(50,'publisher',NULL,'done','2018-12-17 22:37:31','2018-12-17 22:37:51'),(51,'publisher',NULL,'done','2018-12-17 22:48:07','2018-12-17 22:48:14'),(52,'publisher',NULL,'done','2018-12-17 23:11:22','2018-12-17 23:11:40');
/*!40000 ALTER TABLE `workers` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2020-03-25  8:56:23
